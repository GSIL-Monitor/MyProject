{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.data.dataset as ds\n",
    "import importlib\n",
    "from torch.utils import data\n",
    "importlib.reload(ds)\n",
    "import torch.nn as nn\n",
    "from easydict import EasyDict as edict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "房产 房产\n",
      "股票 股票\n",
      "教育 教育\n",
      "彩票 彩票\n",
      "财经 财经\n",
      "家居 家居\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# data_path = 'D:/PROJECT_TW/git/data/nlp/w2v/data/'\n",
    "# model_path = 'D:/PROJECT_TW/git/data/nlp/w2v/'\n",
    "model_path = '/home/hecong/temp/data/txtdect/'\n",
    "data_path = '/home/hecong/temp/data/txtdect/data/'\n",
    "eds = ds.EduData(data_path, model_path)\n",
    "dl = data.DataLoader(eds,batch_size=50,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 64])\n"
     ]
    }
   ],
   "source": [
    "#检测 nn.Emmeding 使用训练好的词向量结果\n",
    "import torch.nn as nn\n",
    "_,in_data = next(enumerate(dl))\n",
    "words, labels = in_data\n",
    "print(words.size())\n",
    "embedding_matrix = torch.from_numpy(eds.embedding_matrix)\n",
    "embed = nn.Embedding(40000, 20,_weight=embedding_matrix)\n",
    "out_data = embed(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1263,  0.0895,  0.1022, -0.0152, -0.0142, -0.1604,  0.0136,  0.2782,\n",
      "         0.1092,  0.3852,  0.0381, -0.1342, -0.0961, -0.3812,  0.1454, -0.0697,\n",
      "         0.2485,  0.3764,  0.2450,  0.1813],\n",
      "       dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "tensor([ 7716,  8260,  9889,  3648,  6989, 10345,  2932,  2932,  2932,  2932,\n",
      "         2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,\n",
      "         2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,\n",
      "         2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,\n",
      "         2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,\n",
      "         2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,\n",
      "         2932,  2932,  2932,  2932])\n",
      "桥往\n",
      "[-0.09392507  0.07842945  0.08145787 -0.06175676 -0.01244122 -0.15300395\n",
      "  0.00825114  0.26267716  0.12067892  0.3600079   0.05808657 -0.11769318\n",
      " -0.05155514 -0.31181234  0.12862869 -0.05610953  0.19461681  0.33628106\n",
      "  0.21073024  0.18801825]\n"
     ]
    }
   ],
   "source": [
    "print(out_data[0][5])\n",
    "print(words[0])\n",
    "print(eds.idx_to_word[4237])\n",
    "print(eds.word_vec_mod.wv.get_vector('布莱克本'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化参数\n",
    "opt =  edict()\n",
    "opt.vocab_size = 40000\n",
    "opt.embedding_dim = 20\n",
    "opt.inception_dim = 40\n",
    "opt.static = False\n",
    "opt.num_classes = 6\n",
    "opt.content_seq_len = 64\n",
    "opt.linear_hidden_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关于conv1D 参看： https://blog.csdn.net/sunny_xsc1994/article/details/82969867\n",
    "import lib.models.CNNText_inception as cni\n",
    "import torch\n",
    "import os\n",
    "importlib.reload(cni)\n",
    "model_path = '/home/hecong/temp/data/txtdect/text_label_model.pkl'\n",
    "embedding_matrix = torch.from_numpy(eds.embedding_matrix)\n",
    "model = cni.CNNText_inception(opt, embedding_matrix)\n",
    "# 注意下面这个， 将model设置成model.double\n",
    "# https://stackoverflow.com/questions/49407303/runtimeerror-expected-object-of-type-torch-doubletensor-but-found-type-torch-fl\n",
    "model = model.double()\n",
    "if os.path.exists(model_path):\n",
    "    model.load_state_dict(torch.load(model_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 0 loss -->  0.16328241401315668 \n",
      "0 - 20 loss -->  0.05633893977000484 \n",
      "0 - 40 loss -->  0.26951541884198543 \n",
      "1 - 0 loss -->  0.12244422631829163 \n",
      "1 - 20 loss -->  0.06169934083270395 \n",
      "1 - 40 loss -->  0.1322342433980609 \n",
      "2 - 0 loss -->  0.11293894033177489 \n",
      "2 - 20 loss -->  0.09090075843086266 \n",
      "2 - 40 loss -->  0.15550820445095412 \n",
      "3 - 0 loss -->  0.1764132696415878 \n",
      "3 - 20 loss -->  0.12626639566555078 \n",
      "3 - 40 loss -->  0.18832226897916585 \n",
      "4 - 0 loss -->  0.032558019594395866 \n",
      "4 - 20 loss -->  0.07329850720954112 \n",
      "4 - 40 loss -->  0.121924726046223 \n",
      "5 - 0 loss -->  0.07428776664816882 \n",
      "5 - 20 loss -->  0.2830046885585898 \n",
      "5 - 40 loss -->  0.1376136573303242 \n",
      "6 - 0 loss -->  0.15969451648023142 \n",
      "6 - 20 loss -->  0.12167635734823863 \n",
      "6 - 40 loss -->  0.10387805624821288 \n",
      "7 - 0 loss -->  0.15330603433696463 \n",
      "7 - 20 loss -->  0.12172527835127418 \n",
      "7 - 40 loss -->  0.11771297107651428 \n",
      "8 - 0 loss -->  0.121118666147443 \n",
      "8 - 20 loss -->  0.07305324908084934 \n",
      "8 - 40 loss -->  0.13953691067651455 \n",
      "9 - 0 loss -->  0.08746598598852953 \n",
      "9 - 20 loss -->  0.0902652026657344 \n",
      "9 - 40 loss -->  0.06309472739793226 \n",
      "10 - 0 loss -->  0.26916841568792926 \n",
      "10 - 20 loss -->  0.12235468172795504 \n",
      "10 - 40 loss -->  0.05500559882725481 \n",
      "11 - 0 loss -->  0.1032662657964371 \n",
      "11 - 20 loss -->  0.08209580902412285 \n",
      "11 - 40 loss -->  0.03785591084133797 \n",
      "12 - 0 loss -->  0.02296382833570812 \n",
      "12 - 20 loss -->  0.11002733796186112 \n",
      "12 - 40 loss -->  0.09455927822990302 \n",
      "13 - 0 loss -->  0.08259106551444004 \n",
      "13 - 20 loss -->  0.08187446227130614 \n",
      "13 - 40 loss -->  0.08651192906985003 \n",
      "14 - 0 loss -->  0.06952579485151937 \n",
      "14 - 20 loss -->  0.04598063369419712 \n",
      "14 - 40 loss -->  0.06448709628465926 \n",
      "15 - 0 loss -->  0.18110912534102552 \n",
      "15 - 20 loss -->  0.05979493952168647 \n",
      "15 - 40 loss -->  0.13959645861737105 \n",
      "16 - 0 loss -->  0.05837388652908105 \n",
      "16 - 20 loss -->  0.08841568387493426 \n",
      "16 - 40 loss -->  0.02520006012928265 \n",
      "17 - 0 loss -->  0.048880308229228675 \n",
      "17 - 20 loss -->  0.06489790592136212 \n",
      "17 - 40 loss -->  0.0735006028456108 \n",
      "18 - 0 loss -->  0.06964176428946996 \n",
      "18 - 20 loss -->  0.05718803713043427 \n",
      "18 - 40 loss -->  0.08902301464363706 \n",
      "19 - 0 loss -->  0.11633891955798552 \n",
      "19 - 20 loss -->  0.057285483873696114 \n",
      "19 - 40 loss -->  0.051562858942923694 \n",
      "20 - 0 loss -->  0.04010402667030874 \n",
      "20 - 20 loss -->  0.02899840326442484 \n",
      "20 - 40 loss -->  0.11276210264203831 \n",
      "21 - 0 loss -->  0.1030911123053662 \n",
      "21 - 20 loss -->  0.06900086402870959 \n",
      "21 - 40 loss -->  0.06678513075361693 \n",
      "22 - 0 loss -->  0.14148873132787565 \n",
      "22 - 20 loss -->  0.03759730547469701 \n",
      "22 - 40 loss -->  0.03006878627007018 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-07c078e1125a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPCHO = 100\n",
    "loss_fun =  nn.CrossEntropyLoss()\n",
    "\n",
    "LR = 0.001\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "MOMENTUM = 0.9\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), lr=LR, momentum=MOMENTUM)\n",
    "\n",
    "for step in range(EPCHO):\n",
    "    for i, (words, labels) in enumerate(dl):\n",
    "        out = model(content=words)\n",
    "        loss = loss_fun(out,labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 20 == 0:\n",
    "            print('{} - {} loss -->  {} '.format(step,i, loss))\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (40x1x40). Calculated output size: (40x1x0). Output size is too small at /pytorch/aten/src/THNN/generic/SpatialDilatedMaxPooling.c:67",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-26140ae93a7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwords_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_lables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# # {0: '家居', 1: '彩票', 2: '房产', 3: '教育', 4: '股票', 5: '财经'}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/temp/myproject/NLP/lib/models/CNNText_inception.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, content)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m#             content=content.detach(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m#         title_out=self.title_conv(title.permute(0,2,1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mcontent_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;31m#         out=torch.cat((title_out,content_out),1).view(content_out.size(0), -1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mcontent_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontent_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     72\u001b[0m         return F.max_pool1d(input, self.kernel_size, self.stride,\n\u001b[1;32m     73\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                             self.return_indices)\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmax_pool1d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool1d\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \"\"\"\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool1d_with_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_indices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given input size: (40x1x40). Calculated output size: (40x1x0). Output size is too small at /pytorch/aten/src/THNN/generic/SpatialDilatedMaxPooling.c:67"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "testDoc = '''\n",
    "乐居携手富力湾人居风水沙龙之二：人居与和谐\n",
    "　　沙龙二：人、居与和谐\n",
    "　　时间：2009年8月29日 15：30-16：30\n",
    "　　嘉宾：\n",
    "　　北京一普传统文化发展中心执行董事、中国华夏易经研究会副会长、中国姓名文化研究会副会长、世界禅道文化学术交流协会秘书长、国际易学文化研究院院长、国际易学文化研究会会长 一普\n",
    "　　东易日盛国际设计师 黄珊珊\n",
    "　　鑫视空间装饰艺术公司总经理 佘达\n",
    "　　以下为此次沙龙实录\n",
    "　　主持人：我们第二场沙龙的主题是人居与和谐，之前我们都看过冯小刚指导的电影《非诚勿扰》里面也说了二十一世纪主题就是和谐。我们的第二场沙龙主题也是人居与和谐，首先我还是隆重的介绍一下嘉宾：\n",
    "　　北京一普传统文化发展中心执行董事、中国华夏易经研究会副会长、中国姓名文化研究会副会长、世界禅道文化学术交流协会秘书长、国际易学文化研究院院长、国际易学文化研究会会长 一普\n",
    "　　东易日盛国际设计师 黄珊珊\n",
    "'''    \n",
    "# 提取中文, 分词， 得到词向量\n",
    "line = ds.extract_chinese(testDoc)\n",
    "ws = jieba.lcut(line, cut_all=False, HMM=True)\n",
    "words_ids = [eds.word_to_idx[x] for x in ws if x in eds.word_to_idx]\n",
    "words_ids = words_ids[0:64]\n",
    "words_ids = torch.LongTensor(words_ids)\n",
    "words_ids = words_ids.unsqueeze(0)\n",
    "twords = words[0]\n",
    "twords = twords.unsqueeze(0)\n",
    "print(twords.size())\n",
    "model.eval()\n",
    "out = model(content=words_ids)\n",
    "print(eds.index_lables[torch.argmax(out).item()])\n",
    "# # {0: '家居', 1: '彩票', 2: '房产', 3: '教育', 4: '股票', 5: '财经'}\n",
    "# print(out)\n",
    "# print(torch.argmax(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6639, -0.5013,  0.8872,  2.0600, -0.9295,  0.2828]],\n",
      "       dtype=torch.float64, grad_fn=<ThAddmmBackward>)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(out)\n",
    "print(torch.argmax(out).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "家居 家居\n",
      "彩票 彩票\n",
      "房产 房产\n",
      "教育 教育\n",
      "股票 股票\n",
      "财经 财经\n"
     ]
    }
   ],
   "source": [
    "import lib.data.dataset as ds\n",
    "import importlib\n",
    "from torch.utils import data\n",
    "importlib.reload(ds)\n",
    "data_path = 'D:/PROJECT_TW/git/data/nlp/w2v/data/'\n",
    "model_path = 'D:/PROJECT_TW/git/data/nlp/w2v/'\n",
    "eds = ds.EduData(data_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(eds.labels_index)\n",
    "# print(eds.texts[1000])\n",
    "# wid,labels = eds.__getitem__(1000)\n",
    "# print(wid)\n",
    "# print(eds.idx_to_word[5312])\n",
    "# print(eds.embedding_matrix[5312])\n",
    "# print(eds.word_vec_mod.wv.get_vector('一个'))\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 --> [tensor([ 10302,   2145,   7184,   2699,   5748]), tensor([ 6397,  8880,  5248,  2706,   487]), tensor([ 9119,  7483,  5870,   509,  5094]), tensor([  6203,   6967,   7773,  11474,    286]), tensor([  2923,  10029,   2848,  12855,  13372]), tensor([ 10692,   2656,   5275,   8921,  12963]), tensor([  3132,    509,   6453,  13312,   6439]), tensor([ 10968,   9744,    131,   5943,   6439]), tensor([ 11565,  11360,   7362,  12076,   6439]), tensor([ 12351,   5719,   2262,   1288,   6439]), tensor([ 3132,  2723,  1669,  9209,  6439]), tensor([  3503,    591,  10478,  12076,   6439]), tensor([ 5181,  6439,  8163,  6533,  6439]), tensor([ 10805,   6439,  12017,   6439,   6439]), tensor([ 3208,  6439,  3466,  6439,  6439]), tensor([  4344,   6439,  11035,   6439,   6439]), tensor([ 12646,   6439,   8472,   6439,   6439]), tensor([ 8158,  6439,  9633,  6439,  6439]), tensor([  1646,   6439,  13427,   6439,   6439]), tensor([  9807,   6439,  10283,   6439,   6439]), tensor([ 11707,   6439,  11797,   6439,   6439]), tensor([ 7064,  6439,  8096,  6439,  6439]), tensor([  9080,   6439,  13427,   6439,   6439]), tensor([ 10238,   6439,  11035,   6439,   6439]), tensor([ 3621,  6439,  8472,  6439,  6439]), tensor([ 4886,  6439,  9633,  6439,  6439]), tensor([ 13427,   6439,   8932,   6439,   6439]), tensor([ 10425,   6439,  10153,   6439,   6439]), tensor([ 10693,   6439,   7026,   6439,   6439]), tensor([  573,  6439,  4030,  6439,  6439]), tensor([ 10968,   6439,  13427,   6439,   6439]), tensor([ 2593,  6439,  2590,  6439,  6439]), tensor([ 4344,  6439,  4030,  6439,  6439]), tensor([ 1646,  6439,  6349,  6439,  6439]), tensor([ 9807,  6439,    98,  6439,  6439]), tensor([  533,  6439,  2316,  6439,  6439]), tensor([ 8062,  6439,  8214,  6439,  6439]), tensor([ 4344,  6439,  3896,  6439,  6439]), tensor([ 8264,  6439,  7362,  6439,  6439]), tensor([  3174,   6439,  10283,   6439,   6439]), tensor([  3277,   6439,  13427,   6439,   6439]), tensor([  5016,   6439,  10153,   6439,   6439]), tensor([ 2593,  6439,  8472,  6439,  6439]), tensor([ 9502,  6439,  9633,  6439,  6439]), tensor([ 5031,  6439,  9280,  6439,  6439]), tensor([ 8759,  6439,  2590,  6439,  6439]), tensor([ 7398,  6439,  4030,  6439,  6439]), tensor([  2149,   6439,  12914,   6439,   6439]), tensor([ 11728,   6439,   1774,   6439,   6439]), tensor([ 4429,  6439,  3175,  6439,  6439]), tensor([ 10302,   6439,   2454,   6439,   6439]), tensor([ 8345,  6439,  5883,  6439,  6439]), tensor([ 13451,   6439,   4142,   6439,   6439]), tensor([ 12523,   6439,  12442,   6439,   6439]), tensor([ 4531,  6439,  2590,  6439,  6439]), tensor([ 6579,  6439,  4030,  6439,  6439]), tensor([ 1646,  6439,  6349,  6439,  6439]), tensor([  9807,   6439,  12417,   6439,   6439]), tensor([ 11707,   6439,   1577,   6439,   6439]), tensor([ 13427,   6439,  11984,   6439,   6439]), tensor([ 13494,   6439,   4450,   6439,   6439]), tensor([  3966,   6439,  12417,   6439,   6439]), tensor([ 2199,  6439,  7055,  6439,  6439]), tensor([ 5067,  6439,  3823,  6439,  6439])] : tensor([ 1,  1,  2,  2,  2])\n"
     ]
    }
   ],
   "source": [
    "dl = data.DataLoader(eds,batch_size=5,shuffle=True)\n",
    "for step, (words,labels,word_source) in enumerate(dl):\n",
    "    if step == 1:\n",
    "        print('{} --> {} : {}'.format( step, words,labels))\n",
    "        break\n",
    "    \n",
    "#     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected torch.FloatTensor (got torch.LongTensor)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-5d4210049430>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# print(word_source)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected torch.FloatTensor (got torch.LongTensor)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(len(words))\n",
    "\n",
    "\n",
    "# print(word_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# CNNText_inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception(\n",
      "  (activa): Sequential(\n",
      "    (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (branch1): Sequential(\n",
      "    (conv1): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (branch2): Sequential(\n",
      "    (conv1): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
      "    (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  )\n",
      "  (branch3): Sequential(\n",
      "    (conv1): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv3): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  )\n",
      "  (branch4): Sequential(\n",
      "    (conv3): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from lib.models import Inception\n",
    "ince = Inception(256,512)\n",
    "print(ince)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

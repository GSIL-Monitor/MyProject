{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "plt.rcParams['figure.figsize'] = 15, 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 生成测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     2,
     91
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "# 取出文本框\n",
    "def get_text_rect(image):\n",
    "    img = image.copy()\n",
    "\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.GaussianBlur(img,(21,7),0)\n",
    "\n",
    "\n",
    "    img = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,11,2)\n",
    "    # plt.imshow(img,'gray')\n",
    "    # plt.show()\n",
    "\n",
    "    element = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 3))\n",
    "    img = cv2.erode(img, element)\n",
    "    # plt.imshow(img,'gray')\n",
    "    # plt.show()\n",
    "\n",
    "    img = cv2.dilate(img, element)\n",
    "    if DEBUG:\n",
    "        plt.imshow(img,'gray')\n",
    "        plt.show()\n",
    "\n",
    "    img = cv2.blur(img, tuple((5, 5)))\n",
    "    if DEBUG:\n",
    "        plt.imshow(img,'gray')\n",
    "        plt.show()\n",
    "    \n",
    "    # 去黑边\n",
    "    vertical = np.copy(img)\n",
    "    cols = vertical.shape[1]\n",
    "    vertical_size = int(cols / 40)\n",
    "    verticalStructure = cv2.getStructuringElement(cv2.MORPH_RECT, (1, vertical_size))\n",
    "    vertical = cv2.erode(vertical, verticalStructure)\n",
    "    vertical = cv2.dilate(vertical, verticalStructure)\n",
    "\n",
    "    vertical = cv2.blur(vertical, tuple((3, 3)))\n",
    "    element = cv2.getStructuringElement(cv2.MORPH_RECT, tuple((17, 17)), (-1, -1))\n",
    "    vertical = cv2.dilate(vertical, element, iterations=1)\n",
    "    vertical = cv2.bitwise_not(vertical)\n",
    "    img = cv2.bitwise_and(img,vertical)    \n",
    "    if DEBUG:\n",
    "        plt.imshow(img,'gray')\n",
    "        plt.show()    \n",
    "\n",
    "    element = cv2.getStructuringElement(cv2.MORPH_RECT, tuple((13, 5)), (-1, -1))\n",
    "    img = cv2.dilate(img, element, iterations=2)\n",
    "    if DEBUG:\n",
    "        plt.imshow(img,'gray')\n",
    "        plt.show()\n",
    "    \n",
    "    nimg, contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = []\n",
    "    # print(contours)\n",
    "    for cnt in contours:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        if w > 150 and w < 400:\n",
    "            cnts.append([y,x,h,w])\n",
    "    return cnts\n",
    "\n",
    "def check_in_areas(rect, rect_lists):\n",
    "    in_area = False\n",
    "    y,x,h,w = rect\n",
    "    for item in rect_lists:\n",
    "        iy,ix,ih,iw = item\n",
    "        if y>iy and x>ix and (y+h) < (iy + ih) and (x+w) <  (ix + iw):\n",
    "            in_area = True\n",
    "    return in_area\n",
    "\n",
    "# 取出字符文档框\n",
    "def get_char_rect(image):\n",
    "    img = image.copy()\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # plt.imshow(img,'gray')\n",
    "    # plt.show()\n",
    "    img = cv2.GaussianBlur(img,(3,3),0)\n",
    "    img = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV,11,2)\n",
    "    # plt.imshow(img,'gray')\n",
    "    # plt.show()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 去燥点\n",
    "    element = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    img = cv2.erode(img, element)\n",
    "    img = cv2.dilate(img, element,iterations=3)\n",
    "    # plt.imshow(img,'gray')\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    nimg, contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = []\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) > 250:    \n",
    "            \n",
    "            rect = cv2.boundingRect(cnt)\n",
    "#             if rect[2] >= 15:\n",
    "            x,y,w,h = rect\n",
    "            # 检查新增的区域是否在现有区域里面\n",
    "            if not check_in_areas([y,x,h,w], cnts):\n",
    "                cnts.append([y,x,h,w])\n",
    "\n",
    "    return cnts\n",
    "\n",
    "# 对文本框位置列表信息按Y、X坐标点进行排序\n",
    "# rect_list: 边框（y,x,h,w)位置列表， 类型 list\n",
    "# 返回排序号的rect_list, 类型list\n",
    "def text_rect_sort(rect_list):\n",
    "    rects = np.array(rect_list)\n",
    "    print('y mean --> {}'.format(np.mean(rects[:,0])))\n",
    "    print('y std --> {}'.format(np.std(rects[:,0])))\n",
    "    \n",
    "    if np.std(rects[:,0]) < 10:\n",
    "        # std 小于10 表明数据在一行，不需再作特殊处理\n",
    "        ridx = np.lexsort([rects[:,1]])\n",
    "        rects = rects[ridx]    \n",
    "    else:\n",
    "        ridx = np.lexsort([rects[:,1],rects[:,0]])\n",
    "        rects = rects[ridx]\n",
    "        # 对边框按坐标点Y进行区间划分\n",
    "        rect_area = (rects[:, 0] - rects[0][0])/ np.std(rects[:, 0],ddof=1)\n",
    "        rect_area = np.around(rect_area,1) \n",
    "\n",
    "        rect_current_class = 0\n",
    "        rect_class = [rect_current_class]\n",
    "        for inx in range(1, len(rect_area)):\n",
    "            if abs(rect_area[inx] - rect_area[inx-1]) > 0.5:\n",
    "                rect_current_class = rect_current_class + 1\n",
    "            rect_class.append(rect_current_class)        \n",
    "\n",
    "        rects = np.insert(rects,4,values=np.array(rect_class),axis=1)\n",
    "        ridx = np.lexsort([rects[:,1],rects[:,4]])\n",
    "        rects = rects[ridx]\n",
    "    return rects[:,0:4].tolist()\n",
    "\n",
    "def answer_bind_rect(rect_list, answer_list):\n",
    "    rect_len = len(rect_list)\n",
    "    answer_len = len(answer_list)\n",
    "    answers = {answer_list[answer_len-idx-1]:rect_list[rect_len-idx -1] for idx in range(answer_len)}\n",
    "    return answers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ 开始处理 360n4s -----------------\n",
      "[[2282, 846, 31, 412], [2287, 378, 30, 416], [2365, 844, 30, 413], [2370, 375, 30, 417], [2446, 842, 31, 414], [2452, 372, 31, 418], [2529, 840, 31, 416], [2535, 370, 32, 418], [2613, 839, 30, 415], [2618, 368, 33, 419]]\n",
      "[[1120, 312, 298, 1816], [1418, 309, 381, 1816], [1799, 299, 300, 1825], [2099, 291, 553, 1834], [2652, 275, 483, 1853]]\n",
      "y mean --> 183.5\n",
      "y std --> 36.16973873281365\n",
      "[[153, 88, 47, 353], [157, 495, 46, 352], [160, 901, 44, 350], [162, 1306, 44, 343], [234, 89, 46, 351], [235, 494, 47, 353]]\n",
      "{6: [235, 494, 47, 353], 5: [234, 89, 46, 351], 4: [162, 1306, 44, 343], 3: [160, 901, 44, 350], 2: [157, 495, 46, 352], 1: [153, 88, 47, 353]}\n",
      "y mean --> 264.75\n",
      "y std --> 38.93825240043523\n",
      "[[235, 84, 46, 265], [235, 404, 45, 264], [235, 724, 47, 262], [233, 1039, 48, 262], [235, 1353, 48, 260], [317, 83, 44, 264], [314, 402, 46, 265], [314, 721, 46, 263]]\n",
      "{14: [314, 721, 46, 263], 13: [314, 402, 46, 265], 12: [317, 83, 44, 264], 11: [235, 1353, 48, 260], 10: [233, 1039, 48, 262], 9: [235, 724, 47, 262], 8: [235, 404, 45, 264], 7: [235, 84, 46, 265]}\n",
      "y mean --> 230.83333333333334\n",
      "y std --> 2.6718699236468995\n",
      "[[235, 16, 51, 182], [234, 268, 51, 182], [230, 519, 53, 184], [229, 769, 52, 178], [228, 1015, 52, 179], [229, 1263, 52, 180]]\n",
      "{20: [229, 1263, 52, 180], 19: [228, 1015, 52, 179], 18: [229, 769, 52, 178], 17: [230, 519, 53, 184], 16: [234, 268, 51, 182], 15: [235, 16, 51, 182]}\n",
      "y mean --> 282.0\n",
      "y std --> 104.33553930423115\n",
      "[[75, 847, 54, 189], [171, 86, 48, 269], [168, 410, 51, 272], [163, 736, 50, 270], [160, 1061, 48, 268], [159, 1384, 50, 268], [256, 85, 47, 268], [253, 407, 50, 272], [246, 734, 51, 271], [246, 1060, 47, 269], [245, 1384, 47, 267], [341, 84, 46, 266], [338, 405, 50, 273], [335, 733, 47, 272], [332, 1059, 47, 271], [329, 1385, 49, 268], [422, 82, 50, 268], [426, 403, 47, 273], [421, 731, 48, 273], [417, 1058, 49, 272], [419, 1387, 47, 268]]\n",
      "{45: [419, 1387, 47, 268], 44: [417, 1058, 49, 272], 43: [421, 731, 48, 273], 42: [426, 403, 47, 273], 41: [422, 82, 50, 268], 40: [329, 1385, 49, 268], 39: [332, 1059, 47, 271], 38: [335, 733, 47, 272], 37: [338, 405, 50, 273], 36: [341, 84, 46, 266], 35: [245, 1384, 47, 267], 34: [246, 1060, 47, 269], 33: [246, 734, 51, 271], 32: [253, 407, 50, 272], 31: [256, 85, 47, 268], 30: [159, 1384, 50, 268], 29: [160, 1061, 48, 268], 28: [163, 736, 50, 270], 27: [168, 410, 51, 272], 26: [171, 86, 48, 269]}\n",
      "------------ 开始处理 iphone6p -----------------\n",
      "[[1857, 712, 29, 371], [1859, 297, 29, 372], [1930, 710, 29, 372], [1932, 295, 30, 373], [2003, 709, 29, 372], [2006, 293, 29, 373], [2077, 707, 29, 374], [2079, 291, 30, 374], [2151, 707, 28, 373], [2153, 289, 30, 375]]\n",
      "[[812, 233, 267, 1636], [1079, 231, 344, 1638], [1423, 226, 271, 1643], [1694, 221, 494, 1648], [2188, 207, 435, 1662]]\n",
      "y mean --> 162.83333333333334\n",
      "y std --> 31.114930321131826\n",
      "[[140, 77, 42, 318], [142, 440, 42, 321], [142, 805, 41, 320], [140, 1170, 42, 321], [213, 76, 41, 318], [200, 439, 55, 321]]\n",
      "{6: [200, 439, 55, 321], 5: [213, 76, 41, 318], 4: [140, 1170, 42, 321], 3: [142, 805, 41, 320], 2: [142, 440, 42, 321], 1: [140, 77, 42, 318]}\n",
      "y mean --> 228.77777777777777\n",
      "y std --> 46.60895902858586\n",
      "[[137, 16, 47, 381], [215, 75, 43, 239], [214, 359, 42, 240], [213, 644, 44, 241], [210, 929, 46, 242], [212, 1215, 44, 242], [289, 74, 40, 238], [285, 357, 43, 241], [284, 643, 43, 241]]\n",
      "{14: [284, 643, 43, 241], 13: [285, 357, 43, 241], 12: [289, 74, 40, 238], 11: [212, 1215, 44, 242], 10: [210, 929, 46, 242], 9: [213, 644, 44, 241], 8: [214, 359, 42, 240], 7: [215, 75, 43, 239]}\n",
      "y mean --> 208.33333333333334\n",
      "y std --> 1.699673171197595\n",
      "[[211, 16, 46, 163], [210, 236, 47, 166], [208, 459, 48, 168], [208, 683, 47, 164], [206, 905, 49, 165], [207, 1128, 49, 168]]\n",
      "{20: [207, 1128, 49, 168], 19: [206, 905, 49, 165], 18: [208, 683, 47, 164], 17: [208, 459, 48, 168], 16: [210, 236, 47, 166], 15: [211, 16, 46, 163]}\n",
      "y mean --> 251.1904761904762\n",
      "y std --> 93.47147211728957\n",
      "[[66, 752, 49, 173], [146, 76, 45, 243], [145, 363, 46, 246], [145, 652, 44, 246], [144, 943, 45, 246], [148, 1234, 46, 249], [222, 74, 44, 243], [221, 360, 45, 246], [219, 652, 46, 246], [222, 918, 43, 271], [225, 1235, 45, 247], [299, 73, 42, 241], [297, 358, 45, 247], [297, 650, 44, 247], [298, 941, 45, 249], [301, 1236, 47, 248], [372, 70, 46, 243], [377, 356, 43, 247], [375, 648, 44, 248], [375, 941, 47, 250], [381, 1237, 46, 249]]\n",
      "{45: [381, 1237, 46, 249], 44: [375, 941, 47, 250], 43: [375, 648, 44, 248], 42: [377, 356, 43, 247], 41: [372, 70, 46, 243], 40: [301, 1236, 47, 248], 39: [298, 941, 45, 249], 38: [297, 650, 44, 247], 37: [297, 358, 45, 247], 36: [299, 73, 42, 241], 35: [225, 1235, 45, 247], 34: [222, 918, 43, 271], 33: [219, 652, 46, 246], 32: [221, 360, 45, 246], 31: [222, 74, 44, 243], 30: [148, 1234, 46, 249], 29: [144, 943, 45, 246], 28: [145, 652, 44, 246], 27: [145, 363, 46, 246], 26: [146, 76, 45, 243]}\n",
      "------------ 开始处理 iphone6s -----------------\n",
      "[[1889, 763, 29, 383], [1890, 341, 29, 378], [1966, 338, 29, 379], [1966, 762, 28, 383], [2042, 760, 29, 384], [2043, 335, 28, 381], [2119, 331, 29, 382], [2119, 758, 29, 385], [2197, 327, 29, 385], [2197, 756, 28, 386]]\n",
      "[[805, 291, 279, 1670], [1084, 284, 354, 1675], [1438, 273, 281, 1684], [1719, 263, 517, 1695], [2236, 241, 456, 1722]]\n",
      "y mean --> 175.0\n",
      "y std --> 35.05709628591621\n",
      "[[153, 76, 42, 320], [151, 441, 43, 326], [150, 813, 42, 327], [147, 1187, 43, 327], [226, 74, 42, 320], [223, 440, 43, 325]]\n",
      "{6: [223, 440, 43, 325], 5: [226, 74, 42, 320], 4: [147, 1187, 43, 327], 3: [150, 813, 42, 327], 2: [151, 441, 43, 326], 1: [153, 76, 42, 320]}\n",
      "y mean --> 235.0\n",
      "y std --> 47.60252094164762\n",
      "[[142, 14, 47, 385], [222, 73, 43, 241], [219, 360, 44, 244], [219, 651, 45, 247], [216, 943, 46, 248], [216, 1238, 46, 247], [297, 71, 41, 241], [292, 358, 45, 245], [292, 650, 44, 246]]\n",
      "{14: [292, 650, 44, 246], 13: [292, 358, 45, 245], 12: [297, 71, 41, 241], 11: [216, 1238, 46, 247], 10: [216, 943, 46, 248], 9: [219, 651, 45, 247], 8: [219, 360, 44, 244], 7: [222, 73, 43, 241]}\n",
      "y mean --> 215.66666666666666\n",
      "y std --> 1.3743685418725538\n",
      "[[218, 11, 48, 167], [217, 237, 49, 169], [215, 465, 50, 172], [215, 695, 49, 168], [214, 923, 50, 170], [215, 1154, 50, 172]]\n",
      "{20: [215, 1154, 50, 172], 19: [214, 923, 50, 170], 18: [215, 695, 49, 168], 17: [215, 465, 50, 172], 16: [217, 237, 49, 169], 15: [218, 11, 48, 167]}\n",
      "y mean --> 260.6190476190476\n",
      "y std --> 96.69612499769141\n",
      "[[69, 776, 49, 178], [151, 75, 46, 252], [149, 373, 47, 253], [150, 673, 45, 254], [150, 973, 47, 254], [155, 1276, 48, 257], [230, 73, 46, 251], [228, 371, 47, 253], [227, 671, 48, 254], [232, 948, 45, 280], [236, 1277, 47, 255], [310, 70, 45, 251], [307, 368, 47, 255], [308, 670, 47, 255], [311, 971, 48, 257], [315, 1277, 50, 257], [388, 67, 47, 252], [377, 366, 58, 254], [390, 667, 47, 256], [392, 971, 48, 257], [398, 1277, 50, 258]]\n",
      "{45: [398, 1277, 50, 258], 44: [392, 971, 48, 257], 43: [390, 667, 47, 256], 42: [377, 366, 58, 254], 41: [388, 67, 47, 252], 40: [315, 1277, 50, 257], 39: [311, 971, 48, 257], 38: [308, 670, 47, 255], 37: [307, 368, 47, 255], 36: [310, 70, 45, 251], 35: [236, 1277, 47, 255], 34: [232, 948, 45, 280], 33: [227, 671, 48, 254], 32: [228, 371, 47, 253], 31: [230, 73, 46, 251], 30: [155, 1276, 48, 257], 29: [150, 973, 47, 254], 28: [150, 673, 45, 254], 27: [149, 373, 47, 253], 26: [151, 75, 46, 252]}\n",
      "------------ 开始处理 iphone8p -----------------\n",
      "[[1945, 745, 30, 384], [1948, 317, 29, 383], [2021, 744, 31, 384], [2025, 315, 28, 384], [2098, 742, 30, 385], [2101, 314, 28, 383], [2175, 740, 30, 387], [2177, 312, 29, 384], [2252, 740, 30, 386], [2255, 309, 28, 386]]\n",
      "[[860, 261, 278, 1678], [1138, 253, 356, 1685], [1494, 244, 280, 1692], [1774, 237, 516, 1698], [2290, 224, 446, 1710]]\n",
      "y mean --> 170.16666666666666\n",
      "y std --> 30.926885103776975\n",
      "[[145, 76, 43, 327], [148, 451, 45, 328], [150, 796, 42, 356], [151, 1198, 42, 325], [220, 74, 42, 327], [207, 448, 59, 329]]\n",
      "{6: [207, 448, 59, 329], 5: [220, 74, 42, 327], 4: [151, 1198, 42, 325], 3: [150, 796, 42, 356], 2: [148, 451, 45, 328], 1: [145, 76, 43, 327]}\n",
      "y mean --> 236.0\n",
      "y std --> 48.29078587059855\n",
      "[[139, 14, 50, 396], [220, 75, 44, 247], [221, 370, 43, 248], [221, 666, 45, 245], [219, 956, 46, 247], [220, 1250, 46, 245], [296, 73, 42, 248], [294, 368, 44, 249], [294, 663, 44, 246]]\n",
      "{14: [294, 663, 44, 246], 13: [294, 368, 44, 249], 12: [296, 73, 42, 248], 11: [220, 1250, 46, 245], 10: [219, 956, 46, 247], 9: [221, 666, 45, 245], 8: [221, 370, 43, 248], 7: [220, 75, 44, 247]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y mean --> 215.0\n",
      "y std --> 1.8257418583505538\n",
      "[[218, 14, 48, 169], [217, 243, 50, 172], [214, 476, 51, 173], [214, 708, 49, 167], [213, 935, 50, 169], [214, 1164, 50, 171]]\n",
      "{20: [214, 1164, 50, 171], 19: [213, 935, 50, 169], 18: [214, 708, 49, 167], 17: [214, 476, 51, 173], 16: [217, 243, 50, 172], 15: [218, 14, 48, 169]}\n",
      "y mean --> 254.66666666666666\n",
      "y std --> 94.25817298570546\n",
      "[[68, 777, 50, 178], [151, 78, 45, 251], [150, 376, 46, 252], [149, 675, 45, 252], [146, 974, 45, 251], [143, 1273, 48, 250], [229, 76, 45, 252], [226, 374, 47, 253], [224, 673, 47, 254], [225, 948, 44, 277], [222, 1273, 45, 248], [307, 75, 44, 250], [304, 372, 46, 254], [304, 673, 44, 253], [302, 972, 44, 253], [299, 1272, 47, 251], [385, 71, 47, 254], [371, 370, 58, 255], [382, 671, 45, 254], [379, 971, 46, 254], [382, 1273, 45, 252]]\n",
      "{45: [382, 1273, 45, 252], 44: [379, 971, 46, 254], 43: [382, 671, 45, 254], 42: [371, 370, 58, 255], 41: [385, 71, 47, 254], 40: [299, 1272, 47, 251], 39: [302, 972, 44, 253], 38: [304, 673, 44, 253], 37: [304, 372, 46, 254], 36: [307, 75, 44, 250], 35: [222, 1273, 45, 248], 34: [225, 948, 44, 277], 33: [224, 673, 47, 254], 32: [226, 374, 47, 253], 31: [229, 76, 45, 252], 30: [143, 1273, 48, 250], 29: [146, 974, 45, 251], 28: [149, 675, 45, 252], 27: [150, 376, 46, 252], 26: [151, 78, 45, 251]}\n",
      "------------ 开始处理 iphonese -----------------\n",
      "[[2052, 761, 29, 394], [2053, 324, 29, 390], [2130, 760, 28, 394], [2131, 322, 29, 391], [2207, 759, 29, 394], [2209, 321, 29, 391], [2286, 757, 28, 396], [2287, 318, 29, 393], [2365, 756, 28, 396], [2366, 316, 29, 394]]\n",
      "[[931, 259, 290, 1740], [1221, 255, 367, 1743], [1588, 248, 289, 1747], [1877, 242, 527, 1753], [2404, 228, 459, 1770]]\n",
      "y mean --> 183.0\n",
      "y std --> 33.54598833442433\n",
      "[[162, 81, 43, 334], [162, 463, 43, 338], [158, 850, 44, 339], [156, 1238, 44, 340], [237, 80, 44, 334], [223, 462, 56, 338]]\n",
      "{6: [223, 462, 56, 338], 5: [237, 80, 44, 334], 4: [156, 1238, 44, 340], 3: [158, 850, 44, 339], 2: [162, 463, 43, 338], 1: [162, 81, 43, 334]}\n",
      "y mean --> 257.625\n",
      "y std --> 37.81843961614493\n",
      "[[232, 79, 45, 250], [230, 378, 44, 253], [229, 680, 46, 255], [225, 984, 47, 255], [226, 1289, 46, 255], [310, 78, 42, 250], [305, 376, 45, 254], [304, 679, 45, 254]]\n",
      "{14: [304, 679, 45, 254], 13: [305, 376, 45, 254], 12: [310, 78, 42, 250], 11: [226, 1289, 46, 255], 10: [225, 984, 47, 255], 9: [229, 680, 46, 255], 8: [230, 378, 44, 253], 7: [232, 79, 45, 250]}\n",
      "y mean --> 222.66666666666666\n",
      "y std --> 2.1343747458109497\n",
      "[[226, 15, 48, 172], [225, 250, 49, 172], [222, 486, 51, 176], [222, 723, 50, 173], [220, 959, 51, 175], [221, 1198, 51, 177]]\n",
      "{20: [221, 1198, 51, 177], 19: [220, 959, 51, 175], 18: [222, 723, 50, 173], 17: [222, 486, 51, 176], 16: [225, 250, 49, 172], 15: [226, 15, 48, 172]}\n",
      "y mean --> 265.2857142857143\n",
      "y std --> 98.55003218435503\n",
      "[[70, 797, 51, 182], [154, 80, 47, 256], [153, 384, 47, 258], [153, 691, 46, 260], [153, 1000, 47, 260], [157, 1311, 48, 262], [234, 78, 46, 256], [232, 382, 47, 259], [232, 689, 48, 261], [235, 973, 46, 287], [238, 1311, 47, 261], [315, 77, 44, 254], [312, 381, 48, 259], [314, 689, 47, 260], [316, 998, 47, 263], [319, 1311, 49, 262], [392, 75, 47, 256], [396, 379, 45, 258], [396, 687, 46, 261], [397, 997, 48, 264], [403, 1312, 49, 262]]\n",
      "{45: [403, 1312, 49, 262], 44: [397, 997, 48, 264], 43: [396, 687, 46, 261], 42: [396, 379, 45, 258], 41: [392, 75, 47, 256], 40: [319, 1311, 49, 262], 39: [316, 998, 47, 263], 38: [314, 689, 47, 260], 37: [312, 381, 48, 259], 36: [315, 77, 44, 254], 35: [238, 1311, 47, 261], 34: [235, 973, 46, 287], 33: [232, 689, 48, 261], 32: [232, 382, 47, 259], 31: [234, 78, 46, 256], 30: [157, 1311, 48, 262], 29: [153, 1000, 47, 260], 28: [153, 691, 46, 260], 27: [153, 384, 47, 258], 26: [154, 80, 47, 256]}\n",
      "------------ 开始处理 iphoneXS -----------------\n",
      "[[2011, 873, 30, 394], [2015, 425, 29, 400], [2089, 871, 31, 396], [2094, 424, 29, 399], [2167, 870, 31, 396], [2172, 422, 30, 399], [2245, 868, 32, 397], [2251, 421, 30, 399], [2325, 867, 31, 397], [2330, 419, 30, 400]]\n",
      "[[894, 359, 285, 1735], [1179, 354, 369, 1740], [1548, 346, 289, 1748], [1837, 341, 525, 1753], [2362, 330, 449, 1762]]\n",
      "y mean --> 175.0\n",
      "y std --> 31.203632267200348\n",
      "[[146, 81, 46, 340], [151, 456, 47, 358], [157, 863, 43, 337], [159, 1249, 43, 334], [224, 80, 45, 341], [213, 471, 62, 341]]\n",
      "{6: [213, 471, 62, 341], 5: [224, 80, 45, 341], 4: [159, 1249, 43, 334], 3: [157, 863, 43, 337], 2: [151, 456, 47, 358], 1: [146, 81, 46, 340]}\n",
      "y mean --> 259.125\n",
      "y std --> 36.84575111189891\n",
      "[[228, 79, 45, 257], [231, 388, 44, 256], [232, 694, 58, 254], [230, 997, 47, 252], [232, 1297, 46, 253], [307, 65, 43, 270], [306, 386, 45, 257], [307, 693, 44, 253]]\n",
      "{14: [307, 693, 44, 253], 13: [306, 386, 45, 257], 12: [307, 65, 43, 270], 11: [232, 1297, 46, 253], 10: [230, 997, 47, 252], 9: [232, 694, 58, 254], 8: [231, 388, 44, 256], 7: [228, 79, 45, 257]}\n",
      "y mean --> 222.16666666666666\n",
      "y std --> 1.7716909687891083\n",
      "[[225, 15, 49, 176], [224, 256, 50, 178], [221, 497, 51, 179], [222, 736, 50, 174], [220, 973, 51, 172], [221, 1208, 51, 174]]\n",
      "{20: [221, 1208, 51, 174], 19: [220, 973, 51, 172], 18: [222, 736, 50, 174], 17: [221, 497, 51, 179], 16: [224, 256, 50, 178], 15: [225, 15, 49, 176]}\n",
      "y mean --> 262.9047619047619\n",
      "y std --> 96.54059336776656\n",
      "[[70, 806, 53, 182], [161, 82, 46, 259], [157, 391, 49, 260], [154, 701, 47, 259], [150, 1008, 46, 258], [146, 1315, 48, 255], [241, 81, 45, 258], [237, 389, 47, 261], [231, 699, 49, 260], [231, 981, 44, 285], [227, 1315, 46, 253], [320, 79, 45, 258], [316, 388, 47, 261], [313, 699, 45, 260], [310, 1006, 44, 260], [304, 1315, 47, 254], [399, 77, 47, 260], [385, 386, 59, 261], [394, 697, 45, 261], [388, 1007, 48, 259], [387, 1316, 46, 256]]\n",
      "{45: [387, 1316, 46, 256], 44: [388, 1007, 48, 259], 43: [394, 697, 45, 261], 42: [385, 386, 59, 261], 41: [399, 77, 47, 260], 40: [304, 1315, 47, 254], 39: [310, 1006, 44, 260], 38: [313, 699, 45, 260], 37: [316, 388, 47, 261], 36: [320, 79, 45, 258], 35: [227, 1315, 46, 253], 34: [231, 981, 44, 285], 33: [231, 699, 49, 260], 32: [237, 389, 47, 261], 31: [241, 81, 45, 258], 30: [146, 1315, 48, 255], 29: [150, 1008, 46, 258], 28: [154, 701, 47, 259], 27: [157, 391, 49, 260], 26: [161, 82, 46, 259]}\n",
      "------------ 开始处理 vivoX9i -----------------\n",
      "[[2133, 924, 29, 400], [2134, 477, 29, 398], [2213, 923, 29, 401], [2214, 476, 28, 398], [2292, 922, 29, 401], [2293, 475, 28, 398], [2372, 473, 28, 399], [2372, 921, 28, 401], [2452, 471, 29, 400], [2452, 920, 28, 401]]\n",
      "[[981, 400, 303, 1805], [1284, 399, 377, 1797], [1661, 395, 296, 1792], [1957, 391, 534, 1792], [2491, 381, 463, 1797]]\n",
      "y mean --> 187.83333333333334\n",
      "y std --> 36.539552390374034\n",
      "[[161, 86, 44, 343], [162, 481, 45, 348], [163, 881, 43, 348], [162, 1282, 44, 348], [240, 85, 45, 344], [239, 480, 47, 347]]\n",
      "{6: [239, 480, 47, 347], 5: [240, 85, 45, 344], 4: [162, 1282, 44, 348], 3: [163, 881, 43, 348], 2: [162, 481, 45, 348], 1: [161, 86, 44, 343]}\n",
      "y mean --> 262.625\n",
      "y std --> 38.265315561223325\n",
      "[[233, 83, 45, 257], [234, 392, 44, 259], [234, 703, 46, 259], [231, 1015, 48, 260], [233, 1327, 47, 260], [314, 84, 43, 255], [311, 391, 45, 259], [311, 703, 46, 257]]\n",
      "{14: [311, 703, 46, 257], 13: [311, 391, 45, 259], 12: [314, 84, 43, 255], 11: [233, 1327, 47, 260], 10: [231, 1015, 48, 260], 9: [234, 703, 46, 259], 8: [234, 392, 44, 259], 7: [233, 83, 45, 257]}\n",
      "y mean --> 226.66666666666666\n",
      "y std --> 1.1055415967851334\n",
      "[[228, 18, 49, 175], [228, 259, 50, 176], [225, 500, 52, 180], [226, 744, 51, 174], [226, 984, 51, 176], [227, 1227, 51, 179]]\n",
      "{20: [227, 1227, 51, 179], 19: [226, 984, 51, 176], 18: [226, 744, 51, 174], 17: [225, 500, 52, 180], 16: [228, 259, 50, 176], 15: [228, 18, 49, 175]}\n",
      "y mean --> 265.7142857142857\n",
      "y std --> 98.91802419278339\n",
      "[[70, 812, 51, 183], [155, 83, 47, 260], [153, 393, 47, 262], [153, 706, 46, 260], [152, 1017, 48, 262], [157, 1331, 48, 263], [236, 81, 46, 260], [233, 391, 47, 262], [231, 704, 48, 262], [235, 991, 45, 288], [238, 1331, 47, 261], [317, 81, 44, 258], [313, 390, 47, 263], [314, 703, 46, 262], [315, 1015, 47, 264], [318, 1331, 49, 262], [396, 79, 46, 260], [397, 388, 45, 263], [397, 701, 46, 263], [397, 1014, 48, 264], [403, 1331, 48, 263]]\n",
      "{45: [403, 1331, 48, 263], 44: [397, 1014, 48, 264], 43: [397, 701, 46, 263], 42: [397, 388, 45, 263], 41: [396, 79, 46, 260], 40: [318, 1331, 49, 262], 39: [315, 1015, 47, 264], 38: [314, 703, 46, 262], 37: [313, 390, 47, 263], 36: [317, 81, 44, 258], 35: [238, 1331, 47, 261], 34: [235, 991, 45, 288], 33: [231, 704, 48, 262], 32: [233, 391, 47, 262], 31: [236, 81, 46, 260], 30: [157, 1331, 48, 263], 29: [152, 1017, 48, 262], 28: [153, 706, 46, 260], 27: [153, 393, 47, 262], 26: [155, 83, 47, 260]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ 开始处理 华为mate7 -----------------\n",
      "[[2170, 987, 29, 388], [2172, 551, 29, 390], [2248, 986, 29, 389], [2250, 549, 29, 391], [2325, 984, 29, 390], [2327, 547, 30, 391], [2403, 983, 29, 390], [2405, 544, 30, 392], [2481, 981, 30, 391], [2484, 542, 30, 393]]\n",
      "[[1058, 486, 289, 1722], [1347, 482, 364, 1721], [1711, 475, 288, 1722], [1999, 469, 521, 1727], [2520, 454, 456, 1741]]\n",
      "y mean --> 180.83333333333334\n",
      "y std --> 31.184486884061798\n",
      "[[152, 82, 47, 334], [159, 464, 45, 335], [162, 848, 42, 331], [163, 1227, 43, 333], [229, 79, 46, 336], [220, 463, 59, 334]]\n",
      "{6: [220, 463, 59, 334], 5: [229, 79, 46, 336], 4: [163, 1227, 43, 333], 3: [162, 848, 42, 331], 2: [159, 464, 45, 335], 1: [152, 82, 47, 334]}\n",
      "y mean --> 255.75\n",
      "y std --> 36.36189626518397\n",
      "[[225, 80, 45, 251], [228, 380, 44, 249], [229, 680, 45, 248], [227, 975, 47, 251], [229, 1273, 47, 250], [303, 77, 43, 251], [302, 377, 45, 252], [303, 676, 44, 251]]\n",
      "{14: [303, 676, 44, 251], 13: [302, 377, 45, 252], 12: [303, 77, 43, 251], 11: [229, 1273, 47, 250], 10: [227, 975, 47, 251], 9: [229, 680, 45, 248], 8: [228, 380, 44, 249], 7: [225, 80, 45, 251]}\n",
      "y mean --> 221.0\n",
      "y std --> 1.0\n",
      "[[222, 14, 48, 173], [222, 249, 49, 173], [220, 485, 50, 174], [220, 719, 50, 170], [220, 950, 50, 171], [222, 1183, 50, 173]]\n",
      "{20: [222, 1183, 50, 173], 19: [220, 950, 50, 171], 18: [220, 719, 50, 170], 17: [220, 485, 50, 174], 16: [222, 249, 49, 173], 15: [222, 14, 48, 173]}\n",
      "y mean --> 263.0\n",
      "y std --> 97.09739832716818\n",
      "[[70, 791, 50, 179], [157, 79, 46, 255], [154, 383, 47, 256], [152, 688, 46, 254], [151, 991, 46, 254], [152, 1295, 47, 253], [236, 78, 45, 254], [233, 381, 46, 256], [230, 686, 47, 255], [232, 965, 44, 280], [233, 1294, 44, 253], [316, 77, 44, 253], [312, 380, 46, 257], [312, 685, 45, 256], [311, 989, 45, 257], [310, 1294, 47, 254], [393, 75, 46, 254], [394, 377, 45, 257], [392, 684, 45, 256], [390, 989, 47, 256], [393, 1294, 45, 255]]\n",
      "{45: [393, 1294, 45, 255], 44: [390, 989, 47, 256], 43: [392, 684, 45, 256], 42: [394, 377, 45, 257], 41: [393, 75, 46, 254], 40: [310, 1294, 47, 254], 39: [311, 989, 45, 257], 38: [312, 685, 45, 256], 37: [312, 380, 46, 257], 36: [316, 77, 44, 253], 35: [233, 1294, 44, 253], 34: [232, 965, 44, 280], 33: [230, 686, 47, 255], 32: [233, 381, 46, 256], 31: [236, 78, 45, 254], 30: [152, 1295, 47, 253], 29: [151, 991, 46, 254], 28: [152, 688, 46, 254], 27: [154, 383, 47, 256], 26: [157, 79, 46, 255]}\n",
      "------------ 开始处理 华为畅享7plus -----------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-296d1ab52fb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mimgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mimage_bin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mexd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEXDetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage_bin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmobile_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'default'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[1;31m# 分隔试卷，取出包含选择题的项\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mregions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_exam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\PROJECT_TW\\git\\myproject\\imagehandle\\common\\examdetect.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, id, image, binaray, mobile_type)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcenter_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m   \u001b[1;31m# 试卷中心区域宽\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manswer_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# 填空题横线队列 [Y,X,H,W], 在clip_answers时设值\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morigin_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcenter_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgray_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcenter_gray_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinaray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgray_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\PROJECT_TW\\git\\myproject\\imagehandle\\common\\examdetect.py\u001b[0m in \u001b[0;36m_init_image\u001b[1;34m(self, image, binaray)\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource_imsage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;31m# 检测图片大小是否符合规格，检测图片清晰度\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mblue_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcenter_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcenter_width\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcenter_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcenter_heigh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__check_image__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             logger.info(\"试卷ID {} 原始图片 清晰度 {:.3f} 高度 {} 宽度 {} 中心宽度 {} 倾斜角度 {:.3f}\".format(self.id, blue_val,\n\u001b[0;32m     48\u001b[0m                                                                                          high, width, self.center_width, angle))\n",
      "\u001b[1;32mD:\\PROJECT_TW\\git\\myproject\\imagehandle\\common\\examdetect.py\u001b[0m in \u001b[0;36m__check_image__\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__check_image__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;31m# 模糊度检测\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mblue_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLaplacian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCV_64F\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[0mhigh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mimg_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_img_center__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\project_tw\\anly\\venv\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_var\u001b[1;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;31m# Note that if dtype is not of inexact type then arraymean will\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;31m# not be either.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[0marrmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         arrmean = um.true_divide(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "from common.examdetect import EXDetect\n",
    "clip_path = 'D:\\\\PROJECT_TW\\\\git\\\\data\\\\example\\\\image\\\\clip\\\\'\n",
    "\n",
    "# moible define\n",
    "qlists = [0,1,2,4]\n",
    "qdefines = {0:[1, 2, 3, 4, 5, 6],1:[7,8,9,10,11,12,13,14],2:[15, 16, 17, 18, 19, 20],\n",
    "            4:[26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]}\n",
    "answerdefines = { \n",
    "    1:'A-CDEF',2:'ABC-EF',3:'ABC-EF',4:'AB-DEF',5:'ABCDE-',6:'-BCDEF',7:'-BCD',8:'ABC-',\n",
    "    9:'AB-D',10:'AB-D',11:'-BCD',12:'AB-D',13:'AB-D',14:'-BCD',15:'T-',16:'-F',17:'T-',\n",
    "    18:'-F',19:'T-',20:'T-',26:'-BCD',27:'A-CD',28:'AB-D',29:'-BCD',30:'ABC-',31:'AB-D',\n",
    "    32:'-BCD',33:'AB-D',34:'A-CD',35:'A-CD',36:'ABC-',37:'A-CD',38:'-BCD',39:'-BCD',40:'A-CD',\n",
    "    41:'-BCD',42:'AB-D',43:'A-CD',44:'A-CD',45:'AB-D'\n",
    "}\n",
    "\n",
    "\n",
    "# mobile3 define\n",
    "# qlists = [0,1]\n",
    "# qdefines = {0:[82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93],1:[94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105]}\n",
    "# answerdefines = {82:'-BCDE',83:'-BCDE',84:'ABCD-',85:'-BCDE',86:'A-CDE',87:'ABC-E',\n",
    "#                  88:'A-CDE',89:'A-CDE',90:'-BCDE',91:'ABCD-',92:'ABC-E',93:'ABCD-',\n",
    "#                  94:'--CDE',95:'-BCD-',96:'AB-D-',97:'A-CDE',98:'AB-DE',99:'A--D-',\n",
    "#                  100:'-BCDE',101:'A-CD-',102:'AB-DE',103:'ABC-E',104:'A--DE',105:'-BCDE'\n",
    "#                 }\n",
    "\n",
    "\n",
    "# filename = '乐视2max'\n",
    "path = 'D:\\\\PROJECT_TW\\\\examrc\\\\data\\\\exam\\\\mobile\\\\'\n",
    "\n",
    "file_list = os.listdir(path)\n",
    "file_list = [x for x in file_list if x.endswith('jpg')]\n",
    "\n",
    "for item in file_list:\n",
    "    filename = item.split('.')[0]\n",
    "    print('------------ 开始处理 {} -----------------'.format(filename))\n",
    "    with  open('{}{}'.format(path,item),'rb') as f:\n",
    "        imgb = f.read()\n",
    "    image_bin = np.frombuffer(imgb, np.uint8)    \n",
    "    exd = EXDetect(id=1, image=image_bin, mobile_type='default')\n",
    "    # 分隔试卷，取出包含选择题的项\n",
    "    regions = exd.clip_exam()\n",
    "\n",
    "    for qidx in qlists:\n",
    "        y,x,h,w = regions[qidx]\n",
    "        rect_list = get_text_rect(exd.origin_image[y:y+h,x:x+w])\n",
    "        cv2.imwrite('d:\\\\clip_11.jpg',exd.origin_image[y:y+h,x:x+w])\n",
    "        rect_list = text_rect_sort(rect_list)\n",
    "        print(rect_list)\n",
    "        answers = answer_bind_rect(rect_list, qdefines[qidx])\n",
    "        print(answers)\n",
    "        for ans_no in answers.keys():\n",
    "            ay,ax,ah,aw = answers[ans_no]\n",
    "            rimg = exd.origin_image[y+ay:y+ay+ah, x+ax:x+ax+aw]\n",
    "            with open('{}{}_{}_{}.jpg'.format(clip_path,filename,ans_no,answerdefines[ans_no]),'wb') as f:\n",
    "                imgbin = cv2.imencode('.jpg',rimg)[1]\n",
    "                f.write(imgbin)\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360n4s_10_AB-D\n",
      "360n4s_11_-BCD\n",
      "360n4s_12_AB-D\n",
      "360n4s_13_AB-D\n",
      "360n4s_14_-BCD\n",
      "360n4s_15_T-\n",
      "360n4s_16_-F\n",
      "360n4s_17_T-\n",
      "360n4s_18_-F\n",
      "360n4s_19_T-\n",
      "360n4s_1_A-CDEF\n",
      "360n4s_20_T-\n",
      "360n4s_26_-BCD\n",
      "360n4s_27_A-CD\n",
      "360n4s_28_AB-D\n",
      "360n4s_29_-BCD\n",
      "360n4s_2_ABC-EF\n",
      "360n4s_30_ABC-\n",
      "360n4s_31_AB-D\n",
      "360n4s_32_-BCD\n",
      "360n4s_33_AB-D\n",
      "360n4s_34_A-CD\n",
      "360n4s_35_A-CD\n",
      "360n4s_36_ABC-\n",
      "360n4s_37_A-CD\n",
      "360n4s_38_-BCD\n",
      "360n4s_39_-BCD\n",
      "360n4s_3_ABC-EF\n",
      "360n4s_40_A-CD\n",
      "360n4s_41_-BCD\n",
      "360n4s_42_AB-D\n",
      "360n4s_43_A-CD\n",
      "360n4s_44_A-CD\n",
      "360n4s_45_AB-D\n",
      "360n4s_4_AB-DEF\n",
      "360n4s_5_ABCDE-\n",
      "360n4s_6_-BCDEF\n",
      "360n4s_7_-BCD\n",
      "360n4s_8_ABC-\n",
      "360n4s_9_AB-D\n",
      "iphone6p_10_AB-D\n",
      "iphone6p_11_-BCD\n",
      "iphone6p_12_AB-D\n",
      "iphone6p_13_AB-D\n",
      "iphone6p_14_-BCD\n",
      "iphone6p_15_T-\n",
      "iphone6p_16_-F\n",
      "iphone6p_17_T-\n",
      "iphone6p_18_-F\n",
      "iphone6p_19_T-\n",
      "iphone6p_1_A-CDEF\n",
      "iphone6p_20_T-\n",
      "iphone6p_26_-BCD\n",
      "iphone6p_27_A-CD\n",
      "iphone6p_28_AB-D\n",
      "iphone6p_29_-BCD\n",
      "iphone6p_2_ABC-EF\n",
      "iphone6p_30_ABC-\n",
      "iphone6p_31_AB-D\n",
      "iphone6p_32_-BCD\n",
      "iphone6p_33_AB-D\n",
      "iphone6p_34_A-CD\n",
      "iphone6p_35_A-CD\n",
      "iphone6p_36_ABC-\n",
      "iphone6p_37_A-CD\n",
      "iphone6p_38_-BCD\n",
      "iphone6p_39_-BCD\n",
      "iphone6p_3_ABC-EF\n",
      "iphone6p_40_A-CD\n",
      "iphone6p_41_-BCD\n",
      "iphone6p_42_AB-D\n",
      "iphone6p_43_A-CD\n",
      "iphone6p_44_A-CD\n",
      "iphone6p_45_AB-D\n",
      "iphone6p_4_AB-DEF\n",
      "iphone6p_5_ABCDE-\n",
      "iphone6p_6_-BCDEF\n",
      "iphone6p_7_-BCD\n",
      "iphone6p_8_ABC-\n",
      "iphone6p_9_AB-D\n",
      "iphone6s_10_AB-D\n",
      "iphone6s_11_-BCD\n",
      "iphone6s_12_AB-D\n",
      "iphone6s_13_AB-D\n",
      "iphone6s_14_-BCD\n",
      "iphone6s_15_T-\n",
      "iphone6s_16_-F\n",
      "iphone6s_17_T-\n",
      "iphone6s_18_-F\n",
      "iphone6s_19_T-\n",
      "iphone6s_1_A-CDEF\n",
      "iphone6s_20_T-\n",
      "iphone6s_26_-BCD\n",
      "iphone6s_27_A-CD\n",
      "iphone6s_28_AB-D\n",
      "iphone6s_29_-BCD\n",
      "iphone6s_2_ABC-EF\n",
      "iphone6s_30_ABC-\n",
      "iphone6s_31_AB-D\n",
      "iphone6s_32_-BCD\n",
      "iphone6s_33_AB-D\n",
      "iphone6s_34_A-CD\n",
      "iphone6s_35_A-CD\n",
      "iphone6s_36_ABC-\n",
      "iphone6s_37_A-CD\n",
      "iphone6s_38_-BCD\n",
      "iphone6s_39_-BCD\n",
      "iphone6s_3_ABC-EF\n",
      "iphone6s_40_A-CD\n",
      "iphone6s_41_-BCD\n",
      "iphone6s_42_AB-D\n",
      "iphone6s_43_A-CD\n",
      "iphone6s_44_A-CD\n",
      "iphone6s_45_AB-D\n",
      "iphone6s_4_AB-DEF\n",
      "iphone6s_5_ABCDE-\n",
      "iphone6s_6_-BCDEF\n",
      "iphone6s_7_-BCD\n",
      "iphone6s_8_ABC-\n",
      "iphone6s_9_AB-D\n",
      "iphone8P_100_-BCDE\n",
      "iphone8P_101_A-CD-\n",
      "iphone8P_102_AB-DE\n",
      "iphone8P_103_ABC-E\n",
      "iphone8P_104_A--DE\n",
      "iphone8P_105_-BCDE\n",
      "iphone8p_10_AB-D\n",
      "iphone8p_11_-BCD\n",
      "iphone8p_12_AB-D\n",
      "iphone8p_13_AB-D\n",
      "iphone8p_14_-BCD\n",
      "iphone8p_15_T-\n",
      "iphone8p_16_-F\n",
      "iphone8p_17_T-\n",
      "iphone8p_18_-F\n",
      "iphone8p_19_T-\n",
      "iphone8p_1_A-CDEF\n",
      "iphone8p_20_T-\n",
      "iphone8p_26_-BCD\n",
      "iphone8p_27_A-CD\n",
      "iphone8p_28_AB-D\n",
      "iphone8p_29_-BCD\n",
      "iphone8p_2_ABC-EF\n",
      "iphone8p_30_ABC-\n",
      "iphone8p_31_AB-D\n",
      "iphone8p_32_-BCD\n",
      "iphone8p_33_AB-D\n",
      "iphone8p_34_A-CD\n",
      "iphone8p_35_A-CD\n",
      "iphone8p_36_ABC-\n",
      "iphone8p_37_A-CD\n",
      "iphone8p_38_-BCD\n",
      "iphone8p_39_-BCD\n",
      "iphone8p_3_ABC-EF\n",
      "iphone8p_40_A-CD\n",
      "iphone8p_41_-BCD\n",
      "iphone8p_42_AB-D\n",
      "iphone8p_43_A-CD\n",
      "iphone8p_44_A-CD\n",
      "iphone8p_45_AB-D\n",
      "iphone8p_4_AB-DEF\n",
      "iphone8p_5_ABCDE-\n",
      "iphone8p_6_-BCDEF\n",
      "iphone8p_7_-BCD\n",
      "iphone8P_82_-BCDE\n",
      "iphone8P_83_-BCDE\n",
      "iphone8P_84_ABCD-\n",
      "iphone8P_85_-BCDE\n",
      "iphone8P_86_A-CDE\n",
      "iphone8P_87_ABC-E\n",
      "iphone8P_88_A-CDE\n",
      "iphone8P_89_A-CDE\n",
      "iphone8p_8_ABC-\n",
      "iphone8P_90_-BCDE\n",
      "iphone8P_91_ABCD-\n",
      "iphone8P_92_ABC-E\n",
      "iphone8P_93_ABCD-\n",
      "iphone8P_94_--CDE\n",
      "iphone8P_95_-BCD-\n",
      "iphone8P_96_AB-D-\n",
      "iphone8P_97_A-CDE\n",
      "iphone8P_98_AB-DE\n",
      "iphone8P_99_A--D-\n",
      "iphone8p_9_AB-D\n",
      "iphoneSE_100_-BCDE\n",
      "iphoneSE_101_A-CD-\n",
      "iphoneSE_102_AB-DE\n",
      "iphoneSE_103_ABC-E\n",
      "iphoneSE_104_A--DE\n",
      "iphoneSE_105_-BCDE\n",
      "iphonese_10_AB-D\n",
      "iphonese_11_-BCD\n",
      "iphonese_12_AB-D\n",
      "iphonese_13_AB-D\n",
      "iphonese_14_-BCD\n",
      "iphonese_15_T-\n",
      "iphonese_16_-F\n",
      "iphonese_17_T-\n",
      "iphonese_18_-F\n",
      "iphonese_19_T-\n",
      "iphonese_1_A-CDEF\n",
      "iphonese_20_T-\n",
      "iphonese_26_-BCD\n",
      "iphonese_27_A-CD\n",
      "iphonese_28_AB-D\n",
      "iphonese_29_-BCD\n",
      "iphonese_2_ABC-EF\n",
      "iphonese_30_ABC-\n",
      "iphonese_31_AB-D\n",
      "iphonese_32_-BCD\n",
      "iphonese_33_AB-D\n",
      "iphonese_34_A-CD\n",
      "iphonese_35_A-CD\n",
      "iphonese_36_ABC-\n",
      "iphonese_37_A-CD\n",
      "iphonese_38_-BCD\n",
      "iphonese_39_-BCD\n",
      "iphonese_3_ABC-EF\n",
      "iphonese_40_A-CD\n",
      "iphonese_41_-BCD\n",
      "iphonese_42_AB-D\n",
      "iphonese_43_A-CD\n",
      "iphonese_44_A-CD\n",
      "iphonese_45_AB-D\n",
      "iphonese_4_AB-DEF\n",
      "iphonese_5_ABCDE-\n",
      "iphonese_6_-BCDEF\n",
      "iphonese_7_-BCD\n",
      "iphoneSE_82_-BCDE\n",
      "iphoneSE_83_-BCDE\n",
      "iphoneSE_84_ABCD-\n",
      "iphoneSE_85_-BCDE\n",
      "iphoneSE_86_A-CDE\n",
      "iphoneSE_87_ABC-E\n",
      "iphoneSE_88_A-CDE\n",
      "iphoneSE_89_A-CDE\n",
      "iphonese_8_ABC-\n",
      "iphoneSE_90_-BCDE\n",
      "iphoneSE_91_ABCD-\n",
      "iphoneSE_92_ABC-E\n",
      "iphoneSE_93_ABCD-\n",
      "iphoneSE_94_--CDE\n",
      "iphoneSE_95_-BCD-\n",
      "iphoneSE_96_AB-D-\n",
      "iphoneSE_97_A-CDE\n",
      "iphoneSE_98_AB-DE\n",
      "iphoneSE_99_A--D-\n",
      "iphonese_9_AB-D\n",
      "iphoneXS_10_AB-D\n",
      "iphoneXS_11_-BCD\n",
      "iphoneXS_12_AB-D\n",
      "iphoneXS_13_AB-D\n",
      "iphoneXS_14_-BCD\n",
      "iphoneXS_15_T-\n",
      "iphoneXS_16_-F\n",
      "iphoneXS_17_T-\n",
      "iphoneXS_18_-F\n",
      "iphoneXS_19_T-\n",
      "iphoneXS_1_A-CDEF\n",
      "iphoneXS_20_T-\n",
      "iphoneXS_26_-BCD\n",
      "iphoneXS_27_A-CD\n",
      "iphoneXS_28_AB-D\n",
      "iphoneXS_29_-BCD\n",
      "iphoneXS_2_ABC-EF\n",
      "iphoneXS_30_ABC-\n",
      "iphoneXS_31_AB-D\n",
      "iphoneXS_32_-BCD\n",
      "iphoneXS_33_AB-D\n",
      "iphoneXS_34_A-CD\n",
      "iphoneXS_35_A-CD\n",
      "iphoneXS_36_ABC-\n",
      "iphoneXS_37_A-CD\n",
      "iphoneXS_38_-BCD\n",
      "iphoneXS_39_-BCD\n",
      "iphoneXS_3_ABC-EF\n",
      "iphoneXS_40_A-CD\n",
      "iphoneXS_41_-BCD\n",
      "iphoneXS_42_AB-D\n",
      "iphoneXS_43_A-CD\n",
      "iphoneXS_44_A-CD\n",
      "iphoneXS_45_AB-D\n",
      "iphoneXS_4_AB-DEF\n",
      "iphoneXS_5_ABCDE-\n",
      "iphoneXS_6_-BCDEF\n",
      "iphoneXS_7_-BCD\n",
      "iphoneXS_8_ABC-\n",
      "iphoneXS_9_AB-D\n",
      "vivoX9i_10_AB-D\n",
      "vivoX9i_11_-BCD\n",
      "vivoX9i_12_AB-D\n",
      "vivoX9i_13_AB-D\n",
      "vivoX9i_14_-BCD\n",
      "vivoX9i_15_T-\n",
      "vivoX9i_16_-F\n",
      "vivoX9i_17_T-\n",
      "vivoX9i_18_-F\n",
      "vivoX9i_19_T-\n",
      "vivoX9i_1_A-CDEF\n",
      "vivoX9i_20_T-\n",
      "vivoX9i_26_-BCD\n",
      "vivoX9i_27_A-CD\n",
      "vivoX9i_28_AB-D\n",
      "vivoX9i_29_-BCD\n",
      "vivoX9i_2_ABC-EF\n",
      "vivoX9i_30_ABC-\n",
      "vivoX9i_31_AB-D\n",
      "vivoX9i_32_-BCD\n",
      "vivoX9i_33_AB-D\n",
      "vivoX9i_34_A-CD\n",
      "vivoX9i_35_A-CD\n",
      "vivoX9i_36_ABC-\n",
      "vivoX9i_37_A-CD\n",
      "vivoX9i_38_-BCD\n",
      "vivoX9i_39_-BCD\n",
      "vivoX9i_3_ABC-EF\n",
      "vivoX9i_40_A-CD\n",
      "vivoX9i_41_-BCD\n",
      "vivoX9i_42_AB-D\n",
      "vivoX9i_43_A-CD\n",
      "vivoX9i_44_A-CD\n",
      "vivoX9i_45_AB-D\n",
      "vivoX9i_4_AB-DEF\n",
      "vivoX9i_5_ABCDE-\n",
      "vivoX9i_6_-BCDEF\n",
      "vivoX9i_7_-BCD\n",
      "vivoX9i_8_ABC-\n",
      "vivoX9i_9_AB-D\n",
      "乐视2max_100_-BCDE\n",
      "乐视2max_101_A-CD-\n",
      "乐视2max_102_AB-DE\n",
      "乐视2max_103_ABC-E\n",
      "乐视2max_104_A--DE\n",
      "乐视2max_105_-BCDE\n",
      "乐视2max_82_-BCDE\n",
      "乐视2max_83_-BCDE\n",
      "乐视2max_84_ABCD-\n",
      "乐视2max_85_-BCDE\n",
      "乐视2max_86_A-CDE\n",
      "乐视2max_87_ABC-E\n",
      "乐视2max_88_A-CDE\n",
      "乐视2max_89_A-CDE\n",
      "乐视2max_90_-BCDE\n",
      "乐视2max_91_ABCD-\n",
      "乐视2max_92_ABC-E\n",
      "乐视2max_93_ABCD-\n",
      "乐视2max_94_--CDE\n",
      "乐视2max_95_-BCD-\n",
      "乐视2max_96_AB-D-\n",
      "乐视2max_97_A-CDE\n",
      "乐视2max_98_AB-DE\n",
      "乐视2max_99_A--D-\n",
      "华为mate7_10_AB-D\n",
      "华为mate7_11_-BCD\n",
      "华为mate7_12_AB-D\n",
      "华为mate7_13_AB-D\n",
      "华为mate7_14_-BCD\n",
      "华为mate7_15_T-\n",
      "华为mate7_16_-F\n",
      "华为mate7_17_T-\n",
      "华为mate7_18_-F\n",
      "华为mate7_19_T-\n",
      "华为mate7_1_A-CDEF\n",
      "华为mate7_20_T-\n",
      "华为mate7_26_-BCD\n",
      "华为mate7_27_A-CD\n",
      "华为mate7_28_AB-D\n",
      "华为mate7_29_-BCD\n",
      "华为mate7_2_ABC-EF\n",
      "华为mate7_30_ABC-\n",
      "华为mate7_31_AB-D\n",
      "华为mate7_32_-BCD\n",
      "华为mate7_33_AB-D\n",
      "华为mate7_34_A-CD\n",
      "华为mate7_35_A-CD\n",
      "华为mate7_36_ABC-\n",
      "华为mate7_37_A-CD\n",
      "华为mate7_38_-BCD\n",
      "华为mate7_39_-BCD\n",
      "华为mate7_3_ABC-EF\n",
      "华为mate7_40_A-CD\n",
      "华为mate7_41_-BCD\n",
      "华为mate7_42_AB-D\n",
      "华为mate7_43_A-CD\n",
      "华为mate7_44_A-CD\n",
      "华为mate7_45_AB-D\n",
      "华为mate7_4_AB-DEF\n",
      "华为mate7_5_ABCDE-\n",
      "华为mate7_6_-BCDEF\n",
      "华为mate7_7_-BCD\n",
      "华为mate7_8_ABC-\n",
      "华为mate7_9_AB-D\n",
      "华为畅享7plus_10_AB-D\n",
      "华为畅享7plus_11_-BCD\n",
      "华为畅享7plus_12_AB-D\n",
      "华为畅享7plus_13_AB-D\n",
      "华为畅享7plus_14_-BCD\n",
      "华为畅享7plus_15_T-\n",
      "华为畅享7plus_16_-F\n",
      "华为畅享7plus_17_T-\n",
      "华为畅享7plus_18_-F\n",
      "华为畅享7plus_19_T-\n",
      "华为畅享7plus_1_A-CDEF\n",
      "华为畅享7plus_20_T-\n",
      "华为畅享7plus_26_-BCD\n",
      "华为畅享7plus_27_A-CD\n",
      "华为畅享7plus_28_AB-D\n",
      "华为畅享7plus_29_-BCD\n",
      "华为畅享7plus_2_ABC-EF\n",
      "华为畅享7plus_30_ABC-\n",
      "华为畅享7plus_31_AB-D\n",
      "华为畅享7plus_32_-BCD\n",
      "华为畅享7plus_33_AB-D\n",
      "华为畅享7plus_34_A-CD\n",
      "华为畅享7plus_35_A-CD\n",
      "华为畅享7plus_36_ABC-\n",
      "华为畅享7plus_37_A-CD\n",
      "华为畅享7plus_38_-BCD\n",
      "华为畅享7plus_39_-BCD\n",
      "华为畅享7plus_3_ABC-EF\n",
      "华为畅享7plus_40_A-CD\n",
      "华为畅享7plus_41_-BCD\n",
      "华为畅享7plus_42_AB-D\n",
      "华为畅享7plus_43_A-CD\n",
      "华为畅享7plus_44_A-CD\n",
      "华为畅享7plus_45_AB-D\n",
      "华为畅享7plus_4_AB-DEF\n",
      "华为畅享7plus_5_ABCDE-\n",
      "华为畅享7plus_6_-BCDEF\n",
      "华为畅享7plus_7_-BCD\n",
      "华为畅享7plus_8_ABC-\n",
      "华为畅享7plus_9_AB-D\n",
      "华为荣耀V10_10_AB-D\n",
      "华为荣耀V10_11_-BCD\n",
      "华为荣耀V10_12_AB-D\n",
      "华为荣耀V10_13_AB-D\n",
      "华为荣耀V10_14_-BCD\n",
      "华为荣耀V10_15_T-\n",
      "华为荣耀V10_16_-F\n",
      "华为荣耀V10_17_T-\n",
      "华为荣耀V10_18_-F\n",
      "华为荣耀V10_19_T-\n",
      "华为荣耀V10_1_A-CDEF\n",
      "华为荣耀V10_20_T-\n",
      "华为荣耀V10_26_-BCD\n",
      "华为荣耀V10_27_A-CD\n",
      "华为荣耀V10_28_AB-D\n",
      "华为荣耀V10_29_-BCD\n",
      "华为荣耀V10_2_ABC-EF\n",
      "华为荣耀V10_30_ABC-\n",
      "华为荣耀V10_31_AB-D\n",
      "华为荣耀V10_32_-BCD\n",
      "华为荣耀V10_33_AB-D\n",
      "华为荣耀V10_34_A-CD\n",
      "华为荣耀V10_35_A-CD\n",
      "华为荣耀V10_36_ABC-\n",
      "华为荣耀V10_37_A-CD\n",
      "华为荣耀V10_38_-BCD\n",
      "华为荣耀V10_39_-BCD\n",
      "华为荣耀V10_3_ABC-EF\n",
      "华为荣耀V10_40_A-CD\n",
      "华为荣耀V10_41_-BCD\n",
      "华为荣耀V10_42_AB-D\n",
      "华为荣耀V10_43_A-CD\n",
      "华为荣耀V10_44_A-CD\n",
      "华为荣耀V10_45_AB-D\n",
      "华为荣耀V10_4_AB-DEF\n",
      "华为荣耀V10_5_ABCDE-\n",
      "华为荣耀V10_6_-BCDEF\n",
      "华为荣耀V10_7_-BCD\n",
      "华为荣耀V10_8_ABC-\n",
      "华为荣耀V10_9_AB-D\n",
      "华为荣耀V8_10_AB-D\n",
      "华为荣耀V8_11_-BCD\n",
      "华为荣耀V8_12_AB-D\n",
      "华为荣耀V8_13_AB-D\n",
      "华为荣耀V8_14_-BCD\n",
      "华为荣耀V8_15_T-\n",
      "华为荣耀V8_16_-F\n",
      "华为荣耀V8_17_T-\n",
      "华为荣耀V8_18_-F\n",
      "华为荣耀V8_19_T-\n",
      "华为荣耀V8_1_A-CDEF\n",
      "华为荣耀V8_20_T-\n",
      "华为荣耀V8_26_-BCD\n",
      "华为荣耀V8_27_A-CD\n",
      "华为荣耀V8_28_AB-D\n",
      "华为荣耀V8_29_-BCD\n",
      "华为荣耀V8_2_ABC-EF\n",
      "华为荣耀V8_30_ABC-\n",
      "华为荣耀V8_31_AB-D\n",
      "华为荣耀V8_32_-BCD\n",
      "华为荣耀V8_33_AB-D\n",
      "华为荣耀V8_34_A-CD\n",
      "华为荣耀V8_35_A-CD\n",
      "华为荣耀V8_36_ABC-\n",
      "华为荣耀V8_37_A-CD\n",
      "华为荣耀V8_38_-BCD\n",
      "华为荣耀V8_39_-BCD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "华为荣耀V8_3_ABC-EF\n",
      "华为荣耀V8_40_A-CD\n",
      "华为荣耀V8_41_-BCD\n",
      "华为荣耀V8_42_AB-D\n",
      "华为荣耀V8_43_A-CD\n",
      "华为荣耀V8_44_A-CD\n",
      "华为荣耀V8_45_AB-D\n",
      "华为荣耀V8_4_AB-DEF\n",
      "华为荣耀V8_5_ABCDE-\n",
      "华为荣耀V8_6_-BCDEF\n",
      "华为荣耀V8_7_-BCD\n",
      "华为荣耀V8_8_ABC-\n",
      "华为荣耀V8_9_AB-D\n",
      "小米5_100_-BCDE\n",
      "小米5_101_A-CD-\n",
      "小米5_102_AB-DE\n",
      "小米5_103_ABC-E\n",
      "小米5_104_A--DE\n",
      "小米5_105_-BCDE\n",
      "小米5_10_AB-D\n",
      "小米5_11_-BCD\n",
      "小米5_12_AB-D\n",
      "小米5_13_AB-D\n",
      "小米5_14_-BCD\n",
      "小米5_15_T-\n",
      "小米5_16_-F\n",
      "小米5_17_T-\n",
      "小米5_18_-F\n",
      "小米5_19_T-\n",
      "小米5_1_A-CDEF\n",
      "小米5_20_T-\n",
      "小米5_26_-BCD\n",
      "小米5_27_A-CD\n",
      "小米5_28_AB-D\n",
      "小米5_29_-BCD\n",
      "小米5_2_ABC-EF\n",
      "小米5_30_ABC-\n",
      "小米5_31_AB-D\n",
      "小米5_32_-BCD\n",
      "小米5_33_AB-D\n",
      "小米5_34_A-CD\n",
      "小米5_35_A-CD\n",
      "小米5_36_ABC-\n",
      "小米5_37_A-CD\n",
      "小米5_38_-BCD\n",
      "小米5_39_-BCD\n",
      "小米5_3_ABC-EF\n",
      "小米5_40_A-CD\n",
      "小米5_41_-BCD\n",
      "小米5_42_AB-D\n",
      "小米5_43_A-CD\n",
      "小米5_44_A-CD\n",
      "小米5_45_AB-D\n",
      "小米5_4_AB-DEF\n",
      "小米5_5_ABCDE-\n",
      "小米5_6_-BCDEF\n",
      "小米5_7_-BCD\n",
      "小米5_82_-BCDE\n",
      "小米5_83_-BCDE\n",
      "小米5_84_ABCD-\n",
      "小米5_85_-BCDE\n",
      "小米5_86_A-CDE\n",
      "小米5_87_ABC-E\n",
      "小米5_88_A-CDE\n",
      "小米5_89_A-CDE\n",
      "小米5_8_ABC-\n",
      "小米5_90_-BCDE\n",
      "小米5_91_ABCD-\n",
      "小米5_92_ABC-E\n",
      "小米5_93_ABCD-\n",
      "小米5_94_--CDE\n",
      "小米5_95_-BCD-\n",
      "小米5_96_AB-D-\n",
      "小米5_97_A-CDE\n",
      "小米5_98_AB-DE\n",
      "小米5_99_A--D-\n",
      "小米5_9_AB-D\n",
      "小米6_10_AB-D\n",
      "小米6_11_-BCD\n",
      "小米6_12_AB-D\n",
      "小米6_13_AB-D\n",
      "小米6_14_-BCD\n",
      "小米6_15_T-\n",
      "小米6_16_-F\n",
      "小米6_17_T-\n",
      "小米6_18_-F\n",
      "小米6_19_T-\n",
      "小米6_1_A-CDEF\n",
      "小米6_20_T-\n",
      "小米6_26_-BCD\n",
      "小米6_27_A-CD\n",
      "小米6_28_AB-D\n",
      "小米6_29_-BCD\n",
      "小米6_2_ABC-EF\n",
      "小米6_30_ABC-\n",
      "小米6_31_AB-D\n",
      "小米6_32_-BCD\n",
      "小米6_33_AB-D\n",
      "小米6_34_A-CD\n",
      "小米6_35_A-CD\n",
      "小米6_36_ABC-\n",
      "小米6_37_A-CD\n",
      "小米6_38_-BCD\n",
      "小米6_39_-BCD\n",
      "小米6_3_ABC-EF\n",
      "小米6_40_A-CD\n",
      "小米6_41_-BCD\n",
      "小米6_42_AB-D\n",
      "小米6_43_A-CD\n",
      "小米6_44_A-CD\n",
      "小米6_45_AB-D\n",
      "小米6_4_AB-DEF\n",
      "小米6_5_ABCDE-\n",
      "小米6_6_-BCDEF\n",
      "小米6_7_-BCD\n",
      "小米6_8_ABC-\n",
      "小米6_9_AB-D\n",
      "小米max1_10_AB-D\n",
      "小米max1_11_-BCD\n",
      "小米max1_12_AB-D\n",
      "小米max1_13_AB-D\n",
      "小米max1_14_-BCD\n",
      "小米max1_15_T-\n",
      "小米max1_16_-F\n",
      "小米max1_17_T-\n",
      "小米max1_18_-F\n",
      "小米max1_19_T-\n",
      "小米max1_1_A-CDEF\n",
      "小米max1_20_T-\n",
      "小米max1_26_-BCD\n",
      "小米max1_27_A-CD\n",
      "小米max1_28_AB-D\n",
      "小米max1_29_-BCD\n",
      "小米max1_2_ABC-EF\n",
      "小米max1_30_ABC-\n",
      "小米max1_31_AB-D\n",
      "小米max1_32_-BCD\n",
      "小米max1_33_AB-D\n",
      "小米max1_34_A-CD\n",
      "小米max1_35_A-CD\n",
      "小米max1_36_ABC-\n",
      "小米max1_37_A-CD\n",
      "小米max1_38_-BCD\n",
      "小米max1_39_-BCD\n",
      "小米max1_3_ABC-EF\n",
      "小米max1_40_A-CD\n",
      "小米max1_41_-BCD\n",
      "小米max1_42_AB-D\n",
      "小米max1_43_A-CD\n",
      "小米max1_44_A-CD\n",
      "小米max1_45_AB-D\n",
      "小米max1_4_AB-DEF\n",
      "小米max1_5_ABCDE-\n",
      "小米max1_6_-BCDEF\n",
      "小米max1_7_-BCD\n",
      "小米max1_8_ABC-\n",
      "小米max1_9_AB-D\n",
      "魅族16_10_AB-D\n",
      "魅族16_11_-BCD\n",
      "魅族16_12_AB-D\n",
      "魅族16_13_AB-D\n",
      "魅族16_14_-BCD\n",
      "魅族16_15_T-\n",
      "魅族16_16_-F\n",
      "魅族16_17_T-\n",
      "魅族16_18_-F\n",
      "魅族16_19_T-\n",
      "魅族16_1_A-CDEF\n",
      "魅族16_20_T-\n",
      "魅族16_26_-BCD\n",
      "魅族16_27_A-CD\n",
      "魅族16_28_AB-D\n",
      "魅族16_29_-BCD\n",
      "魅族16_2_ABC-EF\n",
      "魅族16_30_ABC-\n",
      "魅族16_31_AB-D\n",
      "魅族16_32_-BCD\n",
      "魅族16_33_AB-D\n",
      "魅族16_34_A-CD\n",
      "魅族16_35_A-CD\n",
      "魅族16_36_ABC-\n",
      "魅族16_37_A-CD\n",
      "魅族16_38_-BCD\n",
      "魅族16_39_-BCD\n",
      "魅族16_3_ABC-EF\n",
      "魅族16_40_A-CD\n",
      "魅族16_41_-BCD\n",
      "魅族16_42_AB-D\n",
      "魅族16_43_A-CD\n",
      "魅族16_44_A-CD\n",
      "魅族16_45_AB-D\n",
      "魅族16_4_AB-DEF\n",
      "魅族16_5_ABCDE-\n",
      "魅族16_6_-BCDEF\n",
      "魅族16_7_-BCD\n",
      "魅族16_8_ABC-\n",
      "魅族16_9_AB-D\n",
      "魅族M2Note_10_AB-D\n",
      "魅族M2Note_11_-BCD\n",
      "魅族M2Note_12_AB-D\n",
      "魅族M2Note_13_AB-D\n",
      "魅族M2Note_14_-BCD\n",
      "魅族M2Note_15_T-\n",
      "魅族M2Note_16_-F\n",
      "魅族M2Note_17_T-\n",
      "魅族M2Note_18_-F\n",
      "魅族M2Note_19_T-\n",
      "魅族M2Note_1_A-CDEF\n",
      "魅族M2Note_20_T-\n",
      "魅族M2Note_26_-BCD\n",
      "魅族M2Note_27_A-CD\n",
      "魅族M2Note_28_AB-D\n",
      "魅族M2Note_29_-BCD\n",
      "魅族M2Note_2_ABC-EF\n",
      "魅族M2Note_30_ABC-\n",
      "魅族M2Note_31_AB-D\n",
      "魅族M2Note_32_-BCD\n",
      "魅族M2Note_33_AB-D\n",
      "魅族M2Note_34_A-CD\n",
      "魅族M2Note_35_A-CD\n",
      "魅族M2Note_36_ABC-\n",
      "魅族M2Note_37_A-CD\n",
      "魅族M2Note_38_-BCD\n",
      "魅族M2Note_39_-BCD\n",
      "魅族M2Note_3_ABC-EF\n",
      "魅族M2Note_40_A-CD\n",
      "魅族M2Note_41_-BCD\n",
      "魅族M2Note_42_AB-D\n",
      "魅族M2Note_43_A-CD\n",
      "魅族M2Note_44_A-CD\n",
      "魅族M2Note_45_AB-D\n",
      "魅族M2Note_4_AB-DEF\n",
      "魅族M2Note_5_ABCDE-\n",
      "魅族M2Note_6_-BCDEF\n",
      "魅族M2Note_7_-BCD\n",
      "魅族M2Note_8_ABC-\n",
      "魅族M2Note_9_AB-D\n",
      "魅族MX4_100_-BCDE\n",
      "魅族MX4_101_A-CD-\n",
      "魅族MX4_102_AB-DE\n",
      "魅族MX4_103_ABC-E\n",
      "魅族MX4_104_A--DE\n",
      "魅族MX4_105_-BCDE\n",
      "魅族MX4_82_-BCDE\n",
      "魅族MX4_83_-BCDE\n",
      "魅族MX4_84_ABCD-\n",
      "魅族MX4_85_-BCDE\n",
      "魅族MX4_86_A-CDE\n",
      "魅族MX4_87_ABC-E\n",
      "魅族MX4_88_A-CDE\n",
      "魅族MX4_89_A-CDE\n",
      "魅族MX4_90_-BCDE\n",
      "魅族MX4_91_ABCD-\n",
      "魅族MX4_92_ABC-E\n",
      "魅族MX4_93_ABCD-\n",
      "魅族MX4_94_--CDE\n",
      "魅族MX4_95_-BCD-\n",
      "魅族MX4_96_AB-D-\n",
      "魅族MX4_97_A-CDE\n",
      "魅族MX4_98_AB-DE\n",
      "魅族MX4_99_A--D-\n",
      "total files 760  time 60.9687\n"
     ]
    }
   ],
   "source": [
    "# 从文本框提取字符\n",
    "import time\n",
    "clip_path = 'D:\\\\PROJECT_TW\\\\git\\\\data\\\\example\\\\image\\\\clip\\\\'\n",
    "clip_save_path = 'D:\\\\PROJECT_TW\\\\git\\\\data\\\\example\\\\image\\\\char\\\\'\n",
    "clip_file_name = '23_A-CD'\n",
    "b_number = 0\n",
    "n_number = 0\n",
    "\n",
    "files = os.listdir(clip_path)\n",
    "# files = ['360n4s_17_T-.jpg',]\n",
    "start_time = time.time()\n",
    "for file in files:\n",
    "    clip_file_name = file.split('.')[0]\n",
    "    print(clip_file_name)\n",
    "#     image = cv2.imread('{}{}.jpg'.format(clip_path,clip_file_name),cv2.IMREAD_COLOR)\n",
    "    with open('{}{}.jpg'.format(clip_path,clip_file_name),'rb') as ff:\n",
    "        imgbin = ff.read()\n",
    "    \n",
    "    imgbin = np.frombuffer(imgbin, np.uint8)    \n",
    "    image = cv2.imdecode(imgbin,cv2.IMREAD_COLOR)\n",
    "    \n",
    "#     print(image.shape)\n",
    "    cnts = get_char_rect(image)\n",
    "    cnts_array = np.array(cnts)\n",
    "    cnts_inx = np.lexsort([cnts_array[:,1]])\n",
    "    cnts_array = cnts_array[cnts_inx]\n",
    "    cnts = cnts_array.tolist()\n",
    "    if len(cnts) < (len(clip_file_name.split('_')[-1])):\n",
    "        raise Exception('{} 切割失败 切割长度 {} 最少长度 {}'.format(clip_file_name,len(cnts), \n",
    "                                                         (len(clip_file_name.split('_')[-1]) + 1)))\n",
    "    \n",
    "    binx = [idx for idx,x in enumerate(clip_file_name.split('_')[-1]) if x =='-']\n",
    "    # 取坐标后几位\n",
    "    cnts = cnts[len(cnts)-len(clip_file_name.split('_')[-1]):]\n",
    "    for i, (y,x,h,w) in enumerate(cnts):\n",
    "        crop_img = image[y:y+h,x:x+w]\n",
    "        if i in binx:\n",
    "            cv2.imwrite('{}1_{}.jpg'.format(clip_save_path,b_number),crop_img)\n",
    "            b_number = b_number + 1\n",
    "        else:\n",
    "            cv2.imwrite('{}0_{}.jpg'.format(clip_save_path,n_number),crop_img)\n",
    "            n_number = n_number + 1\n",
    "        \n",
    "\n",
    "print('total files {}  time {:.4f}'.format(len(files),(time.time() - start_time)))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     6,
     19,
     25
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written 1000 / 3158\n",
      "Written 2000 / 3158\n",
      "Written 3000 / 3158\n",
      "Created dataset with 3158 samples\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/pytorch/vision/issues/81\n",
    "\n",
    "# 将图片数据写入到LMDB数据库存中\n",
    "\n",
    "import lmdb\n",
    "import glob\n",
    "# 创建数据库\n",
    "# import lmdb  # install lmdb by \"pip install lmdb\"\n",
    "# env = lmdb.open('./data/lmdb', map_size=511627776)\n",
    "# env = lmdb.open('./data/lmdb', map_size=511627776)\n",
    "# from genLineText import GenTextImage\n",
    "def checkImageIsValid(imageBin):\n",
    "    if imageBin is None:\n",
    "        return False\n",
    "    \n",
    "    imageBuf = np.frombuffer(imageBin, dtype=np.uint8)\n",
    "    img = cv2.imdecode(imageBuf, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        return False\n",
    "    imgH, imgW = img.shape[0], img.shape[1]\n",
    "    if imgH * imgW == 0:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def writeCache(env, cache):\n",
    "    with env.begin(write=True) as txn:\n",
    "        for k, v in cache.items():\n",
    "            txn.put(k.encode(), v)\n",
    "            \n",
    "def createDataset(outputPath, imagePathList, labelList, lexiconList=None, checkValid=True):\n",
    "    \"\"\"\n",
    "    Create LMDB dataset for CRNN training.\n",
    "    ARGS:\n",
    "        outputPath    : LMDB output path\n",
    "        imagePathList : list of image path\n",
    "        labelList     : list of corresponding groundtruth texts\n",
    "        lexiconList   : (optional) list of lexicon lists\n",
    "        checkValid    : if true, check the validity of every image\n",
    "    \"\"\"\n",
    "    # print (len(imagePathList) , len(labelList))\n",
    "    assert (len(imagePathList) == len(labelList))\n",
    "    nSamples = len(imagePathList)\n",
    "    \n",
    "    env = lmdb.open(outputPath, map_size=511627776)\n",
    "\n",
    "    cache = {}\n",
    "    cnt = 1\n",
    "    for i in range(nSamples):\n",
    "        imagePath = imagePathList[i]\n",
    "        label = labelList[i]\n",
    "        if not os.path.exists(imagePath):\n",
    "            print('%s does not exist' % imagePath)\n",
    "            continue\n",
    "        with open(imagePath, 'rb') as f:\n",
    "            imageBin = f.read()\n",
    "        \n",
    "        if checkValid:\n",
    "            if not checkImageIsValid(imageBin):\n",
    "                print('%s is not a valid image' % imagePath)\n",
    "                continue\n",
    "\n",
    "        imageKey = 'image-%09d' % cnt\n",
    "        labelKey = 'label-%09d' % cnt\n",
    "        cache[imageKey] = imageBin\n",
    "        cache[labelKey] = label.encode()\n",
    "        if lexiconList:\n",
    "            lexiconKey = 'lexicon-%09d' % cnt\n",
    "            cache[lexiconKey] = ' '.join(lexiconList[i]).encode()\n",
    "        if cnt % 1000 == 0:\n",
    "            writeCache(env, cache)\n",
    "            cache = {}\n",
    "            print('Written %d / %d' % (cnt, nSamples))\n",
    "        cnt += 1\n",
    "    nSamples = cnt - 1\n",
    "    cache['num-samples'] = str(nSamples).encode()\n",
    "    writeCache(env, cache)\n",
    "    print('Created dataset with %d samples' % nSamples)\n",
    "\n",
    "\n",
    "def read_text(path):\n",
    "    with open(path) as f:\n",
    "        text = f.read()\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# outputPath = './data/lmdb/train'   # 训练数据\n",
    "outputPath = 'D:\\\\PROJECT_TW\\\\git\\\\data\\\\example\\\\lmdb'   # 测试数据\n",
    "path = 'D:\\\\PROJECT_TW\\\\git\\\\data\\\\example\\\\image\\\\char\\\\*.jpg'\n",
    "imagePathList = glob.glob(path)\n",
    "imgLabelLists = []\n",
    "for p in imagePathList:\n",
    "    try:\n",
    "        label = p.split('\\\\')[-1].split('_')[0]\n",
    "        imgLabelLists.append((p,label))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "imgLabelList = sorted(imgLabelLists, key=lambda x: len(x[1]))\n",
    "imgPaths = [p[0] for p in imgLabelList]\n",
    "txtLists = [p[1] for p in imgLabelList]\n",
    "createDataset(outputPath, imgPaths, txtLists, lexiconList=None, checkValid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "# 注意 dataset.alignCollate 将图片转成了灰度图，后期看怎么修改一下。\n",
    "# collate_fn，是用来处理不同情况下的输入dataset的封装，一般采用默认即可，除非你自定义的数据读取输出非常少见\n",
    "import common.dataset as dataset\n",
    "path = 'D:\\\\PROJECT_TW\\\\git\\\\data\\\\example\\\\lmdb'\n",
    "train_dataset = dataset.lmdbDataset(root=path, transform=dataset.resizeNormalize((32,32)))\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=100,\n",
    "    shuffle=True,\n",
    "    sampler=None\n",
    "#     collate_fn=dataset.alignCollate(imgH=32, imgW=32, keep_ratio=False)\n",
    ")\n",
    "\n",
    "# dataset 方法resizeNormalize 中用了transforms.ToTensor 会将数据做归一化处理，在正式用的时候也需要将数据调用该方法做归一化处理\n",
    "\n",
    "# 可参看 https://blog.csdn.net/victoriaw/article/details/72822005 数据预处理torchvision.transforms \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1578\n"
     ]
    }
   ],
   "source": [
    "for idx,v in enumerate(train_loader):\n",
    "#     print(idx,v)\n",
    "#     print(v)\n",
    "    pass\n",
    "# print(v)\n",
    "print(idx)\n",
    "# print(np.array(v[0]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_1 = nn.Sequential(         # input shape (1, 32, 32)\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,              # input height\n",
    "                out_channels=16,            # n_filters\n",
    "                kernel_size=5,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=2,                  # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (16, 28, 28)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 16, 16)\n",
    "        )        \n",
    "        \n",
    "        self.conv_2 = nn.Sequential(         # input shape (16, 16, 16)\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     # output shape (32, 16, 16)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 8, 8)\n",
    "        )        \n",
    "        \n",
    "        self.out = nn.Linear(32 * 8 * 8, 2)   # fully connected layer, output 2 classes\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = x.view(x.size(0), -1)           # flatten the output of conv2 to (batch_size, 32 * 8 * 8)\n",
    "        output = self.out(x)\n",
    "        return output       # return x for visualization    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --> 0  loss : 0.27270165\n",
      "loss --> 0.1460\n",
      "1 --> 0  loss : 0.14705318\n",
      "2 --> 0  loss : 0.09346888\n",
      "3 --> 0  loss : 0.07818905\n",
      "4 --> 0  loss : 0.08490984\n",
      "5 --> 0  loss : 0.04774324\n",
      "6 --> 0  loss : 0.03185656\n",
      "7 --> 0  loss : 0.01841942\n",
      "8 --> 0  loss : 0.01615721\n",
      "9 --> 0  loss : 0.01287981\n",
      "10 --> 0  loss : 0.00671923\n",
      "11 --> 0  loss : 0.01088424\n",
      "12 --> 0  loss : 0.00874346\n",
      "13 --> 0  loss : 0.00457397\n",
      "14 --> 0  loss : 0.00618647\n",
      "15 --> 0  loss : 0.00769486\n",
      "16 --> 0  loss : 0.00346732\n",
      "17 --> 0  loss : 0.00188480\n",
      "18 --> 0  loss : 0.00185975\n",
      "19 --> 0  loss : 0.00235405\n",
      "20 --> 0  loss : 0.00162395\n",
      "21 --> 0  loss : 0.00395346\n",
      "22 --> 0  loss : 0.00271449\n",
      "23 --> 0  loss : 0.00133114\n",
      "24 --> 0  loss : 0.00168175\n",
      "25 --> 0  loss : 0.00195039\n",
      "26 --> 0  loss : 0.00120667\n",
      "27 --> 0  loss : 0.00113640\n",
      "28 --> 0  loss : 0.00157883\n",
      "29 --> 0  loss : 0.00246879\n",
      "30 --> 0  loss : 0.00089439\n",
      "31 --> 0  loss : 0.00161752\n",
      "32 --> 0  loss : 0.00064279\n",
      "33 --> 0  loss : 0.00043792\n",
      "34 --> 0  loss : 0.00102361\n",
      "35 --> 0  loss : 0.00147198\n",
      "36 --> 0  loss : 0.00115987\n",
      "37 --> 0  loss : 0.00132111\n",
      "38 --> 0  loss : 0.00295927\n",
      "39 --> 0  loss : 0.00224146\n",
      "40 --> 0  loss : 0.00072537\n",
      "41 --> 0  loss : 0.00123838\n",
      "42 --> 0  loss : 0.00322697\n",
      "43 --> 0  loss : 0.00060848\n",
      "44 --> 0  loss : 0.00070321\n",
      "45 --> 0  loss : 0.00106288\n",
      "46 --> 0  loss : 0.00058867\n",
      "47 --> 0  loss : 0.00025970\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "src data type = 17 is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-c3f708a2fe30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# 二分类，target 在做损失的时候需要（0，1），（1，0）这样的格式\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\project_tw\\anly\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\project_tw\\anly\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\PROJECT_TW\\git\\myproject\\imagehandle\\common\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m                 \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_RGB2BGR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;31m#                 print(img)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: src data type = 17 is not supported"
     ]
    }
   ],
   "source": [
    "# https://blog.csdn.net/tianweidadada/article/details/82630735   用 pytorch 进行分类（二分类，多分类）\n",
    "net = CNN()\n",
    "opitmizer = torch.optim.SGD(net.parameters(),lr=0.01)\n",
    "loss_fun = nn.MSELoss() \n",
    "epoches = 1000\n",
    "\n",
    "\n",
    "for i in range(epoches):\n",
    "    for step, values in enumerate(train_loader):\n",
    "        images = values[0]\n",
    "        # 二分类，target 在做损失的时候需要（0，1），（1，0）这样的格式\n",
    "        target = [ [1-int(x),int(x) ] for x in values[1]]\n",
    "        target =  Variable(torch.FloatTensor(target)) #变成 1*2的 tensor\n",
    "        preds = F.softmax(net(images),dim=1)\n",
    "        loss = loss_fun(preds,target)\n",
    "        opitmizer.zero_grad()\n",
    "        loss.backward()\n",
    "        opitmizer.step()\n",
    "        if step % 100 == 0:\n",
    "            print('{} --> {}  loss : {:.8f}'.format(i, step, loss))\n",
    "    if i%100 == 0:\n",
    "        print('loss --> {:.4f}'.format(loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "tensor([[ 0.0089,  0.9911]])\n",
      "time --> 0.007995367050170898\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms \n",
    "import time\n",
    "path = 'D:\\\\PROJECT_TW\\\\git\\\\data\\\\example\\\\image\\\\char\\\\1_447.jpg'\n",
    "image = cv2.imread(path,cv2.IMREAD_COLOR)    \n",
    "if image.shape[0] != 32 or image.shape[1] != 32:\n",
    "    image = cv2.resize(image,(32,32))\n",
    "# aa[np.newaxis,:].shape, newaxis增加维度\n",
    "# np.r_[bb,bb].shape 添加行数据\n",
    "# image = image[np.newaxis,:]\n",
    "print(image.shape)\n",
    "\n",
    "start_time = time.time()\n",
    "for _ in range(1):\n",
    "\n",
    "    imdata = transforms.ToTensor()(image)\n",
    "    imdata = imdata.unsqueeze(0)\n",
    "#     print(imdata.size())\n",
    "    preds = net(imdata)\n",
    "    preds = F.softmax(preds,dim=1)\n",
    "    print(preds)\n",
    "    \n",
    "print('time --> {}'.format((time.time()-start_time)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

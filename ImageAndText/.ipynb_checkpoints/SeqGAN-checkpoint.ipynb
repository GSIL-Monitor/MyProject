{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 基本说明 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "    https://cloud.tencent.com/developer/article/1162834\n",
    "    https://www.zhihu.com/question/52602529/answer/155743699\n",
    "    https://github.com/ZiJianZhao/SeqGAN-PyTorch\n",
    "    https://github.com/ChenChengKuan/SeqGAN_tensorflow\n",
    "    https://github.com/suragnair/seqGAN\n",
    "    \n",
    "    https://baike.baidu.com/item/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/3350286?fr=aladdin  MLE 极大似然估计\n",
    "    \n",
    "    http://www.eeworld.com.cn/mp/QbitAI/a53664.jspx 韩国小哥哥用Pytorch实现谷歌最强NLP预训练模型BERT | 代码\n",
    "    \n",
    "    https://blog.csdn.net/zhl493722771/article/details/82781914 令人拍案叫绝的WGAN\n",
    "    \n",
    "    https://www.colabug.com/2639033.html 对抗思想与强化学习的碰撞-SeqGAN模型原理和代码解析\n",
    "    \n",
    "    https://blog.csdn.net/Irving_zhang/article/details/79088143  实现基于seq2seq的聊天机器人\n",
    "    \n",
    "    https://www.leiphone.com/news/201709/QRJPQr3jCOtY7ncQ.html 如何让对抗网络GAN生成更高质量的文本？\n",
    "    \n",
    "    https://blog.csdn.net/Young_Gy/article/details/76474939  构建聊天机器人：检索、seq2seq、RL、SeqGAN\n",
    "    \n",
    "    https://blog.csdn.net/yinruiyang94/article/details/77675586 SeqGAN——对抗思想与增强学习的碰撞\n",
    "    \n",
    "    https://blog.csdn.net/qunnie_yi/article/details/80129851 只知道GAN你就OUT了——VAE背后的哲学思想及数学原理\n",
    "    \n",
    "    https://blog.csdn.net/GitChat/article/details/79081190 手把手教你写一个中文聊天机器人\n",
    "    \n",
    "    https://blog.csdn.net/tMb8Z9Vdm66wH68VX1/article/details/79184714 一文读懂智能对话系统\n",
    "    \n",
    "    https://blog.csdn.net/taoyafan/article/details/81229466#1%20%E4%BB%80%E4%B9%88%E6%98%AF%20Condition%20GAN  Condition GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 强化学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " https://www.cnblogs.com/steven-yang/p/6624253.html 强化学习读书笔记 - 13 - 策略梯度方法(Policy Gradient Methods)\n",
    " https://blog.csdn.net/aliceyangxi1987/article/details/73327378 一文了解强化学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     32
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "import argparse\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from lib.seqgan.generator import Generator\n",
    "from lib.seqgan.discriminator import Discriminator\n",
    "from lib.seqgan.target_lstm import TargetLSTM\n",
    "from lib.seqgan.rollout import Rollout\n",
    "from lib.seqgan.data_iter import GenDataIter, DisDataIter\n",
    "opt = edict()\n",
    "opt.cuda = None\n",
    "# Basic Training Paramters\n",
    "SEED = 88\n",
    "BATCH_SIZE = 64\n",
    "TOTAL_BATCH = 200\n",
    "GENERATED_NUM = 100\n",
    "POSITIVE_FILE = 'real.data'\n",
    "NEGATIVE_FILE = 'gene.data'\n",
    "EVAL_FILE = 'eval.data'\n",
    "VOCAB_SIZE = 5000\n",
    "PRE_EPOCH_NUM = 120\n",
    "\n",
    "if opt.cuda is not None and opt.cuda >= 0:\n",
    "    torch.cuda.set_device(opt.cuda)\n",
    "    opt.cuda = True\n",
    "\n",
    "# Genrator Parameters\n",
    "g_emb_dim = 32\n",
    "g_hidden_dim = 32\n",
    "g_sequence_len = 20\n",
    "\n",
    "# Discriminator Parameters\n",
    "d_emb_dim = 64\n",
    "d_filter_sizes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]\n",
    "d_num_filters = [100, 200, 200, 200, 200, 100, 100, 100, 100, 100, 160, 160]\n",
    "\n",
    "d_dropout = 0.75\n",
    "d_num_class = 2\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def generate_samples(model, batch_size, generated_num, output_file):\n",
    "    samples = []\n",
    "    for _ in range(int(generated_num / batch_size)):\n",
    "        sample = model.sample(batch_size, g_sequence_len).cpu().data.numpy().tolist()\n",
    "        samples.extend(sample)\n",
    "    with open(output_file, 'w') as fout:\n",
    "        for sample in samples:\n",
    "            string = ' '.join([str(s) for s in sample])\n",
    "            fout.write('%s\\n' % string)\n",
    "\n",
    "target_lstm = TargetLSTM(VOCAB_SIZE, g_emb_dim, g_hidden_dim, opt.cuda)\n",
    "print('Generating data ...')\n",
    "generate_samples(target_lstm, BATCH_SIZE, GENERATED_NUM, POSITIVE_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

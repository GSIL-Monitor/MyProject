{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# AutoEncoder自动编码器\n",
    "\n",
    "在自动编码器主要应用有两个方面，第一是数据去噪，第二是进行可视化降维。然而自动编码器还有着一个功能就是生成数据。(https://www.leiphone.com/news/201707/7PjloKpQx1ljroGw.html)\n",
    "\n",
    "1、可以通过这些特征，再采用SVM, KNN等方式对数据进行分类  https://blog.csdn.net/on2way/article/details/50395055（自编码网络与PCA特征学习的分类对比实验）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "# 超参数\n",
    "EPOCH = 10\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.005\n",
    "DOWNLOAD_MNIST = True   # 下过数据的话, 就可以设置成 False\n",
    "N_TEST_IMG = 5          # 到时候显示 5张图片看效果, 如上图一\n",
    "\n",
    "# Mnist digits dataset\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,                                     # this is training data\n",
    "    transform=torchvision.transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                                    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,                        # download it if you don't have it\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "自编码、对抗、注意力模型 等等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# AutoEncoder自动编码器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "https://blog.csdn.net/sinat_27935693/article/details/53502656\n",
    "https://www.cnblogs.com/happylion/p/4209570.html     https://blog.csdn.net/llp1992/article/details/45579615。\n",
    "    Deep Learning最简单的一种方法是利用人工神经网络的特点，人工神经网络（ANN）本身就是具有层次结构的系统，如果给定一个神经网络，我们假设其输出与输入是相同的，然后训练调整其参数，得到每一层中的权重。自然地，我们就得到了输入I的几种不同表示（每一层代表一种表示），这些表示就是特征。自动编码器就是一种尽可能复现输入信号的神经网络。为了实现这种复现，自动编码器就必须捕捉可以代表输入数据的最重要的因素，就像PCA(数据降维)那样，找到可以代表原信息的主要成分。\n",
    "    \n",
    "    \n",
    "具体过程简单的说明如下：\n",
    "\n",
    "![Image of Yaktocat](http://img.my.csdn.net/uploads/201304/09/1365439723_4504.jpg)\n",
    "\n",
    "在我们之前的神经网络中，如第一个图，我们输入的样本是有标签的，即（input, target），这样我们根据当前输出和target（label）之间的差去改变前面各层的参数，直到收敛。但现在我们只有无标签数据，也就是右边的图。那么这个误差怎么得到呢？\n",
    "\n",
    "![Image of Yaktocat](http://img.my.csdn.net/uploads/201304/09/1365439745_1862.jpg)\n",
    "\n",
    "\n",
    "  如上图，我们将input输入一个encoder编码器，就会得到一个code，这个code也就是输入的一个表示，那么我们怎么知道这个code表示的就是input呢？我们加一个decoder解码器，这时候decoder就会输出一个信息，那么如果输出的这个信息和一开始的输入信号input是很像的（理想情况下就是一样的），那很明显，我们就有理由相信这个code是靠谱的。所以，我们就通过调整encoder和decoder的参数，使得重构误差最小，这时候我们就得到了输入input信号的第一个表示了，也就是编码code了。因为是无标签数据，所以误差的来源就是直接重构后与原输入相比得到。\n",
    "  \n",
    "  2）通过编码器产生特征，然后训练下一层。这样逐层训练：\n",
    "  \n",
    "  那上面我们就得到第一层的code，我们的重构误差最小让我们相信这个code就是原输入信号的良好表达了，或者牵强点说，它和原信号是一模一样的（表达不一样，反映的是一个东西）。那第二层和第一层的训练方式就没有差别了，我们将第一层输出的code当成第二层的输入信号，同样最小化重构误差，就会得到第二层的参数，并且得到第二层输入的code，也就是原输入信息的第二个表达了。其他层就同样的方法炮制就行了（训练这一层，前面层的参数都是固定的，并且他们的decoder已经没用了，都不需要了）。\n",
    "    \n",
    "  3）有监督微调：\n",
    "    经过上面的方法，我们就可以得到很多层了。至于需要多少层（或者深度需要多少，这个目前本身就没有一个科学的评价方法）需要自己试验调了。每一层都会得到原始输入的不同的表达。当然了，我们觉得它是越抽象越好了，就像人的视觉系统一样。\n",
    "    到这里，这个AutoEncoder还不能用来分类数据，因为它还没有学习如何去连结一个输入和一个类。它只是学会了如何去重构或者复现它的输入而已。或者说，它只是学习获得了一个可以良好代表输入的特征，这个特征可以最大程度上代表原输入信号。那么，为了实现分类，我们就可以在AutoEncoder的最顶的编码层添加一个分类器（例如罗杰斯特回归、SVM等），然后通过标准的多层神经网络的监督训练方法（梯度下降法）去训练。\n",
    "    也就是说，这时候，我们需要将最后层的特征code输入到最后的分类器，通过有标签样本，通过监督学习进行微调，这也分两种，一个是只调整分类器（黑色部分）：\n",
    "    ![Image of Yaktocat](http://img.my.csdn.net/uploads/201304/09/1365439852_7450.jpg)\n",
    "    \n",
    "   一旦监督训练完成，这个网络就可以用来分类了。神经网络的最顶层可以作为一个线性分类器，然后我们可以用一个更好性能的分类器去取代它。\n",
    "\n",
    "   在研究中可以发现，如果在原有的特征中加入这些自动学习得到的特征可以大大提高精确度，甚至在分类问题中比目前最好的分类算法效果还要好！\n",
    "\n",
    "   AutoEncoder存在一些变体，这里简要介绍下两个：\n",
    "   \n",
    "   A) Sparse AutoEncoder稀疏自动编码器：\n",
    "   当然，我们还可以继续加上一些约束条件得到新的Deep Learning方法，如：如果在AutoEncoder的基础上加上L1的Regularity限制（L1主要是约束每一层中的节点中大部分都要为0，只有少数不为0，这就是Sparse名字的来源），我们就可以得到Sparse AutoEncoder法。\n",
    "   ![Image of Yaktocat](http://img.my.csdn.net/uploads/201304/09/1365439878_3585.jpg)\n",
    "   如上图，其实就是限制每次得到的表达code尽量稀疏。因为稀疏的表达往往比其他的表达要有效（人脑好像也是这样的，某个输入只是刺激某些神经元，其他的大部分的神经元是受到抑制的）。\n",
    "   b) Denoising AutoEncoders降噪自动编码器：\n",
    "   降噪自动编码器DA是在自动编码器的基础上，训练数据加入噪声，所以自动编码器必须学习去去除这种噪声而获得真正的没有被噪声污染过的输入。因此，这就迫使编码器去学习输入信号的更加鲁棒的表达，这也是它的泛化能力比一般编码器强的原因。DA可以通过梯度下降算法去训练。\n",
    "   ![Image of Yaktocat](http://img.my.csdn.net/uploads/201304/09/1365439902_7892.jpg)\n",
    "   2、Sparse Coding稀疏编码\n",
    "    如果我们把输出必须和输入相等的限制放松，同时利用线性代数中基的概念，即O = a1*Φ1 + a2*Φ2+….+ an*Φn， Φi是基，ai是系数，我们可以得到这样一个优化问题：\n",
    "\n",
    "     Min |I – O|，其中I表示输入，O表示输出。\n",
    "     \n",
    "     通过求解这个最优化式子，我们可以求得系数ai和基Φi，\n",
    "     它们可以用来表达输入I，这个过程也是自动学习得到的。如果我们在上述式子上加上L1的Regularity限制，得到：\n",
    "\n",
    "      Min |I – O| + u*(|a1| + |a2| + … + |an |)\n",
    "\n",
    "        这种方法被称为Sparse Coding。通俗的说，就是将一个信号表示为一组基的线性组合，而且要求只需要较少的几个基就可以将信号表示出来。“稀疏性”定义为：只有很少的几个非零元素或只有很少的几个远大于零的元素。要求系数 ai 是稀疏的意思就是说：对于一组输入向量，我们只想有尽可能少的几个系数远大于零。选择使用具有稀疏性的分量来表示我们的输入数据是有原因的，因为绝大多数的感官数据，比如自然图像，可以被表示成少量基本元素的叠加，在图像中这些基本元素可以是面或者线。同时，比如与初级视觉皮层的类比过程也因此得到了提升（人脑有大量的神经元，但对于某些图像或者边缘只有很少的神经元兴奋，其他都处于抑制状态）。\n",
    "\n",
    "         稀疏编码算法是一种无监督学习方法，它用来寻找一组“超完备”基向量来更高效地表示样本数据。虽然形如主成分分析技术（PCA）能使我们方便地找到一组“完备”基向量，但是这里我们想要做的是找到一组“超完备”基向量来表示输入向量（也就是说，基向量的个数比输入向量的维数要大）。超完备基的好处是它们能更有效地找出隐含在输入数据内部的结构与模式。然而，对于超完备基来说，系数ai不再由输入向量唯一确定。因此，在稀疏编码算法中，我们另加了一个评判标准“稀疏性”来解决因超完备而导致的退化（degeneracy）问题。（详细过程请参考：UFLDL Tutorial稀疏编码）\n",
    "![Image of Yaktocat](http://img.my.csdn.net/uploads/201304/09/1365483386_5095.jpg)       \n",
    " 比如在图像的Feature Extraction的最底层要做Edge Detector的生成，那么这里的工作就是从Natural Images中randomly选取一些小patch，通过这些patch生成能够描述他们的“基”，也就是右边的8*8=64个basis组成的basis，然后给定一个test patch, 我们可以按照上面的式子通过basis的线性组合得到，而sparse matrix就是a，下图中的a中有64个维度，其中非零项只有3个，故称“sparse”。\n",
    "\n",
    "       这里可能大家会有疑问，为什么把底层作为Edge Detector呢？上层又是什么呢？这里做个简单解释大家就会明白，之所以是Edge Detector是因为不同方向的Edge就能够描述出整幅图像，所以不同方向的Edge自然就是图像的basis了……而上一层的basis组合的结果，上上层又是上一层的组合basis……（就是上面第四部分的时候咱们说的那样）\n",
    "\n",
    "       Sparse coding分为两个部分：\n",
    "\n",
    "1）Training阶段：给定一系列的样本图片[x1, x 2, …]，我们需要学习得到一组基[Φ1, Φ2, …]，也就是字典。\n",
    "\n",
    "       稀疏编码是k-means算法的变体，其训练过程也差不多（EM算法的思想：如果要优化的目标函数包含两个变量，如L(W, B)，那么我们可以先固定W，调整B使得L最小，然后再固定B，调整W使L最小，这样迭代交替，不断将L推向最小值。EM算法可以见我的博客：“从最大似然到EM算法浅解”）。\n",
    "\n",
    "       训练过程就是一个重复迭代的过程，按上面所说，我们交替的更改a和Φ使得下面这个目标函数最小。\n",
    "![Image of Yaktocat](http://img.my.csdn.net/uploads/201304/09/1365483429_5706.jpg)  \n",
    "每次迭代分两步：\n",
    "\n",
    "a）固定字典Φ[k]，然后调整a[k]，使得上式，即目标函数最小（即解LASSO问题）。\n",
    "\n",
    "b）然后固定住a [k]，调整Φ [k]，使得上式，即目标函数最小（即解凸QP问题）。\n",
    "\n",
    "      不断迭代，直至收敛。这样就可以得到一组可以良好表示这一系列x的基，也就是字典。\n",
    "\n",
    "2）Coding阶段：给定一个新的图片x，由上面得到的字典，通过解一个LASSO问题得到稀疏向量a。这个稀疏向量就是这个输入向量x的一个稀疏表达了。\n",
    "![Image of Yaktocat](http://img.my.csdn.net/uploads/201304/09/1365483491_9524.jpg)\n",
    "\n",
    "\n",
    "........., 请再看https://blog.csdn.net/sinat_27935693/article/details/53502656\n",
    "\n",
    "Pytorch 实现自编码\n",
    "https://morvanzhou.github.io/tutorials/machine-learning/torch/4-04-autoencoder/\n",
    "AutoEncoder 形式很简单, 分别是 encoder 和 decoder, 压缩和解压, 压缩后得到压缩的特征值, 再从压缩的特征值解压成原图片."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        # 压缩\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(12, 3),   # 压缩成3个特征, 进行 3D 图像可视化\n",
    "        )\n",
    "        # 解压\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 28*28),\n",
    "            nn.Sigmoid(),       # 激励函数让输出值在 (0, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "autoencoder = AutoEncoder()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "训练\n",
    "\n",
    "训练, 并可视化训练的过程. 我们可以有效的利用 encoder 和 decoder 来做很多事, 比如这里我们用 decoder 的信息输出看和原图片的对比, 还能用 encoder 来看经过压缩后, 神经网络对原图片的理解. encoder 能将不同图片数据大概的分离开来. 这样就是一个无监督学习的过程."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.2784,  0.3569,  0.3569,  0.3569,  0.5216,\n",
      "           1.0000,  0.7882,  0.3451,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0902,  0.7059,  0.9294,  0.9922,  0.9922,  0.9922,  0.9922,\n",
      "           0.9922,  0.9922,  0.9843,  0.7059,  0.2314,  0.0353,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.7059,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,\n",
      "           0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.7294,  0.0824,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.7059,  0.9922,  0.9922,  0.9922,  0.9647,  0.8627,  0.8627,\n",
      "           0.8627,  0.9882,  0.9922,  0.9922,  0.9922,  0.9922,  0.1882,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.7059,  0.9922,  0.9294,  0.5059,  0.4118,  0.0000,  0.0000,\n",
      "           0.0000,  0.9647,  0.9922,  0.9922,  0.9922,  0.7725,  0.0980,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.6941,  0.5255,  0.1373,  0.0000,  0.0000,  0.0000,  0.1765,\n",
      "           0.1961,  0.9725,  0.9922,  0.9922,  0.9725,  0.4392,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.2902,  0.0000,  0.0000,  0.0000,  0.0000,  0.3059,  0.9529,\n",
      "           0.9922,  0.9922,  0.9922,  0.9922,  0.5373,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.3451,  0.9529,  0.9922,\n",
      "           0.9922,  0.9922,  0.9843,  0.4863,  0.0235,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.3020,  0.9333,  0.9922,  0.9922,\n",
      "           0.9922,  0.9922,  0.5608,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.3373,  0.9765,  0.9922,  0.9922,  0.9922,\n",
      "           0.9922,  0.4706,  0.0118,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.7725,  0.9922,  0.9922,  0.9922,  0.9843,\n",
      "           0.5608,  0.0118,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.1647,  0.8588,  0.9922,  0.9922,  0.9922,  0.4863,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0078,  0.4784,  0.9922,  0.9922,  0.9725,  0.8941,  0.0824,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.3608,  0.9922,  0.9922,  0.9922,  0.7961,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.7059,  0.9922,  0.9922,  0.9922,  0.2784,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.1137,  0.1647,  0.2275,  0.8039,  0.6980,\n",
      "           0.1647,  0.1255,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1882,\n",
      "           0.8549,  0.9922,  0.9922,  0.9922,  0.5882,  0.5137,  0.5137,\n",
      "           0.5137,  0.5137,  0.8392,  0.9922,  0.9922,  0.9922,  0.9922,\n",
      "           0.9922,  0.8824,  0.5137,  0.0314,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2745,\n",
      "           0.9255,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,\n",
      "           0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,\n",
      "           0.9922,  0.9922,  0.9922,  0.6235,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.7059,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,\n",
      "           0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,\n",
      "           0.9922,  0.9922,  0.9922,  0.7020,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.5176,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,\n",
      "           0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.9922,  0.7569,\n",
      "           0.7020,  0.1412,  0.0588,  0.0431,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0235,  0.3490,  0.8510,  0.9922,  0.9922,  0.9922,  0.4078,\n",
      "           0.3490,  0.3490,  0.3490,  0.3490,  0.3490,  0.3490,  0.0667,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "# plot one example\n",
    "print(train_data.train_data.size()) # (60000, 28, 28)\n",
    "print(train_data.train_labels.size()) # (60000)\n",
    "\n",
    "plt.imshow(train_data.train_data[2].numpy(), cmap='gray')\n",
    "\n",
    "plt.title('%i' % train_data.train_labels[2])\n",
    "plt.show()\n",
    "# print(train_data.train_data[2].numpy())\n",
    "\n",
    "# train_data = torchvision.datasets.MNIST(\n",
    "#     root='./mnist/',\n",
    "#     train=True,                                     # this is training data\n",
    "#     transform=torchvision.transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "#                                                     # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "#     download=DOWNLOAD_MNIST,                        # download it if you don't have it\n",
    "# )\n",
    "\n",
    "# DataLoader 自动对数据做了归一化处理 , train_data 指定了  transform\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "_,(x,y) = next(enumerate(train_loader))\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\project_tw\\anly\\venv\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.2328\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x144 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.2326\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.2326\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.2325\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.2336\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.2317\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.2326\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.2322\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-c44cdb8d454d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mb_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# batch x, shape (batch, 28*28)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mb_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# batch y, shape (batch, 28*28)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\project_tw\\anly\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\project_tw\\anly\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\project_tw\\anly\\venv\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\project_tw\\anly\\venv\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \"\"\"\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\project_tw\\anly\\venv\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mnchannel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnchannel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;31m# yikes, this transpose takes 80% of the loading time/CPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialize figure\n",
    "f, a = plt.subplots(2, N_TEST_IMG, figsize=(5, 2))\n",
    "plt.ion()   # continuously plot\n",
    "\n",
    "# original data (first row) for viewing\n",
    "\n",
    "view_data = Variable(train_data.train_data[:N_TEST_IMG].view(-1, 28*28).type(torch.FloatTensor)/255.)  # 训练图片值将在0到1之间\n",
    "for i in range(N_TEST_IMG):\n",
    "    a[0][i].imshow(np.reshape(view_data.data.numpy()[i], (28, 28)), cmap='gray'); a[0][i].set_xticks(()); a[0][i].set_yticks(())\n",
    "\n",
    "for epoch in range(5):\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        \n",
    "        b_x = Variable(x.view(-1, 28*28))   # batch x, shape (batch, 28*28)\n",
    "        b_y = Variable(x.view(-1, 28*28))   # batch y, shape (batch, 28*28)\n",
    "        b_label = Variable(y)               # batch label\n",
    "\n",
    "        encoded, decoded = autoencoder(b_x)\n",
    "\n",
    "        loss = loss_func(decoded, b_y)      # mean square error\n",
    "        optimizer.zero_grad()               # clear gradients for this training step\n",
    "        loss.backward()                     # backpropagation, compute gradients\n",
    "        optimizer.step()                    # apply gradients\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data[0].item())\n",
    "#            b print(b_y)\n",
    "            # plotting decoded image (second row)\n",
    "            _, decoded_data = autoencoder(view_data)\n",
    "            for i in range(N_TEST_IMG):\n",
    "                a[1][i].clear()\n",
    "                a[1][i].imshow(np.reshape(decoded_data.data.numpy()[i], (28, 28)), cmap='gray')\n",
    "                a[1][i].set_xticks(()); a[1][i].set_yticks(())\n",
    "            plt.draw(); plt.pause(0.05)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()\n",
    "\n",
    "# visualize in 3D plot\n",
    "view_data = Variable(train_data.train_data[:200].view(-1, 28*28).type(torch.FloatTensor)/255.)\n",
    "encoded_data, _ = autoencoder(view_data)\n",
    "# fig = plt.figure(2); ax = Axes3D(fig)\n",
    "# X, Y, Z 表示该图片的特征\n",
    "# X, Y, Z = encoded_data.data[:, 0].numpy(), encoded_data.data[:, 1].numpy(), encoded_data.data[:, 2].numpy()\n",
    "# values = train_data.train_labels[:200].numpy()\n",
    "# for x, y, z, s in zip(X, Y, Z, values):\n",
    "#     c = cm.rainbow(int(255*s/9)); ax.text(x, y, z, s, backgroundcolor=c)\n",
    "# ax.set_xlim(X.min(), X.max()); ax.set_ylim(Y.min(), Y.max()); ax.set_zlim(Z.min(), Z.max())\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0039,  0.4275,  0.5882,  0.9922,  0.9922,  1.0000,  0.9922,\n",
      "           0.9922,  0.9922,  1.0000,  0.9922,  0.9922,  0.9922,  0.2471,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2078,\n",
      "           0.6078,  0.9882,  0.9882,  0.9882,  0.9882,  0.9922,  0.9882,\n",
      "           0.9882,  0.9882,  0.8706,  0.7020,  0.7020,  0.3804,  0.4078,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2863,  0.9098,\n",
      "           0.9882,  0.9882,  0.9882,  0.9882,  0.9059,  0.8510,  0.8431,\n",
      "           0.7647,  0.2784,  0.1608,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.2471,  0.9294,  0.9882,\n",
      "           0.9882,  0.9882,  0.5020,  0.4235,  0.1804,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.9922,  0.9882,  0.9882,\n",
      "           0.9882,  0.3216,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.8275,  0.9882,  0.9882,\n",
      "           0.9882,  0.2863,  0.2039,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.3686,  0.9686,  0.9882,\n",
      "           0.9882,  0.9882,  0.9059,  0.6275,  0.1451,  0.0824,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.3647,  0.5020,\n",
      "           0.9882,  0.9882,  0.9882,  0.9882,  0.9882,  0.8118,  0.4078,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.4902,  0.6275,  0.9922,  1.0000,  0.9922,\n",
      "           0.9098,  0.1843,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0196,  0.4667,  0.8275,  0.9882,\n",
      "           0.9882,  0.9098,  0.6118,  0.2863,  0.0824,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1216,  0.2784,\n",
      "           0.7059,  0.9882,  0.9922,  0.9882,  0.7059,  0.0627,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0627,  0.4235,  0.6667,  0.9882,  0.9882,  0.7451,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.1647,  0.8706,  0.9922,  1.0000,\n",
      "           0.3843,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0039,  0.1647,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.5059,  0.8667,  0.9922,\n",
      "           0.7843,  0.2471,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0039,  0.8667,  0.1804,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1608,  0.9098,\n",
      "           0.9882,  0.8667,  0.0627,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0039,  0.9882,  0.8667,  0.5647,  0.2431,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.4275,\n",
      "           0.9882,  0.9882,  0.4235,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.6118,  0.9922,  0.9922,  1.0000,  0.5020,\n",
      "           0.1216,  0.0000,  0.0000,  0.0000,  0.0000,  0.2471,  0.6706,\n",
      "           0.9922,  0.9922,  0.4235,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.2039,  0.9059,  0.9882,  0.9922,  0.9882,\n",
      "           0.8902,  0.8510,  0.8549,  0.8510,  0.8510,  0.9294,  0.9922,\n",
      "           0.9882,  0.9882,  0.4235,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.2039,  0.6039,  0.9098,  0.9882,\n",
      "           0.9882,  0.9882,  0.9922,  0.9882,  0.9882,  0.9882,  0.9922,\n",
      "           0.9882,  0.8863,  0.1216,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1843,  0.4235,\n",
      "           0.5020,  0.9882,  0.9922,  0.9882,  0.9882,  0.9882,  0.9922,\n",
      "           0.8235,  0.3608,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "step,(x, y) = next(enumerate(train_loader))\n",
    "print(step)\n",
    "print(x[60])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 深度自编码器的应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "    https://blog.csdn.net/u010089444/article/details/52601193\n",
    "    \n",
    "    http://www.cnblogs.com/taojake-ML/p/6475422.html\n",
    "    \n",
    "    https://zhuanlan.zhihu.com/p/33088428  李宏毅机器学习2016 第十四讲 深度自编码器\n",
    "    \n",
    "    \n",
    "    https://zhuanlan.zhihu.com/p/28084477\n",
    "    \n",
    "    1、文本检索（Text Retrieval）\n",
    "    \n",
    "    一般的文本检索方法有向量空间模型（Vector Space Model），上图中蓝色的点代表的是文档（经过降维后），接着计算要查询的文档与其他的距离，选择较为接近，相似程度高的，但这个模型的好坏关键取决于向量化的好坏；单词包（Bag-of-word），通过建立一个词向量，若文档中存在某些词记1否则记0，然后再计算相似性，但此模型不能很好的表达语义层面。自编码器可以很好的实现文本搜索。具有相同主题的文档会有相近的code。\n",
    "    \n",
    "    \n",
    "    2、图像搜索（Image Search）\n",
    "    \n",
    "    3、预训练深度神经网络（Pre-training DNN）\n",
    "    在深度学习中，自编码器可用于在训练阶段开始前，确定权重矩阵W的初始值。神经网络中的权重矩阵W可看作是对输入的数据进行特征转换，即先将数据编码为另一种形式，然后在此基础上进行一系列学习。如果编码后的数据能够较为容易地通过解码恢复成原始数据，我们则认为W较好的保留了数据信息。但是现如今强大的计算能力，使得深度学习并不使用自编码来预训练。在大量无标签的数据情况下，深度自编码器仍然有一定作用。\n",
    "    \n",
    "    # https://www.linkedin.com/pulse/pre-trained-autoencoders-cnn-using-pytorch-zenodia-charpy\n",
    "    \n",
    "    4、Auto-decoder for CNN\n",
    "    在卷积神经网络中，也可以应用自编码器。CNN主要是卷积（Convolution）和池化（Pooling）操作。\n",
    "\n",
    "    因此相对应的就要有反卷积（Deconvolution）和反池化（Depooling）操作。\n",
    "\n",
    "    反池化很好理解，只需记住池化过程中的位置（最大值出现的地方），在反池化的过程中，将对应位置置相应的值，其余位置置0即可。指需对卷积后的结果进行填充（padding）再进行池化操作，所得值就是所谓的反卷积结果。\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  栈式自编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    https://www.cnblogs.com/neopenx/p/4378635.html\n",
    "    \n",
    "    https://github.com/ShayanPersonal/stacked-autoencoder-pytorch\n",
    "    \n",
    "    https://www.cnblogs.com/zyly/p/9078786.html 去噪自编码和栈式自编码\n",
    "    \n",
    "    https://blog.csdn.net/jmh1996/article/details/78695393\n",
    "    \n",
    "    栈式自编码神经网络(Stacked Autoencoder,SA)是自编码网络的一种使用方法，是一个由多层训练好的自编码器组成的神经网络。由于网络中的每一层都是单独训练而来，相当于都初始化了一个合理的数值。所以，这样的网络会更容易训练，并且有更快的收敛性及更高的准确度。\n",
    "\n",
    "    栈式自编码常常被用于预训练(初始化)深度神经网络之前的权重预训练步骤。例如，在一个分类问题上，可以按照从前向后的顺序执行每一层通过自编码器来训练，最终将网络中最深层的输出作为softmax分类器的输入特征，通过softmax层将其分开。\n",
    "    \n",
    "    栈式自编码器在深度学习中的意义\n",
    "    看到这里或许你会奇怪？为什么要这么麻烦，直接使用多层神经网络来训练不是也可以吗？在这里是为大家介绍的这种训练方法，更像是手动训练，之所以我们愿意这么麻烦，主要是因为有如下几个有点：\n",
    "\n",
    "    每一层都是单独训练，保证降维特征的可控性。\n",
    "    对于高维度的分类问题，一下拿出一套完整可用的模型相对来讲并不是容易的事，因为节点太多，参数太多，一味地增加深度只会使结果越来越不可控，成为彻底的黑盒，而使用栈式自编码器逐层降维，可以将复杂问题简单化，更容易完成任务。\n",
    "    任意深层，理论上是越深层的神经网络对现实的拟合度越高，但是传统的多层神经网络，由于使用的是误差反向传播方式，导致层越深，传播的误差越小，栈式自编码巧妙的绕过这个问题，直接使用降维后的特征值进行二次训练，可以任意层数的加深。\n",
    "    栈式自编码神经网络具有强大的表达能力和深度神经网络的所有优点，但是它通常能够获取到输入的\"层次型分组\"或者\"部分-整体分解\"结构，自编码器倾向于学习得到与样本相对应的低位向量，该向量可以更好地表示高维样本的数据特征。\n",
    "    如果网络输入的是图像，第一层会学习识别边，第二层会学习组合边，构成轮廓等，更高层会学习组合更形象的特征。例如：人脸识别，学习如何识别眼睛、鼻子、嘴等。\n",
    "    \n",
    "    1、为什么会引进自编码网络？\n",
    "\n",
    "    我们都是知道深度神经网络里面的网络一般是比较深的，在训练之初，模型参数的初始化对模型影响十分深远的。当初始化选的好时，模型可以很快的收敛，可以避开一些局部最优点。当初始化选的不好是，模型要么就收敛到局部最优的马鞍点，要么就是收敛的特别慢。\n",
    "\n",
    "    所以为了解决参数初始化的问题，Hinton大佬提出了使用大量的没label的数据来“无监督”算法逐层预训练网络的初值，再使用有label的数值来微调网络参数的算法。\n",
    "\n",
    "    也就是说白了：1.自编码网络的提出是为了预训练网络参数，给网络参数一个合适的初值 \n",
    "    \n",
    "    另外一个重要的原因来引进自编码网络的原因是：现实生活中，那些打好标签的数据其实是很少的，在有监督学习中 这些没有label是用不来的；可以我们又想用这些数据咋个办嘞？自编码网络就提供一种无监督聚类的能力\n",
    "    \n",
    "    2、逐层学习策略\n",
    "    \n",
    "    逐层学习就是一层一层的学习，这个是什么意思嘞？就是说将相邻的层级视为一个简单的只有2层的特别浅的神经网络，对于这种浅层神经网络先有的方法的可以很好的训练，浅层网络也没得深度网络所面临的梯度爆炸和衰减的麻烦事，然后再将逐层学习后的层级“迭”在一些形成深度神经网络，从来加快学习速率，提高网络的泛化能力。\n",
    "    \n",
    "    3、自编码网络\n",
    "    \n",
    "    自编码网络是浅层神经网络，它希望尽可能让输入和输出保持一致。自编码训练方式的”无监督“训练，其实它这个的无监督是指 自编码网络的训练集可以是那些没有打上label的数据，而不是我们通常意思上说的监督学习的监督（通常监督学习是把样本真实的label当做期望输出，并以此监督学习的过程）。\n",
    "    \n",
    "    4、深度堆栈自编码网络\n",
    "    \n",
    "    介绍了简单的自编码网络，下面我们将自编码网络复合起来组成一个复杂的网络。 我们在分类问题里面使用这个深度自编码网络。\n",
    "\n",
    "    深度堆栈自编码网络有两个设计和模型训练步骤。第一个是设计自编码网络进行初始化参数进行预先学习，第二个步骤是设计分类器，然后使用分类器利用第一步学习到的初始化参数对模型进行微调。\n",
    "    \n",
    "    数据集分成两个部分：一部分是有label的数据（很少），另外一部分是无label的数据（很大），他们记为： \n",
    "    有label的数据：T={(xi,yi),i=1,2,…,n}{(xi,yi),i=1,2,…,n}\\{ (x^{i},y^{i}),i=1,2,\\dots,n\\},其中yiyiy^{i}是第i个样本的label。 \n",
    "    没有label的数据：T2={(xi),i=1,2,…,m}{(xi),i=1,2,…,m}\\{ (x^{i}),i=1,2,\\dots,m\\} \n",
    "    两个数据集一共有m+n个样本。\n",
    "    \n",
    "    模型网络结构，预学习阶段一共L个隐层，每个隐层上的神经元数目为ni,i∈{1,2,3,…,L}ni,i∈{1,2,3,…,L}n_{i},i \\in \\{1,2,3,\\dots ,L\\}，每个隐层上的激活函数为σi,i∈{1,2,3,…,L}σi,i∈{1,2,3,…,L}\\sigma_{i},i \\in \\{1,2,3,\\dots, L \\};最后一个输出层使用softmax进行分类。\n",
    "\n",
    "    因为有L个隐层，所以一个会有L个浅层自编码神经网络。对于每一层的自编码网络： \n",
    "    Xl=σal(Wal×Xl−1+bal)Xl=σla(Wla×Xl−1+bla)X_{l}=\\sigma^{a} _{l}(W^{a}_{l} \\times X_{l-1}+b^{a}_{l}) \n",
    "    Xl−1^=σsl(Wsl×Xl+bsl)Xl−1^=σls(Wls×Xl+bls)\\hat{X_{l-1}}=\\sigma^{s} _{l}(W^{s}_{l} \\times X_{l}+b^{s}_{l}) \n",
    "    其中XlXlX_{l}是每一层自编码网络里面的隐层输出，X^l−1X^l−1\\hat X_{l-1}表示第l层自编码网络的输出，这个输出也就是上一层输入期望的输出。然后使用上面提到的自编码网络的学习方法进行学习。\n",
    "\n",
    "    之后我们只保留每一自编码层的分析阶段的参数：Wal和balWla和blaW^{a}_{l}和b^{a}_{l},直接丢弃合成阶段的参数：Wsl和bslWls和blsW^{s}_{l}和b^{s}_{l}进行完成的学习。把保留的参数当做最后网络的初始化参数，然后使用带标签的数据使用传统的神经网络的训练方法进行参数的微调即可\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "    https://www.cnblogs.com/skyfsm/p/6806246.html 基于深度学习的目标检测技术演进：R-CNN、Fast R-CNN、Faster R-CNN\n",
    "    \n",
    "    https://blog.csdn.net/u013293750/article/details/64904681 CNN+LSTM深度学习文字检测\n",
    "    \n",
    "    https://blog.csdn.net/forest_world/article/details/78566737 主流ocr算法：CNN+BLSTM+CTC架构\n",
    "    \n",
    "    https://blog.csdn.net/slade_ruan/article/details/78301842?utm_source=blogxgwz1 场景文本检测，CTPN tensorflow版本\n",
    "    \n",
    "    https://blog.csdn.net/Quincuntial/article/details/79475339?utm_source=blogxgwz1 CTPN论文翻译——中英文对照"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "    https://www.cnblogs.com/freeweb/p/6548208.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "    https://deepsense.ai/region-of-interest-pooling-in-tensorflow-example/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "    https://www.cnblogs.com/king-lps/p/9031568.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method imdb.default_roidb of <lib.datasets.pascal_voc.pascal_voc object at 0x000002D485B5AEF0>>\n",
      "voc_2007_trainval gt roidb loaded from D:\\PROJECT_TW\\git\\data\\voc_2007_trainval_gt_roidb.pkl\n"
     ]
    }
   ],
   "source": [
    "from lib.datasets.factory import get_imdb\n",
    "from lib.datasets.pascal_voc import pascal_voc\n",
    "from lib.roi_data_layer.roidb import prepare_roidb\n",
    "from lib.roi_data_layer.layer import RoIDataLayer\n",
    "\n",
    "\n",
    "imdb = pascal_voc('trainval', '2007')\n",
    "# roidb ROI框的坐标位置信息, 信息来源于Annotations目录下对图片的XML定义\n",
    "prepare_roidb(imdb)   #  为方便训练，在原roidb信息基础上增加象image等等信息\n",
    "roidb = imdb.roidb \n",
    "data_layer = RoIDataLayer(roidb, imdb.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "RPN_CHANNELS = 512\n",
    "TRUNCATED = False\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        self._predictions = {}\n",
    "        self._losses = {}\n",
    "        self._anchor_targets = {}\n",
    "        self._proposal_targets = {}\n",
    "        self._layers = {}\n",
    "        self._gt_image = None\n",
    "        self._act_summaries = {}\n",
    "        self._score_summaries = {}\n",
    "        self._event_summaries = {}\n",
    "        self._image_gt_summaries = {}\n",
    "        self._variables_to_fix = {}\n",
    "\n",
    "    def create_architecture(self, num_classes, tag=None,anchor_scales=(16,), anchor_ratios=(0.5, 1, 2)):\n",
    "        self._tag = tag\n",
    "        self._num_classes = num_classes\n",
    "        self._anchor_scales = anchor_scales\n",
    "        self._num_scales = len(anchor_scales)\n",
    "        self._anchor_ratios = anchor_ratios\n",
    "        self._num_ratios = len(anchor_ratios)\n",
    "        self._num_anchors = 4\n",
    "        assert tag != None\n",
    "        # Initialize layers\n",
    "        self._init_modules()\n",
    "        \n",
    "    def _init_modules(self):\n",
    "        self._init_head_tail()\n",
    "        # rpn\n",
    "        self.rpn_net = nn.Conv2d(self._net_conv_channels, RPN_CHANNELS, [3, 3], padding=1)\n",
    "        self.rpn_bi_net = nn.LSTM(RPN_CHANNELS, 256, batch_first=True, bidirectional=True)\n",
    "        self.rpn_cls_score_net = nn.LSTM(RPN_CHANNELS, self._num_anchors * 2, batch_first=True, bidirectional=False)\n",
    "        self.rpn_bbox_pred_net = nn.LSTM(RPN_CHANNELS, self._num_anchors * 4, batch_first=True, bidirectional=False)\n",
    "        self.init_weights()    \n",
    "        \n",
    "    # 对构建的网络参数（weight, bias）进行正则、初始化\n",
    "    def init_weights(self):\n",
    "        def normal_init(m, mean, stddev, truncated=False):\n",
    "            \"\"\"\n",
    "                weight initalizer: truncated normal and random normal.\n",
    "            \"\"\"\n",
    "            # x is a parameter\n",
    "            if isinstance(m, nn.LSTM):\n",
    "                init.xavier_normal_(m.all_weights[0][0])\n",
    "                init.xavier_normal_(m.all_weights[0][1])\n",
    "                if len(m.all_weights) == 2:   # 双向  LSTM\n",
    "                    init.xavier_normal_(m.all_weights[1][0])\n",
    "                    init.xavier_normal_(m.all_weights[1][1])\n",
    "            else:\n",
    "                if truncated:\n",
    "                    m.weight.data.normal_().fmod_(2).mul_(stddev).add_(mean)  # not a perfect approximation\n",
    "                else:\n",
    "                    m.weight.data.normal_(mean, stddev)\n",
    "                m.bias.data.zero_()\n",
    "        normal_init(self.rpn_net, 0, 0.01, TRUNCATED)\n",
    "        normal_init(self.rpn_cls_score_net,0, 0.01, TRUNCATED)\n",
    "        normal_init(self.rpn_bbox_pred_net,0, 0.01, TRUNCATED)\n",
    "        normal_init(self.rpn_bi_net,0, 0.01, TRUNCATED)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class vgg16(Network):\n",
    "    def __init__(self):\n",
    "        Network.__init__(self)\n",
    "        self._feat_stride = [16, ]\n",
    "        self._feat_compress = [1. / float(self._feat_stride[0]), ]\n",
    "        self._net_conv_channels = 512\n",
    "        self._fc7_channels = 4096\n",
    "\n",
    "    def _init_head_tail(self):\n",
    "        # 注意， 通过 models.vgg16() 加载的模型是基础模型，是还没有经过训练的模型， 所以需要load_pretrained_cnn从外部载入已训练好的权重信息\n",
    "        # 而通过 models.vgg16(pretrained=True)，则是已训练好的模型，无需再加载模型，本次实现采用models.vgg16(pretrained=True)，无需再加载了\n",
    "        # 注意预加载的是识别图像的（对于识字的需做更改）\n",
    "        self.vgg = models.vgg16_bn(pretrained=True)\n",
    "        # Remove fc8\n",
    "        self.vgg.classifier = nn.Sequential(*list(self.vgg.classifier._modules.values())[:-1])\n",
    "\n",
    "        # Fix the layers before conv3:\n",
    "        for layer in range(12):\n",
    "          for p in self.vgg.features[layer].parameters(): p.requires_grad = False\n",
    "\n",
    "        # not using the last maxpool layer\n",
    "        self._layers['head'] = nn.Sequential(*list(self.vgg.features._modules.values())[:-1])\n",
    "#         print(self._layers['head'])\n",
    "\n",
    "\n",
    "    # 通过卷积网络VG16的feature层，抽取图片的特征\n",
    "    def _image_to_head(self):\n",
    "        net_conv = self._layers['head'](self._image)\n",
    "        self._act_summaries['conv'] = net_conv\n",
    "        return net_conv\n",
    "\n",
    "    def _head_to_tail(self, pool5):\n",
    "        pool5_flat = pool5.view(pool5.size(0), -1)\n",
    "        fc7 = self.vgg.classifier(pool5_flat)\n",
    "        return fc7\n",
    "\n",
    "\n",
    "    # 注意， 通过 models.vgg16() 加载的模型是基础模型，是还没有经过训练的模型， 所以需要该方法从外部载入权重信息\n",
    "    # 而通过 models.vgg16(pretrained=True)，则是已训练好的模型，无需再加载模型，本次实现采用models.vgg16(pretrained=True)，无需再加载了\n",
    "    def load_pretrained_cnn(self, state_dict):\n",
    "        self.vgg.load_state_dict({k:v for k,v in state_dict.items() if k in self.vgg.state_dict()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "train image name : num 0 : D:\\PROJECT_TW\\git\\data\\VOCdevkit2007\\VOC2007\\JPEGImages\\1.jpg\n",
      "train image name : num 0 : D:\\PROJECT_TW\\git\\data\\VOCdevkit2007\\VOC2007\\JPEGImages\\2.jpg\n",
      "train image name : num 0 : D:\\PROJECT_TW\\git\\data\\VOCdevkit2007\\VOC2007\\JPEGImages\\1.jpg\n",
      "train image name : num 0 : D:\\PROJECT_TW\\git\\data\\VOCdevkit2007\\VOC2007\\JPEGImages\\1.jpg\n",
      "train image name : num 0 : D:\\PROJECT_TW\\git\\data\\VOCdevkit2007\\VOC2007\\JPEGImages\\2.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ANCHOR_SCALES = [16]\n",
    "ANCHOR_RATIOS = [0.5,1,2]\n",
    "MOMENTUM = 0.9\n",
    "lr = 0.001\n",
    "DOUBLE_BIAS = True\n",
    "BIAS_DECAY = False\n",
    "WEIGHT_DECAY = 0.0005\n",
    "\n",
    "net = vgg16()\n",
    "print(imdb.num_classes)\n",
    "net.create_architecture(imdb.num_classes, tag='default',\n",
    "                                            anchor_scales=ANCHOR_SCALES,\n",
    "                                            anchor_ratios=ANCHOR_RATIOS)\n",
    "params = []\n",
    "\n",
    "for key, value in dict(net.named_parameters()).items():\n",
    "  if value.requires_grad:\n",
    "    if 'bias' in key:\n",
    "      params += [{'params':[value],'lr':lr*(DOUBLE_BIAS + 1), \n",
    "                  'weight_decay': BIAS_DECAY and WEIGHT_DECAY or 0}]\n",
    "    else:\n",
    "      params += [{'params':[value],'lr':lr, \n",
    "                  'weight_decay': WEIGHT_DECAY}]\n",
    "\n",
    "optimizer = torch.optim.SGD(params,lr=lr, momentum=MOMENTUM)\n",
    "\n",
    "for i in range(5):\n",
    "    blobs = data_layer.forward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

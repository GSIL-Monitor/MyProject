{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 需用到的知识点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1、Wavelet transform 小波变换  https://www.zhihu.com/question/22864189/answer/40772083\n",
    "        Consequently, wavelet is useful in handling highly irregular financial time series\n",
    "            https://www.researchgate.net/publication/223249583_Forecasting_stock_markets_using_wavelet_transforms_and_recurrent_neural_networks_An_integrated_system_based_on_artificial_bee_colony_algorithm\n",
    "            \n",
    "        https://pywavelets.readthedocs.io/en/latest/regression/index.html\n",
    "        \n",
    "        https://blog.csdn.net/zhaoyuxia517/article/details/78005713 基于小波变换的时间序列预测，Python实现\n",
    "        \n",
    "        http://www.docin.com/p-1546109075.html\n",
    "        \n",
    "        http://www.docin.com/p-1072414208.html?docfrom=rrela\n",
    "        \n",
    "        https://www.zhihu.com/question/19725983/answer/13856998\n",
    "        \n",
    "        http://www.360doc.com/content/13/0614/15/10724725_292827411.shtml\n",
    "            \n",
    "    2、Stacked autoencoders\n",
    "        https://blog.csdn.net/jningwei/article/details/78836823\n",
    "    \n",
    "    另注意： \n",
    "    什么Autoencoder啦、RBM啦，现在都已经 没人用了 。\n",
    "    现在所常说的 pre-training (预训练) ，其实 专指 migration learning (迁移学习)，那是一种无比强大又省事儿的trick。\n",
    "    \n",
    "        https://blog.csdn.net/hai008007/article/details/79676994"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 包含部分指标数据\n",
    "from stock.common.sdata import StockData\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "code = '600016'\n",
    "sd = StockData(code)\n",
    "data = sd.combine_income(ndays=5)\n",
    "key_defines = ['RSI','MACD']\n",
    "# 指标数据\n",
    "\n",
    "data = StockData.combine_index_data(data,index_keys=key_defines)\n",
    "\n",
    "use_column = [x not in ['Flag','INCOME'] for x in data.columns.get_level_values(0)]\n",
    "\n",
    "data.iloc[:,use_column] =  \\\n",
    "     data.iloc[:,use_column].apply(lambda x: (x-np.mean(x))/np.std(x))\n",
    "\n",
    "data_values = data.iloc[:,use_column].values\n",
    "dlen = int(len(data_values)*0.8)\n",
    "train_data = torch.from_numpy(np.array(data_values[0:dlen])).float()\n",
    "test_data = torch.from_numpy(np.array(data_values[dlen:])).float()\n",
    "dataset = TensorDataset(train_data)\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=8, shuffle=True)\n",
    "# data_in , target = sd.package_data(data=data, pdays=50)\n",
    "# data_in = [x.values for x in data_in]\n",
    "# dlen = int(len(data_in) * 0.9)\n",
    "# train_data, train_target = torch.from_numpy(np.array(data_in[0:dlen])).float(), torch.from_numpy(np.array(target[0:dlen])).long()\n",
    "# test_data, test_target = torch.from_numpy(np.array(data_in[dlen:])).float(), torch.from_numpy(np.array(target[dlen:]).squeeze()).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencode模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自编码主要用于数据降维\n",
    "import torch.nn as nn\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, n_feature):\n",
    "        super(AutoEncoder,self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(n_feature, 6),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(6, 3)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3,6),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(6, n_feature)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded        \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载上次训练模型...\n",
      "epcho --> 0 ： loss 0.057\n",
      "epcho --> 5 ： loss 0.056\n",
      "epcho --> 10 ： loss 0.056\n",
      "epcho --> 15 ： loss 0.056\n",
      "epcho --> 20 ： loss 0.056\n",
      "epcho --> 25 ： loss 0.056\n",
      "epcho --> 30 ： loss 0.056\n",
      "epcho --> 35 ： loss 0.056\n",
      "epcho --> 40 ： loss 0.056\n",
      "epcho --> 45 ： loss 0.058\n",
      "epcho --> 50 ： loss 0.056\n",
      "epcho --> 55 ： loss 0.056\n",
      "epcho --> 60 ： loss 0.056\n",
      "epcho --> 65 ： loss 0.056\n",
      "epcho --> 70 ： loss 0.056\n",
      "epcho --> 75 ： loss 0.056\n",
      "epcho --> 80 ： loss 0.056\n",
      "epcho --> 85 ： loss 0.056\n",
      "epcho --> 90 ： loss 0.056\n",
      "epcho --> 95 ： loss 0.056\n",
      "epcho --> 100 ： loss 0.057\n",
      "epcho --> 105 ： loss 0.056\n",
      "epcho --> 110 ： loss 0.056\n",
      "epcho --> 115 ： loss 0.056\n",
      "epcho --> 120 ： loss 0.056\n",
      "epcho --> 125 ： loss 0.056\n",
      "epcho --> 130 ： loss 0.056\n",
      "epcho --> 135 ： loss 0.056\n",
      "epcho --> 140 ： loss 0.056\n",
      "epcho --> 145 ： loss 0.056\n",
      "epcho --> 150 ： loss 0.056\n",
      "epcho --> 155 ： loss 0.056\n",
      "epcho --> 160 ： loss 0.056\n",
      "epcho --> 165 ： loss 0.056\n",
      "epcho --> 170 ： loss 0.056\n",
      "epcho --> 175 ： loss 0.056\n",
      "epcho --> 180 ： loss 0.056\n",
      "epcho --> 185 ： loss 0.056\n",
      "epcho --> 190 ： loss 0.056\n",
      "epcho --> 195 ： loss 0.056\n",
      "epcho --> 200 ： loss 0.056\n",
      "epcho --> 205 ： loss 0.056\n",
      "epcho --> 210 ： loss 0.056\n",
      "epcho --> 215 ： loss 0.056\n",
      "epcho --> 220 ： loss 0.056\n",
      "epcho --> 225 ： loss 0.056\n",
      "epcho --> 230 ： loss 0.056\n",
      "epcho --> 235 ： loss 0.056\n",
      "epcho --> 240 ： loss 0.056\n",
      "epcho --> 245 ： loss 0.056\n",
      "epcho --> 250 ： loss 0.056\n",
      "epcho --> 255 ： loss 0.056\n",
      "epcho --> 260 ： loss 0.056\n",
      "epcho --> 265 ： loss 0.056\n",
      "epcho --> 270 ： loss 0.056\n",
      "epcho --> 275 ： loss 0.056\n",
      "epcho --> 280 ： loss 0.056\n",
      "epcho --> 285 ： loss 0.056\n",
      "epcho --> 290 ： loss 0.056\n",
      "epcho --> 295 ： loss 0.056\n",
      "epcho --> 300 ： loss 0.056\n",
      "epcho --> 305 ： loss 0.056\n",
      "epcho --> 310 ： loss 0.056\n",
      "epcho --> 315 ： loss 0.056\n",
      "epcho --> 320 ： loss 0.056\n",
      "epcho --> 325 ： loss 0.056\n",
      "epcho --> 330 ： loss 0.056\n",
      "epcho --> 335 ： loss 0.056\n",
      "epcho --> 340 ： loss 0.056\n",
      "epcho --> 345 ： loss 0.056\n",
      "epcho --> 350 ： loss 0.056\n",
      "epcho --> 355 ： loss 0.056\n",
      "epcho --> 360 ： loss 0.056\n",
      "epcho --> 365 ： loss 0.056\n",
      "epcho --> 370 ： loss 0.056\n",
      "epcho --> 375 ： loss 0.056\n",
      "epcho --> 380 ： loss 0.056\n",
      "epcho --> 385 ： loss 0.056\n",
      "epcho --> 390 ： loss 0.056\n",
      "epcho --> 395 ： loss 0.056\n",
      "epcho --> 400 ： loss 0.056\n",
      "epcho --> 405 ： loss 0.056\n",
      "epcho --> 410 ： loss 0.056\n",
      "epcho --> 415 ： loss 0.056\n",
      "epcho --> 420 ： loss 0.056\n",
      "epcho --> 425 ： loss 0.056\n",
      "epcho --> 430 ： loss 0.056\n",
      "epcho --> 435 ： loss 0.056\n",
      "epcho --> 440 ： loss 0.056\n",
      "epcho --> 445 ： loss 0.056\n",
      "epcho --> 450 ： loss 0.056\n",
      "epcho --> 455 ： loss 0.056\n",
      "epcho --> 460 ： loss 0.056\n",
      "epcho --> 465 ： loss 0.056\n",
      "epcho --> 470 ： loss 0.056\n",
      "epcho --> 475 ： loss 0.057\n",
      "epcho --> 480 ： loss 0.056\n",
      "epcho --> 485 ： loss 0.056\n",
      "epcho --> 490 ： loss 0.056\n",
      "epcho --> 495 ： loss 0.056\n",
      "epcho --> 500 ： loss 0.056\n",
      "epcho --> 505 ： loss 0.056\n",
      "epcho --> 510 ： loss 0.056\n",
      "epcho --> 515 ： loss 0.056\n",
      "epcho --> 520 ： loss 0.056\n",
      "epcho --> 525 ： loss 0.056\n",
      "epcho --> 530 ： loss 0.056\n",
      "epcho --> 535 ： loss 0.056\n",
      "epcho --> 540 ： loss 0.056\n",
      "epcho --> 545 ： loss 0.057\n",
      "epcho --> 550 ： loss 0.057\n",
      "epcho --> 555 ： loss 0.056\n",
      "epcho --> 560 ： loss 0.056\n",
      "epcho --> 565 ： loss 0.056\n",
      "epcho --> 570 ： loss 0.056\n",
      "epcho --> 575 ： loss 0.056\n",
      "epcho --> 580 ： loss 0.056\n",
      "epcho --> 585 ： loss 0.056\n",
      "epcho --> 590 ： loss 0.056\n",
      "epcho --> 595 ： loss 0.056\n",
      "epcho --> 600 ： loss 0.056\n",
      "epcho --> 605 ： loss 0.056\n",
      "epcho --> 610 ： loss 0.056\n",
      "epcho --> 615 ： loss 0.056\n",
      "epcho --> 620 ： loss 0.056\n",
      "epcho --> 625 ： loss 0.056\n",
      "epcho --> 630 ： loss 0.056\n",
      "epcho --> 635 ： loss 0.056\n",
      "epcho --> 640 ： loss 0.056\n",
      "epcho --> 645 ： loss 0.056\n",
      "epcho --> 650 ： loss 0.056\n",
      "epcho --> 655 ： loss 0.056\n",
      "epcho --> 660 ： loss 0.056\n",
      "epcho --> 665 ： loss 0.056\n",
      "epcho --> 670 ： loss 0.056\n",
      "epcho --> 675 ： loss 0.056\n",
      "epcho --> 680 ： loss 0.056\n",
      "epcho --> 685 ： loss 0.056\n",
      "epcho --> 690 ： loss 0.056\n",
      "epcho --> 695 ： loss 0.056\n",
      "epcho --> 700 ： loss 0.056\n",
      "epcho --> 705 ： loss 0.056\n",
      "epcho --> 710 ： loss 0.056\n",
      "epcho --> 715 ： loss 0.056\n",
      "epcho --> 720 ： loss 0.056\n",
      "epcho --> 725 ： loss 0.056\n",
      "epcho --> 730 ： loss 0.056\n",
      "epcho --> 735 ： loss 0.056\n",
      "epcho --> 740 ： loss 0.056\n",
      "epcho --> 745 ： loss 0.056\n",
      "epcho --> 750 ： loss 0.056\n",
      "epcho --> 755 ： loss 0.056\n",
      "epcho --> 760 ： loss 0.056\n",
      "epcho --> 765 ： loss 0.056\n",
      "epcho --> 770 ： loss 0.056\n",
      "epcho --> 775 ： loss 0.056\n",
      "epcho --> 780 ： loss 0.056\n",
      "epcho --> 785 ： loss 0.056\n",
      "epcho --> 790 ： loss 0.056\n",
      "epcho --> 795 ： loss 0.056\n",
      "epcho --> 800 ： loss 0.056\n",
      "epcho --> 805 ： loss 0.056\n",
      "epcho --> 810 ： loss 0.056\n",
      "epcho --> 815 ： loss 0.056\n",
      "epcho --> 820 ： loss 0.056\n",
      "epcho --> 825 ： loss 0.056\n",
      "epcho --> 830 ： loss 0.056\n",
      "epcho --> 835 ： loss 0.056\n",
      "epcho --> 840 ： loss 0.056\n",
      "epcho --> 845 ： loss 0.056\n",
      "epcho --> 850 ： loss 0.056\n",
      "epcho --> 855 ： loss 0.056\n",
      "epcho --> 860 ： loss 0.056\n",
      "epcho --> 865 ： loss 0.056\n",
      "epcho --> 870 ： loss 0.056\n",
      "epcho --> 875 ： loss 0.056\n",
      "epcho --> 880 ： loss 0.056\n",
      "epcho --> 885 ： loss 0.056\n",
      "epcho --> 890 ： loss 0.056\n",
      "epcho --> 895 ： loss 0.056\n",
      "epcho --> 900 ： loss 0.056\n",
      "epcho --> 905 ： loss 0.056\n",
      "epcho --> 910 ： loss 0.056\n",
      "epcho --> 915 ： loss 0.056\n",
      "epcho --> 920 ： loss 0.056\n",
      "epcho --> 925 ： loss 0.056\n",
      "epcho --> 930 ： loss 0.057\n",
      "epcho --> 935 ： loss 0.056\n",
      "epcho --> 940 ： loss 0.056\n",
      "epcho --> 945 ： loss 0.057\n",
      "epcho --> 950 ： loss 0.056\n",
      "epcho --> 955 ： loss 0.056\n",
      "epcho --> 960 ： loss 0.056\n",
      "epcho --> 965 ： loss 0.056\n",
      "epcho --> 970 ： loss 0.056\n",
      "epcho --> 975 ： loss 0.056\n",
      "epcho --> 980 ： loss 0.056\n",
      "epcho --> 985 ： loss 0.056\n",
      "epcho --> 990 ： loss 0.056\n",
      "epcho --> 995 ： loss 0.056\n",
      "epcho --> 1000 ： loss 0.056\n",
      "epcho --> 1005 ： loss 0.056\n",
      "epcho --> 1010 ： loss 0.056\n",
      "epcho --> 1015 ： loss 0.056\n",
      "epcho --> 1020 ： loss 0.056\n",
      "epcho --> 1025 ： loss 0.057\n",
      "epcho --> 1030 ： loss 0.057\n",
      "epcho --> 1035 ： loss 0.056\n",
      "epcho --> 1040 ： loss 0.057\n",
      "epcho --> 1045 ： loss 0.056\n",
      "epcho --> 1050 ： loss 0.056\n",
      "epcho --> 1055 ： loss 0.056\n",
      "epcho --> 1060 ： loss 0.056\n",
      "epcho --> 1065 ： loss 0.056\n",
      "epcho --> 1070 ： loss 0.056\n",
      "epcho --> 1075 ： loss 0.056\n",
      "epcho --> 1080 ： loss 0.056\n",
      "epcho --> 1085 ： loss 0.056\n",
      "epcho --> 1090 ： loss 0.056\n",
      "epcho --> 1095 ： loss 0.056\n",
      "epcho --> 1100 ： loss 0.056\n",
      "epcho --> 1105 ： loss 0.056\n",
      "epcho --> 1110 ： loss 0.056\n",
      "epcho --> 1115 ： loss 0.056\n",
      "epcho --> 1120 ： loss 0.056\n",
      "epcho --> 1125 ： loss 0.056\n",
      "epcho --> 1130 ： loss 0.056\n",
      "epcho --> 1135 ： loss 0.056\n",
      "epcho --> 1140 ： loss 0.056\n",
      "epcho --> 1145 ： loss 0.057\n",
      "epcho --> 1150 ： loss 0.056\n",
      "epcho --> 1155 ： loss 0.057\n",
      "epcho --> 1160 ： loss 0.056\n",
      "epcho --> 1165 ： loss 0.056\n",
      "epcho --> 1170 ： loss 0.056\n",
      "epcho --> 1175 ： loss 0.056\n",
      "epcho --> 1180 ： loss 0.056\n",
      "epcho --> 1185 ： loss 0.056\n",
      "epcho --> 1190 ： loss 0.056\n",
      "epcho --> 1195 ： loss 0.056\n",
      "epcho --> 1200 ： loss 0.056\n",
      "epcho --> 1205 ： loss 0.056\n",
      "epcho --> 1210 ： loss 0.056\n",
      "epcho --> 1215 ： loss 0.056\n",
      "epcho --> 1220 ： loss 0.056\n",
      "epcho --> 1225 ： loss 0.056\n",
      "epcho --> 1230 ： loss 0.056\n",
      "epcho --> 1235 ： loss 0.056\n",
      "epcho --> 1240 ： loss 0.056\n",
      "epcho --> 1245 ： loss 0.056\n",
      "epcho --> 1250 ： loss 0.056\n",
      "epcho --> 1255 ： loss 0.056\n",
      "epcho --> 1260 ： loss 0.056\n",
      "epcho --> 1265 ： loss 0.056\n",
      "epcho --> 1270 ： loss 0.056\n",
      "epcho --> 1275 ： loss 0.056\n",
      "epcho --> 1280 ： loss 0.056\n",
      "epcho --> 1285 ： loss 0.056\n",
      "epcho --> 1290 ： loss 0.056\n",
      "epcho --> 1295 ： loss 0.056\n",
      "epcho --> 1300 ： loss 0.056\n",
      "epcho --> 1305 ： loss 0.056\n",
      "epcho --> 1310 ： loss 0.056\n",
      "epcho --> 1315 ： loss 0.056\n",
      "epcho --> 1320 ： loss 0.056\n",
      "epcho --> 1325 ： loss 0.056\n",
      "epcho --> 1330 ： loss 0.057\n",
      "epcho --> 1335 ： loss 0.056\n",
      "epcho --> 1340 ： loss 0.056\n",
      "epcho --> 1345 ： loss 0.056\n",
      "epcho --> 1350 ： loss 0.057\n",
      "epcho --> 1355 ： loss 0.056\n",
      "epcho --> 1360 ： loss 0.056\n",
      "epcho --> 1365 ： loss 0.056\n",
      "epcho --> 1370 ： loss 0.056\n",
      "epcho --> 1375 ： loss 0.056\n",
      "epcho --> 1380 ： loss 0.056\n",
      "epcho --> 1385 ： loss 0.056\n",
      "epcho --> 1390 ： loss 0.056\n",
      "epcho --> 1395 ： loss 0.056\n",
      "epcho --> 1400 ： loss 0.056\n",
      "epcho --> 1405 ： loss 0.056\n",
      "epcho --> 1410 ： loss 0.056\n",
      "epcho --> 1415 ： loss 0.057\n",
      "epcho --> 1420 ： loss 0.056\n",
      "epcho --> 1425 ： loss 0.056\n",
      "epcho --> 1430 ： loss 0.056\n",
      "epcho --> 1435 ： loss 0.057\n",
      "epcho --> 1440 ： loss 0.056\n",
      "epcho --> 1445 ： loss 0.056\n",
      "epcho --> 1450 ： loss 0.056\n",
      "epcho --> 1455 ： loss 0.056\n",
      "epcho --> 1460 ： loss 0.056\n",
      "epcho --> 1465 ： loss 0.056\n",
      "epcho --> 1470 ： loss 0.056\n",
      "epcho --> 1475 ： loss 0.056\n",
      "epcho --> 1480 ： loss 0.056\n",
      "epcho --> 1485 ： loss 0.056\n",
      "epcho --> 1490 ： loss 0.056\n",
      "epcho --> 1495 ： loss 0.056\n",
      "epcho --> 1500 ： loss 0.056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epcho --> 1505 ： loss 0.056\n",
      "epcho --> 1510 ： loss 0.056\n",
      "epcho --> 1515 ： loss 0.056\n",
      "epcho --> 1520 ： loss 0.056\n",
      "epcho --> 1525 ： loss 0.056\n",
      "epcho --> 1530 ： loss 0.056\n",
      "epcho --> 1535 ： loss 0.056\n",
      "epcho --> 1540 ： loss 0.056\n",
      "epcho --> 1545 ： loss 0.056\n",
      "epcho --> 1550 ： loss 0.056\n",
      "epcho --> 1555 ： loss 0.056\n",
      "epcho --> 1560 ： loss 0.056\n",
      "epcho --> 1565 ： loss 0.056\n",
      "epcho --> 1570 ： loss 0.057\n",
      "epcho --> 1575 ： loss 0.056\n",
      "epcho --> 1580 ： loss 0.056\n",
      "epcho --> 1585 ： loss 0.056\n",
      "epcho --> 1590 ： loss 0.056\n",
      "epcho --> 1595 ： loss 0.056\n",
      "epcho --> 1600 ： loss 0.056\n",
      "epcho --> 1605 ： loss 0.056\n",
      "epcho --> 1610 ： loss 0.056\n",
      "epcho --> 1615 ： loss 0.056\n",
      "epcho --> 1620 ： loss 0.056\n",
      "epcho --> 1625 ： loss 0.056\n",
      "epcho --> 1630 ： loss 0.056\n",
      "epcho --> 1635 ： loss 0.056\n",
      "epcho --> 1640 ： loss 0.056\n",
      "epcho --> 1645 ： loss 0.057\n",
      "epcho --> 1650 ： loss 0.056\n",
      "epcho --> 1655 ： loss 0.056\n",
      "epcho --> 1660 ： loss 0.056\n",
      "epcho --> 1665 ： loss 0.056\n",
      "epcho --> 1670 ： loss 0.057\n",
      "epcho --> 1675 ： loss 0.056\n",
      "epcho --> 1680 ： loss 0.056\n",
      "epcho --> 1685 ： loss 0.056\n",
      "epcho --> 1690 ： loss 0.056\n",
      "epcho --> 1695 ： loss 0.056\n",
      "epcho --> 1700 ： loss 0.056\n",
      "epcho --> 1705 ： loss 0.058\n",
      "epcho --> 1710 ： loss 0.056\n",
      "epcho --> 1715 ： loss 0.056\n",
      "epcho --> 1720 ： loss 0.056\n",
      "epcho --> 1725 ： loss 0.056\n",
      "epcho --> 1730 ： loss 0.056\n",
      "epcho --> 1735 ： loss 0.056\n",
      "epcho --> 1740 ： loss 0.056\n",
      "epcho --> 1745 ： loss 0.056\n",
      "epcho --> 1750 ： loss 0.056\n",
      "epcho --> 1755 ： loss 0.057\n",
      "epcho --> 1760 ： loss 0.056\n",
      "epcho --> 1765 ： loss 0.056\n",
      "epcho --> 1770 ： loss 0.057\n",
      "epcho --> 1775 ： loss 0.056\n",
      "epcho --> 1780 ： loss 0.056\n",
      "epcho --> 1785 ： loss 0.056\n",
      "epcho --> 1790 ： loss 0.056\n",
      "epcho --> 1795 ： loss 0.056\n",
      "epcho --> 1800 ： loss 0.056\n",
      "epcho --> 1805 ： loss 0.056\n",
      "epcho --> 1810 ： loss 0.056\n",
      "epcho --> 1815 ： loss 0.056\n",
      "epcho --> 1820 ： loss 0.056\n",
      "epcho --> 1825 ： loss 0.056\n",
      "epcho --> 1830 ： loss 0.057\n",
      "epcho --> 1835 ： loss 0.056\n",
      "epcho --> 1840 ： loss 0.056\n",
      "epcho --> 1845 ： loss 0.056\n",
      "epcho --> 1850 ： loss 0.056\n",
      "epcho --> 1855 ： loss 0.056\n",
      "epcho --> 1860 ： loss 0.056\n",
      "epcho --> 1865 ： loss 0.056\n",
      "epcho --> 1870 ： loss 0.056\n",
      "epcho --> 1875 ： loss 0.056\n",
      "epcho --> 1880 ： loss 0.056\n",
      "epcho --> 1885 ： loss 0.056\n",
      "epcho --> 1890 ： loss 0.056\n",
      "epcho --> 1895 ： loss 0.056\n",
      "epcho --> 1900 ： loss 0.056\n",
      "epcho --> 1905 ： loss 0.056\n",
      "epcho --> 1910 ： loss 0.056\n",
      "epcho --> 1915 ： loss 0.056\n",
      "epcho --> 1920 ： loss 0.056\n",
      "epcho --> 1925 ： loss 0.056\n",
      "epcho --> 1930 ： loss 0.057\n",
      "epcho --> 1935 ： loss 0.056\n",
      "epcho --> 1940 ： loss 0.056\n",
      "epcho --> 1945 ： loss 0.056\n",
      "epcho --> 1950 ： loss 0.056\n",
      "epcho --> 1955 ： loss 0.056\n",
      "epcho --> 1960 ： loss 0.056\n",
      "epcho --> 1965 ： loss 0.056\n",
      "epcho --> 1970 ： loss 0.056\n",
      "epcho --> 1975 ： loss 0.056\n",
      "epcho --> 1980 ： loss 0.056\n",
      "epcho --> 1985 ： loss 0.056\n",
      "epcho --> 1990 ： loss 0.056\n",
      "epcho --> 1995 ： loss 0.056\n",
      "epcho --> 2000 ： loss 0.056\n",
      "epcho --> 2005 ： loss 0.056\n",
      "epcho --> 2010 ： loss 0.056\n",
      "epcho --> 2015 ： loss 0.056\n",
      "epcho --> 2020 ： loss 0.056\n",
      "epcho --> 2025 ： loss 0.056\n",
      "epcho --> 2030 ： loss 0.056\n",
      "epcho --> 2035 ： loss 0.056\n",
      "epcho --> 2040 ： loss 0.056\n",
      "epcho --> 2045 ： loss 0.056\n",
      "epcho --> 2050 ： loss 0.056\n",
      "epcho --> 2055 ： loss 0.056\n",
      "epcho --> 2060 ： loss 0.056\n",
      "epcho --> 2065 ： loss 0.056\n",
      "epcho --> 2070 ： loss 0.056\n",
      "epcho --> 2075 ： loss 0.057\n",
      "epcho --> 2080 ： loss 0.056\n",
      "epcho --> 2085 ： loss 0.056\n",
      "epcho --> 2090 ： loss 0.056\n",
      "epcho --> 2095 ： loss 0.056\n",
      "epcho --> 2100 ： loss 0.056\n",
      "epcho --> 2105 ： loss 0.056\n",
      "epcho --> 2110 ： loss 0.056\n",
      "epcho --> 2115 ： loss 0.056\n",
      "epcho --> 2120 ： loss 0.056\n",
      "epcho --> 2125 ： loss 0.056\n",
      "epcho --> 2130 ： loss 0.056\n",
      "epcho --> 2135 ： loss 0.056\n",
      "epcho --> 2140 ： loss 0.056\n",
      "epcho --> 2145 ： loss 0.056\n",
      "epcho --> 2150 ： loss 0.056\n",
      "epcho --> 2155 ： loss 0.056\n",
      "epcho --> 2160 ： loss 0.056\n",
      "epcho --> 2165 ： loss 0.056\n",
      "epcho --> 2170 ： loss 0.056\n",
      "epcho --> 2175 ： loss 0.056\n",
      "epcho --> 2180 ： loss 0.056\n",
      "epcho --> 2185 ： loss 0.056\n",
      "epcho --> 2190 ： loss 0.056\n",
      "epcho --> 2195 ： loss 0.056\n",
      "epcho --> 2200 ： loss 0.056\n",
      "epcho --> 2205 ： loss 0.057\n",
      "epcho --> 2210 ： loss 0.056\n",
      "epcho --> 2215 ： loss 0.056\n",
      "epcho --> 2220 ： loss 0.056\n",
      "epcho --> 2225 ： loss 0.057\n",
      "epcho --> 2230 ： loss 0.056\n",
      "epcho --> 2235 ： loss 0.056\n",
      "epcho --> 2240 ： loss 0.056\n",
      "epcho --> 2245 ： loss 0.056\n",
      "epcho --> 2250 ： loss 0.056\n",
      "epcho --> 2255 ： loss 0.056\n",
      "epcho --> 2260 ： loss 0.056\n",
      "epcho --> 2265 ： loss 0.056\n",
      "epcho --> 2270 ： loss 0.056\n",
      "epcho --> 2275 ： loss 0.056\n",
      "epcho --> 2280 ： loss 0.056\n",
      "epcho --> 2285 ： loss 0.056\n",
      "epcho --> 2290 ： loss 0.056\n",
      "epcho --> 2295 ： loss 0.056\n",
      "epcho --> 2300 ： loss 0.056\n",
      "epcho --> 2305 ： loss 0.056\n",
      "epcho --> 2310 ： loss 0.056\n",
      "epcho --> 2315 ： loss 0.056\n",
      "epcho --> 2320 ： loss 0.056\n",
      "epcho --> 2325 ： loss 0.056\n",
      "epcho --> 2330 ： loss 0.056\n",
      "epcho --> 2335 ： loss 0.056\n",
      "epcho --> 2340 ： loss 0.056\n",
      "epcho --> 2345 ： loss 0.056\n",
      "epcho --> 2350 ： loss 0.056\n",
      "epcho --> 2355 ： loss 0.057\n",
      "epcho --> 2360 ： loss 0.056\n",
      "epcho --> 2365 ： loss 0.056\n",
      "epcho --> 2370 ： loss 0.056\n",
      "epcho --> 2375 ： loss 0.056\n",
      "epcho --> 2380 ： loss 0.056\n",
      "epcho --> 2385 ： loss 0.056\n",
      "epcho --> 2390 ： loss 0.056\n",
      "epcho --> 2395 ： loss 0.056\n",
      "epcho --> 2400 ： loss 0.056\n",
      "epcho --> 2405 ： loss 0.056\n",
      "epcho --> 2410 ： loss 0.056\n",
      "epcho --> 2415 ： loss 0.056\n",
      "epcho --> 2420 ： loss 0.056\n",
      "epcho --> 2425 ： loss 0.056\n",
      "epcho --> 2430 ： loss 0.056\n",
      "epcho --> 2435 ： loss 0.056\n",
      "epcho --> 2440 ： loss 0.056\n",
      "epcho --> 2445 ： loss 0.056\n",
      "epcho --> 2450 ： loss 0.056\n",
      "epcho --> 2455 ： loss 0.056\n",
      "epcho --> 2460 ： loss 0.056\n",
      "epcho --> 2465 ： loss 0.056\n",
      "epcho --> 2470 ： loss 0.056\n",
      "epcho --> 2475 ： loss 0.056\n",
      "epcho --> 2480 ： loss 0.056\n",
      "epcho --> 2485 ： loss 0.057\n",
      "epcho --> 2490 ： loss 0.056\n",
      "epcho --> 2495 ： loss 0.056\n",
      "epcho --> 2500 ： loss 0.056\n",
      "epcho --> 2505 ： loss 0.056\n",
      "epcho --> 2510 ： loss 0.056\n",
      "epcho --> 2515 ： loss 0.056\n",
      "epcho --> 2520 ： loss 0.056\n",
      "epcho --> 2525 ： loss 0.056\n",
      "epcho --> 2530 ： loss 0.056\n",
      "epcho --> 2535 ： loss 0.056\n",
      "epcho --> 2540 ： loss 0.056\n",
      "epcho --> 2545 ： loss 0.056\n",
      "epcho --> 2550 ： loss 0.057\n",
      "epcho --> 2555 ： loss 0.056\n",
      "epcho --> 2560 ： loss 0.057\n",
      "epcho --> 2565 ： loss 0.057\n",
      "epcho --> 2570 ： loss 0.056\n",
      "epcho --> 2575 ： loss 0.056\n",
      "epcho --> 2580 ： loss 0.056\n",
      "epcho --> 2585 ： loss 0.056\n",
      "epcho --> 2590 ： loss 0.056\n",
      "epcho --> 2595 ： loss 0.056\n",
      "epcho --> 2600 ： loss 0.056\n",
      "epcho --> 2605 ： loss 0.056\n",
      "epcho --> 2610 ： loss 0.056\n",
      "epcho --> 2615 ： loss 0.056\n",
      "epcho --> 2620 ： loss 0.056\n",
      "epcho --> 2625 ： loss 0.056\n",
      "epcho --> 2630 ： loss 0.056\n",
      "epcho --> 2635 ： loss 0.056\n",
      "epcho --> 2640 ： loss 0.056\n",
      "epcho --> 2645 ： loss 0.056\n",
      "epcho --> 2650 ： loss 0.056\n",
      "epcho --> 2655 ： loss 0.056\n",
      "epcho --> 2660 ： loss 0.056\n",
      "epcho --> 2665 ： loss 0.056\n",
      "epcho --> 2670 ： loss 0.056\n",
      "epcho --> 2675 ： loss 0.056\n",
      "epcho --> 2680 ： loss 0.056\n",
      "epcho --> 2685 ： loss 0.056\n",
      "epcho --> 2690 ： loss 0.056\n",
      "epcho --> 2695 ： loss 0.056\n",
      "epcho --> 2700 ： loss 0.056\n",
      "epcho --> 2705 ： loss 0.056\n",
      "epcho --> 2710 ： loss 0.056\n",
      "epcho --> 2715 ： loss 0.056\n",
      "epcho --> 2720 ： loss 0.056\n",
      "epcho --> 2725 ： loss 0.056\n",
      "epcho --> 2730 ： loss 0.056\n",
      "epcho --> 2735 ： loss 0.056\n",
      "epcho --> 2740 ： loss 0.056\n",
      "epcho --> 2745 ： loss 0.056\n",
      "epcho --> 2750 ： loss 0.056\n",
      "epcho --> 2755 ： loss 0.056\n",
      "epcho --> 2760 ： loss 0.056\n",
      "epcho --> 2765 ： loss 0.056\n",
      "epcho --> 2770 ： loss 0.056\n",
      "epcho --> 2775 ： loss 0.056\n",
      "epcho --> 2780 ： loss 0.057\n",
      "epcho --> 2785 ： loss 0.056\n",
      "epcho --> 2790 ： loss 0.056\n",
      "epcho --> 2795 ： loss 0.056\n",
      "epcho --> 2800 ： loss 0.056\n",
      "epcho --> 2805 ： loss 0.056\n",
      "epcho --> 2810 ： loss 0.056\n",
      "epcho --> 2815 ： loss 0.057\n",
      "epcho --> 2820 ： loss 0.056\n",
      "epcho --> 2825 ： loss 0.056\n",
      "epcho --> 2830 ： loss 0.056\n",
      "epcho --> 2835 ： loss 0.056\n",
      "epcho --> 2840 ： loss 0.056\n",
      "epcho --> 2845 ： loss 0.056\n",
      "epcho --> 2850 ： loss 0.056\n",
      "epcho --> 2855 ： loss 0.056\n",
      "epcho --> 2860 ： loss 0.056\n",
      "epcho --> 2865 ： loss 0.056\n",
      "epcho --> 2870 ： loss 0.056\n",
      "epcho --> 2875 ： loss 0.056\n",
      "epcho --> 2880 ： loss 0.056\n",
      "epcho --> 2885 ： loss 0.056\n",
      "epcho --> 2890 ： loss 0.056\n",
      "epcho --> 2895 ： loss 0.056\n",
      "epcho --> 2900 ： loss 0.056\n",
      "epcho --> 2905 ： loss 0.056\n",
      "epcho --> 2910 ： loss 0.056\n",
      "epcho --> 2915 ： loss 0.056\n",
      "epcho --> 2920 ： loss 0.056\n",
      "epcho --> 2925 ： loss 0.056\n",
      "epcho --> 2930 ： loss 0.056\n",
      "epcho --> 2935 ： loss 0.057\n",
      "epcho --> 2940 ： loss 0.056\n",
      "epcho --> 2945 ： loss 0.056\n",
      "epcho --> 2950 ： loss 0.056\n",
      "epcho --> 2955 ： loss 0.056\n",
      "epcho --> 2960 ： loss 0.056\n",
      "epcho --> 2965 ： loss 0.056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epcho --> 2970 ： loss 0.056\n",
      "epcho --> 2975 ： loss 0.056\n",
      "epcho --> 2980 ： loss 0.056\n",
      "epcho --> 2985 ： loss 0.056\n",
      "epcho --> 2990 ： loss 0.056\n",
      "epcho --> 2995 ： loss 0.056\n",
      "epcho --> 3000 ： loss 0.056\n",
      "epcho --> 3005 ： loss 0.056\n",
      "epcho --> 3010 ： loss 0.056\n",
      "epcho --> 3015 ： loss 0.056\n",
      "epcho --> 3020 ： loss 0.056\n",
      "epcho --> 3025 ： loss 0.056\n",
      "epcho --> 3030 ： loss 0.056\n",
      "epcho --> 3035 ： loss 0.056\n",
      "epcho --> 3040 ： loss 0.056\n",
      "epcho --> 3045 ： loss 0.056\n",
      "epcho --> 3050 ： loss 0.056\n",
      "epcho --> 3055 ： loss 0.056\n",
      "epcho --> 3060 ： loss 0.056\n",
      "epcho --> 3065 ： loss 0.056\n",
      "epcho --> 3070 ： loss 0.056\n",
      "epcho --> 3075 ： loss 0.056\n",
      "epcho --> 3080 ： loss 0.056\n",
      "epcho --> 3085 ： loss 0.056\n",
      "epcho --> 3090 ： loss 0.056\n",
      "epcho --> 3095 ： loss 0.056\n",
      "epcho --> 3100 ： loss 0.056\n",
      "epcho --> 3105 ： loss 0.056\n",
      "epcho --> 3110 ： loss 0.056\n",
      "epcho --> 3115 ： loss 0.056\n",
      "epcho --> 3120 ： loss 0.056\n",
      "epcho --> 3125 ： loss 0.056\n",
      "epcho --> 3130 ： loss 0.056\n",
      "epcho --> 3135 ： loss 0.056\n",
      "epcho --> 3140 ： loss 0.056\n",
      "epcho --> 3145 ： loss 0.056\n",
      "epcho --> 3150 ： loss 0.056\n",
      "epcho --> 3155 ： loss 0.056\n",
      "epcho --> 3160 ： loss 0.056\n",
      "epcho --> 3165 ： loss 0.056\n",
      "epcho --> 3170 ： loss 0.056\n",
      "epcho --> 3175 ： loss 0.056\n",
      "epcho --> 3180 ： loss 0.056\n",
      "epcho --> 3185 ： loss 0.056\n",
      "epcho --> 3190 ： loss 0.056\n",
      "epcho --> 3195 ： loss 0.056\n",
      "epcho --> 3200 ： loss 0.056\n",
      "epcho --> 3205 ： loss 0.056\n",
      "epcho --> 3210 ： loss 0.056\n",
      "epcho --> 3215 ： loss 0.056\n",
      "epcho --> 3220 ： loss 0.056\n",
      "epcho --> 3225 ： loss 0.056\n",
      "epcho --> 3230 ： loss 0.056\n",
      "epcho --> 3235 ： loss 0.056\n",
      "epcho --> 3240 ： loss 0.056\n",
      "epcho --> 3245 ： loss 0.056\n",
      "epcho --> 3250 ： loss 0.056\n",
      "epcho --> 3255 ： loss 0.056\n",
      "epcho --> 3260 ： loss 0.056\n",
      "epcho --> 3265 ： loss 0.056\n",
      "epcho --> 3270 ： loss 0.056\n",
      "epcho --> 3275 ： loss 0.056\n",
      "epcho --> 3280 ： loss 0.056\n",
      "epcho --> 3285 ： loss 0.056\n",
      "epcho --> 3290 ： loss 0.056\n",
      "epcho --> 3295 ： loss 0.056\n",
      "epcho --> 3300 ： loss 0.056\n",
      "epcho --> 3305 ： loss 0.056\n",
      "epcho --> 3310 ： loss 0.056\n",
      "epcho --> 3315 ： loss 0.056\n",
      "epcho --> 3320 ： loss 0.056\n",
      "epcho --> 3325 ： loss 0.056\n",
      "epcho --> 3330 ： loss 0.056\n",
      "epcho --> 3335 ： loss 0.056\n",
      "epcho --> 3340 ： loss 0.056\n",
      "epcho --> 3345 ： loss 0.056\n",
      "epcho --> 3350 ： loss 0.056\n",
      "epcho --> 3355 ： loss 0.056\n",
      "epcho --> 3360 ： loss 0.056\n",
      "epcho --> 3365 ： loss 0.056\n",
      "epcho --> 3370 ： loss 0.056\n",
      "epcho --> 3375 ： loss 0.056\n",
      "epcho --> 3380 ： loss 0.056\n",
      "epcho --> 3385 ： loss 0.056\n",
      "epcho --> 3390 ： loss 0.056\n",
      "epcho --> 3395 ： loss 0.056\n",
      "epcho --> 3400 ： loss 0.056\n",
      "epcho --> 3405 ： loss 0.056\n",
      "epcho --> 3410 ： loss 0.056\n",
      "epcho --> 3415 ： loss 0.056\n",
      "epcho --> 3420 ： loss 0.056\n",
      "epcho --> 3425 ： loss 0.056\n",
      "epcho --> 3430 ： loss 0.056\n",
      "epcho --> 3435 ： loss 0.056\n",
      "epcho --> 3440 ： loss 0.056\n",
      "epcho --> 3445 ： loss 0.056\n",
      "epcho --> 3450 ： loss 0.056\n",
      "epcho --> 3455 ： loss 0.056\n",
      "epcho --> 3460 ： loss 0.056\n",
      "epcho --> 3465 ： loss 0.056\n",
      "epcho --> 3470 ： loss 0.056\n",
      "epcho --> 3475 ： loss 0.056\n",
      "epcho --> 3480 ： loss 0.056\n",
      "epcho --> 3485 ： loss 0.056\n",
      "epcho --> 3490 ： loss 0.056\n",
      "epcho --> 3495 ： loss 0.056\n",
      "epcho --> 3500 ： loss 0.056\n",
      "epcho --> 3505 ： loss 0.056\n",
      "epcho --> 3510 ： loss 0.056\n",
      "epcho --> 3515 ： loss 0.057\n",
      "epcho --> 3520 ： loss 0.056\n",
      "epcho --> 3525 ： loss 0.056\n",
      "epcho --> 3530 ： loss 0.056\n",
      "epcho --> 3535 ： loss 0.056\n",
      "epcho --> 3540 ： loss 0.056\n",
      "epcho --> 3545 ： loss 0.056\n",
      "epcho --> 3550 ： loss 0.056\n",
      "epcho --> 3555 ： loss 0.056\n",
      "epcho --> 3560 ： loss 0.056\n",
      "epcho --> 3565 ： loss 0.056\n",
      "epcho --> 3570 ： loss 0.056\n",
      "epcho --> 3575 ： loss 0.056\n",
      "epcho --> 3580 ： loss 0.056\n",
      "epcho --> 3585 ： loss 0.056\n",
      "epcho --> 3590 ： loss 0.056\n",
      "epcho --> 3595 ： loss 0.056\n",
      "epcho --> 3600 ： loss 0.056\n",
      "epcho --> 3605 ： loss 0.056\n",
      "epcho --> 3610 ： loss 0.056\n",
      "epcho --> 3615 ： loss 0.056\n",
      "epcho --> 3620 ： loss 0.056\n",
      "epcho --> 3625 ： loss 0.056\n",
      "epcho --> 3630 ： loss 0.056\n",
      "epcho --> 3635 ： loss 0.056\n",
      "epcho --> 3640 ： loss 0.056\n",
      "epcho --> 3645 ： loss 0.056\n",
      "epcho --> 3650 ： loss 0.057\n",
      "epcho --> 3655 ： loss 0.056\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import copy\n",
    "LR = 0.00001\n",
    "autoencoder = AutoEncoder(n_feature = 10)\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)\n",
    "loss_func = nn.MSELoss()\n",
    "epcho = 50000\n",
    "\n",
    "if os.path.exists('/home/hecong/dplearn/model/autoencode_model.pkl'):\n",
    "    print('加载上次训练模型...')\n",
    "    autoencoder.load_state_dict(torch.load('/home/hecong/dplearn/model/autoencode_model.pkl'))\n",
    "    \n",
    "for epcho in range(epcho):\n",
    "    run_loss = 0\n",
    "    for step, x in enumerate(train_loader):\n",
    "#         print(x[0])\n",
    "#         print(x[0].shape)\n",
    "        in_x = x[0]\n",
    "        target  = x[0]\n",
    "        encode,decode = autoencoder(in_x)\n",
    "        loss = loss_func(decode, target)\n",
    "        run_loss = run_loss + loss\n",
    "        optimizer.zero_grad()               # clear gradients for this training step\n",
    "        loss.backward()                     # backpropagation, compute gradients\n",
    "        optimizer.step()                    # apply gradients        \n",
    "        \n",
    "    if epcho % 5 == 0:\n",
    "        print('epcho --> {} ： loss {:.3f}'.format(epcho, run_loss/step))\n",
    "        _wts = copy.deepcopy(autoencoder.state_dict())  \n",
    "        torch.save(_wts,'/home/hecong/dplearn/model/autoencode_model.pkl')            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2571, -0.2636, -0.2650, -0.2605, -0.3169, -0.2908, -0.6318, -0.4533,\n",
      "         -0.4420, -0.1194],\n",
      "        [-1.2194, -1.1845, -1.1930, -1.2207,  0.5459,  0.1038,  0.7714, -0.5541,\n",
      "         -0.8477,  0.9763],\n",
      "        [-1.0904, -1.0912, -1.0958, -1.0954, -0.3427, -0.5237, -0.5420, -0.4528,\n",
      "         -0.4383, -0.1299],\n",
      "        [-0.7954, -0.8040, -0.8044, -0.7985, -0.4298, -0.4952, -1.3418, -1.4378,\n",
      "         -1.5266,  0.0809],\n",
      "        [-0.9357, -0.9489, -0.9545, -0.9460, -0.5109, -0.5838, -0.9815, -0.2808,\n",
      "         -0.0734, -0.8035],\n",
      "        [ 0.2880,  0.3267,  0.2969,  0.2479,  2.6068,  2.5594, -0.1802, -0.1576,\n",
      "          0.1135, -1.0116],\n",
      "        [-0.1651, -0.1829, -0.1901, -0.1802, -0.3653, -0.2724, -0.8293,  0.1698,\n",
      "          0.5403, -1.3222],\n",
      "        [ 1.3665,  1.3738,  1.3652,  1.3559,  0.1619,  0.3871, -0.6694, -1.5177,\n",
      "         -1.6189,  0.1139]], grad_fn=<ThAddmmBackward>)\n",
      "tensor([[-0.2587, -0.3029, -0.2897, -0.2864, -0.6152, -0.5640, -0.8206, -0.3655,\n",
      "         -0.3894,  0.0262],\n",
      "        [-1.3780, -1.3658, -1.3662, -1.3958,  0.1439, -0.2980,  0.5364, -0.2417,\n",
      "         -0.6694,  1.5184],\n",
      "        [-1.1889, -1.2085, -1.2046, -1.1934, -0.5707, -0.6139, -0.7130, -0.2859,\n",
      "         -0.3550,  0.2040],\n",
      "        [-0.8302, -0.8363, -0.8299, -0.8087, -0.3768, -0.4613, -1.9286, -1.1746,\n",
      "         -1.3758,  0.5376],\n",
      "        [-0.9682, -0.9936, -1.0074, -0.9869, -0.5695, -0.5942, -1.0223, -0.2147,\n",
      "         -0.0588, -0.6040],\n",
      "        [ 0.7778,  0.7215,  0.6094,  0.6571,  3.0120,  3.1018, -1.1004, -0.2569,\n",
      "          0.1444, -1.5049],\n",
      "        [-0.1602, -0.1495, -0.1201, -0.2054,  0.4279,  0.2505, -0.6146, -0.0844,\n",
      "          0.4053, -1.7985],\n",
      "        [ 1.3256,  1.2856,  1.1852,  1.2442, -0.2390, -0.0111, -0.7443, -1.2891,\n",
      "         -1.4920,  0.5247]])\n"
     ]
    }
   ],
   "source": [
    "print(decode)\n",
    "print(target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

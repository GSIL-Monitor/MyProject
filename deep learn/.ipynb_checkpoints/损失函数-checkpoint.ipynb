{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "    1、softmax    \n",
    "        函数 Softmax(x) 也是一个 non-linearity, 但它的特殊之处在于它通常是网络中一次操作. 这是因为它接受了一个实数向量并返回一个概率分布.其定义如下. 定义 x 是一个实数的向量(正数或负数都无所谓, 没有限制). 然后, 第i个 Softmax(x) 的组成是 \n",
    "\n",
    "![Image of Yaktocat](https://img-blog.csdn.net/20161011083834897) \n",
    "    \n",
    "        输出是一个概率分布: 每个元素都是非负的, 并且所有元素的总和都是1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# cross entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "    交叉熵损失函数, 交叉熵描述了两个概率分布之间的距离，当交叉熵越小说明二者之间越接近。\n",
    "\n",
    "![Image of Yaktocat](https://img-blog.csdn.net/20161011083834897) \n",
    "\n",
    "    1、交叉熵原理  https://blog.csdn.net/xg123321123/article/details/52864830\n",
    "    \n",
    "    1) 信息量\n",
    "        信息量是用来衡量一个事件的不确定性的；一个事件发生的概率越大，不确定性越小，则它所携带的信息量就越小。\n",
    "        \n",
    "        假设X是一个离散型随机变量，其取值集合为X，概率分布函数为p(x)=Pr(X=x),x∈X，我们定义事件X=x0的信息量为：I(x0)=−log(p(x0))\n",
    "        当p(x0)=1时，熵将等于0，也就是说该事件的发生不会导致任何信息量的增加。\n",
    "\n",
    "        举个例子，小明考试经常不及格，而小王则经常得满分，所以我们可以做如下假设：\n",
    "        \n",
    "        事件A：小明考试及格\n",
    "        概率为\n",
    "            P(xA)=0.1\n",
    "        信息量为\n",
    "            I(xA)=−log(0.1)=3.3219\n",
    "            \n",
    "        事件B：小王考试及格\n",
    "        概率为\n",
    "            P(xB)=0.999\n",
    "        信息量为\n",
    "            I(xB)=−log(0.999)=0.0014\n",
    "\n",
    "        可以看出：小明及格的可能性很低(10次考试只有1次及格)，因此如果某次考试及格了（大家都会说：XXX竟然及格了！），必然会引入较大的信息量，对应的I值也较高;而对于小王而言，考试及格是大概率事件，在事件B发生前，大家普遍认为事件B的发生几乎是确定的，因此当某次考试小王及格这个事件发生时并不会引入太多的信息量，相应的I值也非常的低。\n",
    "\n",
    "        这跟《黑天鹅》一书中强调的“黑天鹅事件往往有重大影响”有异曲同工之妙。\n",
    "        \n",
    "    2) 熵\n",
    "        \n",
    "        是用来衡量一个系统的混乱程度的，代表一个系统中信息量的总和；信息量总和越大，表明这个系统不确定性就越大。\n",
    "        假设小明的考试结果是一个0-1分布XA\n",
    "        只有两个取值{0：不及格，1：及格}。那么在某次考试结果公布前，根据先验知识，小明及格的概率仅有10%,其余90%的可能都是不及格的。\n",
    "        在上面章节，我们可以分别得到小明和小王考试及格对应的信息量。\n",
    "        而如果我们想要进一步度量小明考试结果的不确定度，就要借助于熵的概念。\n",
    "        信息量用来衡量一个事件的不确定度，熵则用来衡量一个系统（也就是所有事件）的不确定度。\n",
    "        那如何度量系统中所有事件的不确定度？期望。\n",
    "    \n",
    "        我们对所有可能事件所带来的信息量求期望，其结果就能衡量小明考试的不确定度：\n",
    "        HA(x)=−[p(xA)log(p(xA))+(1−p(xA))log(1−p(xA))]=0.4690\n",
    "        \n",
    "        与之对应地，小王的熵：\n",
    "        HB(x)=−[p(xB)log(p(xB))+(1−p(xB))log(1−p(xB))]=0.0114\n",
    "        \n",
    "        虽然小明考试结果的不确定度较低，毕竟十次有9次都不及格；但是小王考试结果的不确定度更低，1000次考试只有1次不及格的机会，结果相当的确定。\n",
    "\n",
    "        再假设一个成绩相对普通的学生小东，他及格的概率是P(xC)=0.5,即及格与否的概率是一样的，对应的熵：\n",
    "        HC(x)=−[p(xC)log(p(xC))+(1−p(xC))log(1−p(xC))]=1\n",
    "\n",
    "        小东考试结果的不确定度比前边两位同学要高很多，在成绩公布之前，很难准确猜测出他的考试结果。\n",
    "        \n",
    "        \n",
    "        对于一个随机变量X，它所有可能取值的信息量的期望E[I(x)]\n",
    "\n",
    "        就称为熵。\n",
    "            X的熵定义为：\n",
    "            H(X)=Eplog1p(x)=−∑x∈Xp(x)logp(x)\n",
    "\n",
    "            如果p(x)是连续型随机变量的p(df)，则熵定义为：\n",
    "            H(X)=−∫x∈Xp(x)logp(x)dx\n",
    "\n",
    "\n",
    "        为了保证有效性，这里约定当p(x)→0时,有p(x)logp(x)→0\n",
    "\n",
    "        假如X为0-1分布，当两种取值的可能性相等时（p=0.5），不确定度最大（此时没有任何先验知识）；当p=0或1时，熵为0，即此时X完全确定。\n",
    "        \n",
    "    3) 条件熵\n",
    "        在随机变量X发生的前提下，随机变量Y发生所新带来的熵定义为Y的条件熵，用H(Y|X)表示，用来衡量在已知随机变量X的条件下随机变量Y的不确定性。\n",
    "        \n",
    "    4) 相对熵\n",
    "        相对熵(relative entropy)又称为KL散度(Kullback-Leibler divergence)，KL距离，是两个随机分布间距离的度量。记为DKL(p||q),它度量当真实分布为p时，假设分布q的无效性。\n",
    "        \n",
    "    5) 交叉熵\n",
    "        交叉熵容易跟相对熵搞混，二者有所区别。\n",
    "        假设有两个分布p，q，它们在给定样本集上的交叉熵定义如下：\n",
    "        CEH(p,q)=Ep[−logq]=−∑x∈χp(x)logq(x)=H(p)+DKL(p||q)\n",
    "        \n",
    "        当p已知时，可以把H(p)看做一个常数，此时交叉熵与KL距离在行为上是等价的，都反映了分布p，q的相似程度。 \n",
    "        \n",
    "        最小化交叉熵等于最小化KL距离。它们都将在p=q时取得最小值H(p)（因为p=q时KL距离为0，因此有的工程文献中将最小化KL距离的方法称为Principle of Minimum Cross-Entropy (MCE)或Minxent方法）。\n",
    "        \n",
    "        在logistic regression中， \n",
    "            p:真实样本分布，服从参数为p的0-1分布，即X∼B(1,p) \n",
    "            q:待估计的模型，服从参数为q的0-1分布，即X∼B(1,q) \n",
    "            两者的交叉熵为： \n",
    "                CEH(p,q)=−∑x∈χp(x)logq(x)\n",
    "\n",
    "                =−[Pp(x=1)logPq(x=1)+Pp(x=0)logPq(x=0)]\n",
    "                =−[plogq+(1−p)log(1−q)]\n",
    "                =−[yloghθ(x)+(1−y)log(1−hθ(x))]\n",
    "\n",
    "        对所有训练样本取均值得：\n",
    "            −1m∑im=1m[y(i)loghθ(x(i))+(1−y(i))log(1−hθ(x(i)))]\n",
    "\n",
    "        这个结果与通过最大似然估计方法求出来的结果一致。\n",
    "        \n",
    "        \n",
    "        \n",
    "    2、交叉熵损失函数\n",
    "        尽管交叉熵刻画的是两个概率分布之间的距离，但是神经网络的输出却不一定是一个概率分布。为此我们常常用Softmax回归将神经网络前向传播得到的结果变成概率分布。 \n",
    "\n",
    "    softmax常用于多分类过程中，它将多个神经元的输出，归一化到( 0, 1) 区间内，因此Softmax的输出可以看成概率，从而来进行多分类。\n",
    "    Cross Entropy Loss的公式：Hy‘(y):=−∑iy′ilog(yi)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.9000],\n",
      "        [0.0000, 0.0000, 0.9404],\n",
      "        [0.0000, 0.0000, 0.9404]], dtype=torch.float64, requires_grad=True)\n",
      "torch.Size([3, 3])\n",
      "tensor([[0.0000, 0.0000, 0.9000],\n",
      "        [0.0000, 0.0000, 0.9404],\n",
      "        [0.0000, 0.0000, 0.9404]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([0, 1, 2])\n",
      "tensor([[-0.2586,  0.0747,  0.1838],\n",
      "        [ 0.0731, -0.2603,  0.1872],\n",
      "        [ 0.0731,  0.0731, -0.1462]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "loss = nn.CrossEntropyLoss()\n",
    "aaa = np.array([[0,0,0.9],[0,0,0.9404],[0,0,0.9404]])\n",
    "input = torch.from_numpy(aaa)\n",
    "input.requires_grad=True\n",
    "print(input)\n",
    "print(input.size())\n",
    "target = torch.from_numpy(np.array([0,1,2]))\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "\n",
    "print(input)\n",
    "print(target)\n",
    "print(input.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

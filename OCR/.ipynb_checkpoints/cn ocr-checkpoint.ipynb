{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "\n",
    "# https://github.com/BelBES/crnn-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................\n",
      "Written 1000 / 1438\n",
      "Created dataset with 1438 samples\n"
     ]
    }
   ],
   "source": [
    "import lib.data.gen_data as gd\n",
    "import lib.data.dataset as ds\n",
    "import lib.data.char as char\n",
    "import importlib\n",
    "importlib.reload(gd)\n",
    "importlib.reload(char)\n",
    "\n",
    "# 生成文字图片\n",
    "gd.create_data(1000)\n",
    "\n",
    "# 根据生成文字图片，保存到lmdb\n",
    "ds.main_create_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.data.lmdb_dataset as lds\n",
    "import torch\n",
    "train_path = '/home/hecong/temp/data/ocr/lmdb'\n",
    "batchSize = 5\n",
    "sampler = None\n",
    "workers = 1\n",
    "imgH = 32\n",
    "imgW = 256\n",
    "\n",
    "train_dataset = lds.lmdbDataset(root=train_path)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batchSize,\n",
    "    shuffle=True,\n",
    "    sampler=sampler,\n",
    "    num_workers=int(workers),\n",
    "    collate_fn=lds.alignCollate(imgH=imgH, imgW=imgW, keep_ratio=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('洁洪洒浇浊洞测洗活派', '狡狱狠贸怨急饶蚀饺饼', '羽观欢买红纤级约纪驰', '夕丸么广亡门义之尸弓', '勉狭狮独狡狱狠贸怨急')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "_,(image,label) = next(enumerate(train_loader))\n",
    "image_0 = image[0][0]\n",
    "image_0 = image_0.numpy()\n",
    "print(label)\n",
    "plt.imshow(image_0,'gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "\n",
    "# custom weights initialization called on crnn\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def data_parallel(model, input, ngpu):\n",
    "    if ngpu > 1 and isinstance(input.data, torch.cuda.FloatTensor):\n",
    "        output = nn.parallel.data_parallel(model, input, range(ngpu))\n",
    "    else:\n",
    "        output = model(input)\n",
    "    return output\n",
    "    \n",
    "class BidirectionalLSTM(nn.Module):\n",
    "    def __init__(self, nIn, nHidden, nOut, ngpu):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True)\n",
    "        self.embedding = nn.Linear(nHidden * 2, nOut)\n",
    "\n",
    "    def forward(self, input):\n",
    "        recurrent, _ = data_parallel(self.rnn, input,\n",
    "                                           self.ngpu)  # [T, b, h * 2]\n",
    "        T, b, h = recurrent.size()\n",
    "        t_rec = recurrent.view(T * b, h)\n",
    "        output = data_parallel(self.embedding, \n",
    "                               t_rec,self.ngpu)  # [T * b, nOut]\n",
    "        output = output.view(T, b, -1)\n",
    "        return output\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, imgH, nc, nclass, nh, ngpu, n_rnn=2, leakyRelu=False):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        assert imgH % 16 == 0, 'imgH has to be a multiple of 16'\n",
    "\n",
    "        ks = [3, 3, 3, 3, 3, 3, 2]\n",
    "        ps = [1, 1, 1, 1, 1, 1, 0]\n",
    "        ss = [1, 1, 1, 1, 1, 1, 1]\n",
    "        nm = [64, 128, 256, 256, 512, 512, 512]\n",
    "\n",
    "        cnn = nn.Sequential()\n",
    "\n",
    "        def convRelu(i, batchNormalization=False):\n",
    "            nIn = nc if i == 0 else nm[i - 1]\n",
    "            nOut = nm[i]\n",
    "            cnn.add_module('conv{0}'.format(i),\n",
    "                           nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\n",
    "            if batchNormalization:\n",
    "                cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut))\n",
    "            if leakyRelu:\n",
    "                cnn.add_module('relu{0}'.format(i),\n",
    "                               nn.LeakyReLU(0.2, inplace=True))\n",
    "            else:\n",
    "                cnn.add_module('relu{0}'.format(i), nn.ReLU(True))\n",
    "                                                                    \n",
    "        convRelu(0)\n",
    "        cnn.add_module('pooling{0}'.format(0), nn.MaxPool2d(2, 2))  # 64x16x64\n",
    "        convRelu(1)\n",
    "        cnn.add_module('pooling{0}'.format(1), nn.MaxPool2d(2, 2))  # 128x8x32\n",
    "        convRelu(2, True)\n",
    "        convRelu(3)\n",
    "        # pool = nn.MaxPool2d(kernel_size=2, stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
    "        # 注意MaxPool2d 当stride = (2,1),表示只会根据H轴方向进行Pool，因为W方向是1。\n",
    "        cnn.add_module('pooling{0}'.format(2),\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 256x4x16\n",
    "        convRelu(4, True)\n",
    "        convRelu(5)\n",
    "        cnn.add_module('pooling{0}'.format(3),\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 512x2x16\n",
    "        convRelu(6, True)  # 512x1x16\n",
    "\n",
    "        self.cnn = cnn\n",
    "        self.rnn = nn.Sequential(\n",
    "            BidirectionalLSTM(512, nh, nh, ngpu),\n",
    "            BidirectionalLSTM(nh, nh, nclass, ngpu))\n",
    "\n",
    "    def forward(self, input):\n",
    "        # conv features\n",
    "#         print('input size --> {}'.format(input.size()))\n",
    "        conv = data_parallel(self.cnn, input, self.ngpu)\n",
    "        b, c, h, w = conv.size()\n",
    "#         print('conv out size --> {}'.format(conv.size()))\n",
    "        assert h == 1, \"the height of conv must be 1\"\n",
    "        conv = conv.squeeze(2)\n",
    "        conv = conv.permute(2, 0, 1)  # [w, b, c]\n",
    "        \n",
    "        # rnn features\n",
    "        output = data_parallel(self.rnn, conv, self.ngpu)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:0 loss --> tensor([320.7214], grad_fn=<DivBackward0>)\n",
      "0:10 loss --> tensor([77.6259], grad_fn=<DivBackward0>)\n",
      "0:20 loss --> tensor([90.4536], grad_fn=<DivBackward0>)\n",
      "0:30 loss --> tensor([78.0594], grad_fn=<DivBackward0>)\n",
      "0:40 loss --> tensor([74.9094], grad_fn=<DivBackward0>)\n",
      "0:50 loss --> tensor([74.5928], grad_fn=<DivBackward0>)\n",
      "0:60 loss --> tensor([74.6056], grad_fn=<DivBackward0>)\n",
      "0:70 loss --> tensor([74.7702], grad_fn=<DivBackward0>)\n",
      "0:80 loss --> tensor([74.7112], grad_fn=<DivBackward0>)\n",
      "0:90 loss --> tensor([74.5401], grad_fn=<DivBackward0>)\n",
      "0:100 loss --> tensor([74.8786], grad_fn=<DivBackward0>)\n",
      "0:110 loss --> tensor([74.5008], grad_fn=<DivBackward0>)\n",
      "0:120 loss --> tensor([74.8326], grad_fn=<DivBackward0>)\n",
      "0:130 loss --> tensor([74.4863], grad_fn=<DivBackward0>)\n",
      "0:140 loss --> tensor([74.9165], grad_fn=<DivBackward0>)\n",
      "0:150 loss --> tensor([74.8420], grad_fn=<DivBackward0>)\n",
      "0:160 loss --> tensor([74.6646], grad_fn=<DivBackward0>)\n",
      "0:170 loss --> tensor([74.7253], grad_fn=<DivBackward0>)\n",
      "0:180 loss --> tensor([74.5925], grad_fn=<DivBackward0>)\n",
      "0:190 loss --> tensor([74.8873], grad_fn=<DivBackward0>)\n",
      "0:200 loss --> tensor([74.7502], grad_fn=<DivBackward0>)\n",
      "0:210 loss --> tensor([74.6710], grad_fn=<DivBackward0>)\n",
      "0:220 loss --> tensor([74.7576], grad_fn=<DivBackward0>)\n",
      "0:230 loss --> tensor([74.5079], grad_fn=<DivBackward0>)\n",
      "0:240 loss --> tensor([74.3797], grad_fn=<DivBackward0>)\n",
      "0:250 loss --> tensor([74.8753], grad_fn=<DivBackward0>)\n",
      "0:260 loss --> tensor([74.8643], grad_fn=<DivBackward0>)\n",
      "0:270 loss --> tensor([74.9939], grad_fn=<DivBackward0>)\n",
      "0:280 loss --> tensor([74.8048], grad_fn=<DivBackward0>)\n",
      "1:0 loss --> tensor([74.6238], grad_fn=<DivBackward0>)\n",
      "1:10 loss --> tensor([74.4460], grad_fn=<DivBackward0>)\n",
      "1:20 loss --> tensor([74.5399], grad_fn=<DivBackward0>)\n",
      "1:30 loss --> tensor([74.4087], grad_fn=<DivBackward0>)\n",
      "1:40 loss --> tensor([74.4185], grad_fn=<DivBackward0>)\n",
      "1:50 loss --> tensor([74.6997], grad_fn=<DivBackward0>)\n",
      "1:60 loss --> tensor([74.4738], grad_fn=<DivBackward0>)\n",
      "1:70 loss --> tensor([74.5090], grad_fn=<DivBackward0>)\n",
      "1:80 loss --> tensor([74.5170], grad_fn=<DivBackward0>)\n",
      "1:90 loss --> tensor([74.9374], grad_fn=<DivBackward0>)\n",
      "1:100 loss --> tensor([74.4935], grad_fn=<DivBackward0>)\n",
      "1:110 loss --> tensor([74.9134], grad_fn=<DivBackward0>)\n",
      "1:120 loss --> tensor([74.6407], grad_fn=<DivBackward0>)\n",
      "1:130 loss --> tensor([74.7600], grad_fn=<DivBackward0>)\n",
      "1:140 loss --> tensor([74.6085], grad_fn=<DivBackward0>)\n",
      "1:150 loss --> tensor([74.3856], grad_fn=<DivBackward0>)\n",
      "1:160 loss --> tensor([74.6188], grad_fn=<DivBackward0>)\n",
      "1:170 loss --> tensor([74.8146], grad_fn=<DivBackward0>)\n",
      "1:180 loss --> tensor([75.0348], grad_fn=<DivBackward0>)\n",
      "1:190 loss --> tensor([75.0923], grad_fn=<DivBackward0>)\n",
      "1:200 loss --> tensor([74.9815], grad_fn=<DivBackward0>)\n",
      "1:210 loss --> tensor([74.2977], grad_fn=<DivBackward0>)\n",
      "1:220 loss --> tensor([74.7926], grad_fn=<DivBackward0>)\n",
      "1:230 loss --> tensor([74.9978], grad_fn=<DivBackward0>)\n",
      "1:240 loss --> tensor([74.2882], grad_fn=<DivBackward0>)\n",
      "1:250 loss --> tensor([74.5123], grad_fn=<DivBackward0>)\n",
      "1:260 loss --> tensor([74.4323], grad_fn=<DivBackward0>)\n",
      "1:270 loss --> tensor([74.3661], grad_fn=<DivBackward0>)\n",
      "1:280 loss --> tensor([74.1350], grad_fn=<DivBackward0>)\n",
      "2:0 loss --> tensor([74.2670], grad_fn=<DivBackward0>)\n",
      "2:10 loss --> tensor([74.4788], grad_fn=<DivBackward0>)\n",
      "2:20 loss --> tensor([74.2000], grad_fn=<DivBackward0>)\n",
      "2:30 loss --> tensor([74.6015], grad_fn=<DivBackward0>)\n",
      "2:40 loss --> tensor([74.9512], grad_fn=<DivBackward0>)\n",
      "2:50 loss --> tensor([74.7244], grad_fn=<DivBackward0>)\n",
      "2:60 loss --> tensor([74.0441], grad_fn=<DivBackward0>)\n",
      "2:70 loss --> tensor([73.9548], grad_fn=<DivBackward0>)\n",
      "2:80 loss --> tensor([74.2193], grad_fn=<DivBackward0>)\n",
      "2:90 loss --> tensor([75.0695], grad_fn=<DivBackward0>)\n",
      "2:100 loss --> tensor([75.2703], grad_fn=<DivBackward0>)\n",
      "2:110 loss --> tensor([74.2303], grad_fn=<DivBackward0>)\n",
      "2:120 loss --> tensor([74.8664], grad_fn=<DivBackward0>)\n",
      "2:130 loss --> tensor([74.1725], grad_fn=<DivBackward0>)\n",
      "2:140 loss --> tensor([74.0978], grad_fn=<DivBackward0>)\n",
      "2:150 loss --> tensor([74.5182], grad_fn=<DivBackward0>)\n",
      "2:160 loss --> tensor([74.5768], grad_fn=<DivBackward0>)\n",
      "2:170 loss --> tensor([75.3822], grad_fn=<DivBackward0>)\n",
      "2:180 loss --> tensor([73.7337], grad_fn=<DivBackward0>)\n",
      "2:190 loss --> tensor([75.1359], grad_fn=<DivBackward0>)\n",
      "2:200 loss --> tensor([74.2936], grad_fn=<DivBackward0>)\n",
      "2:210 loss --> tensor([74.6363], grad_fn=<DivBackward0>)\n",
      "2:220 loss --> tensor([74.3765], grad_fn=<DivBackward0>)\n",
      "2:230 loss --> tensor([74.2083], grad_fn=<DivBackward0>)\n",
      "2:240 loss --> tensor([74.0749], grad_fn=<DivBackward0>)\n",
      "2:250 loss --> tensor([74.2593], grad_fn=<DivBackward0>)\n",
      "2:260 loss --> tensor([73.6831], grad_fn=<DivBackward0>)\n",
      "2:270 loss --> tensor([74.7948], grad_fn=<DivBackward0>)\n",
      "2:280 loss --> tensor([75.0432], grad_fn=<DivBackward0>)\n",
      "3:0 loss --> tensor([73.8727], grad_fn=<DivBackward0>)\n",
      "3:10 loss --> tensor([75.3526], grad_fn=<DivBackward0>)\n",
      "3:20 loss --> tensor([74.8480], grad_fn=<DivBackward0>)\n",
      "3:30 loss --> tensor([74.7225], grad_fn=<DivBackward0>)\n",
      "3:40 loss --> tensor([74.2434], grad_fn=<DivBackward0>)\n",
      "3:50 loss --> tensor([74.6806], grad_fn=<DivBackward0>)\n",
      "3:60 loss --> tensor([73.7161], grad_fn=<DivBackward0>)\n",
      "3:70 loss --> tensor([73.9430], grad_fn=<DivBackward0>)\n",
      "3:80 loss --> tensor([74.0730], grad_fn=<DivBackward0>)\n",
      "3:90 loss --> tensor([74.8521], grad_fn=<DivBackward0>)\n",
      "3:100 loss --> tensor([73.9560], grad_fn=<DivBackward0>)\n",
      "3:110 loss --> tensor([75.5831], grad_fn=<DivBackward0>)\n",
      "3:120 loss --> tensor([74.8162], grad_fn=<DivBackward0>)\n",
      "3:130 loss --> tensor([74.4440], grad_fn=<DivBackward0>)\n",
      "3:140 loss --> tensor([73.6391], grad_fn=<DivBackward0>)\n",
      "3:150 loss --> tensor([74.0962], grad_fn=<DivBackward0>)\n",
      "3:160 loss --> tensor([74.3976], grad_fn=<DivBackward0>)\n",
      "3:170 loss --> tensor([73.4849], grad_fn=<DivBackward0>)\n",
      "3:180 loss --> tensor([73.7839], grad_fn=<DivBackward0>)\n",
      "3:190 loss --> tensor([75.4352], grad_fn=<DivBackward0>)\n",
      "3:200 loss --> tensor([73.8650], grad_fn=<DivBackward0>)\n",
      "3:210 loss --> tensor([74.5873], grad_fn=<DivBackward0>)\n",
      "3:220 loss --> tensor([75.2408], grad_fn=<DivBackward0>)\n",
      "3:230 loss --> tensor([74.4187], grad_fn=<DivBackward0>)\n",
      "3:240 loss --> tensor([75.4964], grad_fn=<DivBackward0>)\n",
      "3:250 loss --> tensor([74.3612], grad_fn=<DivBackward0>)\n",
      "3:260 loss --> tensor([74.6953], grad_fn=<DivBackward0>)\n",
      "3:270 loss --> tensor([75.3306], grad_fn=<DivBackward0>)\n",
      "3:280 loss --> tensor([73.9642], grad_fn=<DivBackward0>)\n",
      "4:0 loss --> tensor([74.2827], grad_fn=<DivBackward0>)\n",
      "4:10 loss --> tensor([74.5749], grad_fn=<DivBackward0>)\n",
      "4:20 loss --> tensor([72.6459], grad_fn=<DivBackward0>)\n",
      "4:30 loss --> tensor([75.5592], grad_fn=<DivBackward0>)\n",
      "4:40 loss --> tensor([72.5492], grad_fn=<DivBackward0>)\n",
      "4:50 loss --> tensor([73.4307], grad_fn=<DivBackward0>)\n",
      "4:60 loss --> tensor([72.0390], grad_fn=<DivBackward0>)\n",
      "4:70 loss --> tensor([73.2405], grad_fn=<DivBackward0>)\n",
      "4:80 loss --> tensor([75.1327], grad_fn=<DivBackward0>)\n",
      "4:90 loss --> tensor([74.4008], grad_fn=<DivBackward0>)\n",
      "4:100 loss --> tensor([74.0264], grad_fn=<DivBackward0>)\n",
      "4:110 loss --> tensor([74.0287], grad_fn=<DivBackward0>)\n",
      "4:120 loss --> tensor([74.3339], grad_fn=<DivBackward0>)\n",
      "4:130 loss --> tensor([74.7325], grad_fn=<DivBackward0>)\n",
      "4:140 loss --> tensor([75.6452], grad_fn=<DivBackward0>)\n",
      "4:150 loss --> tensor([73.7242], grad_fn=<DivBackward0>)\n",
      "4:160 loss --> tensor([73.6734], grad_fn=<DivBackward0>)\n",
      "4:170 loss --> tensor([71.8635], grad_fn=<DivBackward0>)\n",
      "4:180 loss --> tensor([74.5339], grad_fn=<DivBackward0>)\n",
      "4:190 loss --> tensor([72.8386], grad_fn=<DivBackward0>)\n",
      "4:200 loss --> tensor([73.7594], grad_fn=<DivBackward0>)\n",
      "4:210 loss --> tensor([75.5753], grad_fn=<DivBackward0>)\n",
      "4:220 loss --> tensor([72.2037], grad_fn=<DivBackward0>)\n",
      "4:230 loss --> tensor([74.9071], grad_fn=<DivBackward0>)\n",
      "4:240 loss --> tensor([73.8023], grad_fn=<DivBackward0>)\n",
      "4:250 loss --> tensor([75.8140], grad_fn=<DivBackward0>)\n",
      "4:260 loss --> tensor([73.7900], grad_fn=<DivBackward0>)\n",
      "4:270 loss --> tensor([75.0577], grad_fn=<DivBackward0>)\n",
      "4:280 loss --> tensor([73.5964], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5:0 loss --> tensor([72.8894], grad_fn=<DivBackward0>)\n",
      "5:10 loss --> tensor([71.3742], grad_fn=<DivBackward0>)\n",
      "5:20 loss --> tensor([73.2969], grad_fn=<DivBackward0>)\n",
      "5:30 loss --> tensor([74.3069], grad_fn=<DivBackward0>)\n",
      "5:40 loss --> tensor([72.9953], grad_fn=<DivBackward0>)\n",
      "5:50 loss --> tensor([74.3831], grad_fn=<DivBackward0>)\n",
      "5:60 loss --> tensor([71.3462], grad_fn=<DivBackward0>)\n",
      "5:70 loss --> tensor([72.5229], grad_fn=<DivBackward0>)\n",
      "5:80 loss --> tensor([73.1297], grad_fn=<DivBackward0>)\n",
      "5:90 loss --> tensor([73.6777], grad_fn=<DivBackward0>)\n",
      "5:100 loss --> tensor([73.7048], grad_fn=<DivBackward0>)\n",
      "5:110 loss --> tensor([72.7418], grad_fn=<DivBackward0>)\n",
      "5:120 loss --> tensor([74.8567], grad_fn=<DivBackward0>)\n",
      "5:130 loss --> tensor([73.2119], grad_fn=<DivBackward0>)\n",
      "5:140 loss --> tensor([75.4549], grad_fn=<DivBackward0>)\n",
      "5:150 loss --> tensor([72.4072], grad_fn=<DivBackward0>)\n",
      "5:160 loss --> tensor([72.1368], grad_fn=<DivBackward0>)\n",
      "5:170 loss --> tensor([74.2331], grad_fn=<DivBackward0>)\n",
      "5:180 loss --> tensor([73.9079], grad_fn=<DivBackward0>)\n",
      "5:190 loss --> tensor([75.6343], grad_fn=<DivBackward0>)\n",
      "5:200 loss --> tensor([73.3707], grad_fn=<DivBackward0>)\n",
      "5:210 loss --> tensor([72.9332], grad_fn=<DivBackward0>)\n",
      "5:220 loss --> tensor([75.5760], grad_fn=<DivBackward0>)\n",
      "5:230 loss --> tensor([73.9532], grad_fn=<DivBackward0>)\n",
      "5:240 loss --> tensor([72.6629], grad_fn=<DivBackward0>)\n",
      "5:250 loss --> tensor([74.1354], grad_fn=<DivBackward0>)\n",
      "5:260 loss --> tensor([72.9475], grad_fn=<DivBackward0>)\n",
      "5:270 loss --> tensor([73.9950], grad_fn=<DivBackward0>)\n",
      "5:280 loss --> tensor([73.1192], grad_fn=<DivBackward0>)\n",
      "6:0 loss --> tensor([72.8761], grad_fn=<DivBackward0>)\n",
      "6:10 loss --> tensor([74.8070], grad_fn=<DivBackward0>)\n",
      "6:20 loss --> tensor([75.7977], grad_fn=<DivBackward0>)\n",
      "6:30 loss --> tensor([72.1055], grad_fn=<DivBackward0>)\n",
      "6:40 loss --> tensor([70.9144], grad_fn=<DivBackward0>)\n",
      "6:50 loss --> tensor([72.5234], grad_fn=<DivBackward0>)\n",
      "6:60 loss --> tensor([73.1913], grad_fn=<DivBackward0>)\n",
      "6:70 loss --> tensor([74.9498], grad_fn=<DivBackward0>)\n",
      "6:80 loss --> tensor([73.9208], grad_fn=<DivBackward0>)\n",
      "6:90 loss --> tensor([72.4944], grad_fn=<DivBackward0>)\n",
      "6:100 loss --> tensor([71.9403], grad_fn=<DivBackward0>)\n",
      "6:110 loss --> tensor([73.7117], grad_fn=<DivBackward0>)\n",
      "6:120 loss --> tensor([71.5955], grad_fn=<DivBackward0>)\n",
      "6:130 loss --> tensor([71.4129], grad_fn=<DivBackward0>)\n",
      "6:140 loss --> tensor([74.4867], grad_fn=<DivBackward0>)\n",
      "6:150 loss --> tensor([74.3222], grad_fn=<DivBackward0>)\n",
      "6:160 loss --> tensor([75.1506], grad_fn=<DivBackward0>)\n",
      "6:170 loss --> tensor([72.1371], grad_fn=<DivBackward0>)\n",
      "6:180 loss --> tensor([74.7775], grad_fn=<DivBackward0>)\n",
      "6:190 loss --> tensor([73.5185], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-124:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hecong/tools/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/hecong/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/hecong/tools/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/hecong/tools/python3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/hecong/tools/python3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/hecong/tools/python3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/hecong/tools/python3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/hecong/tools/python3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-7be988c99af8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                         \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import lib.data.char as c\n",
    "from warpctc_pytorch import CTCLoss\n",
    "import lib.utils as utils\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "\n",
    "\n",
    "ngpu = 0\n",
    "# size of the lstm hidden state\n",
    "nh = 256\n",
    "nclass = len(c.alphabet) + 1\n",
    "# input channel ， 因为训练图片是转成灰度图，所以该值为1\n",
    "nc = 1\n",
    "lr = 0.001\n",
    "beta1=0.5\n",
    "MOMENTUM = 0.9\n",
    "EPOCH = 100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 字符转换编码\n",
    "converter = utils.strLabelConverter(c.alphabet)\n",
    "# 损失函数\n",
    "criterion = CTCLoss()\n",
    "\n",
    "crnn = CRNN(imgH, nc, nclass, nh, ngpu)\n",
    "crnn.apply(weights_init)\n",
    "if os.path.exists('/home/hecong/temp/data/ocr/simple_ocr.pkl'):\n",
    "    crnn.load_state_dict(torch.load('/home/hecong/temp/data/ocr/simple_ocr.pkl'))\n",
    "\n",
    "image = torch.FloatTensor(batchSize, 3, imgH, imgH)\n",
    "text = torch.IntTensor(batchSize * 5)\n",
    "length = torch.IntTensor(batchSize)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    crnn.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "# optimizer = optim.SGD(\n",
    "#     crnn.parameters(), lr=lr, momentum=MOMENTUM)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for step,(t_image,t_label) in enumerate(train_loader):\n",
    "        batch_size = t_image.size(0)\n",
    "        utils.loadData(image, t_image)\n",
    "        t, l = converter.encode(t_label)\n",
    "        utils.loadData(text, t)\n",
    "        utils.loadData(length, l)\n",
    "        preds = crnn(image)\n",
    "        preds_size = Variable(torch.IntTensor([preds.size(0)] * batch_size))\n",
    "        optimizer.zero_grad()\n",
    "        cost = criterion(preds, text, preds_size, length) / batch_size\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            print('{}:{} loss --> {}'.format(epoch, step, cost))\n",
    "            torch.save(crnn.state_dict(), '/home/hecong/temp/data/ocr/simple_ocr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49, 1, 42])\n",
      "torch.Size([10])\n",
      "tensor([ 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], dtype=torch.int32)\n",
      "tensor([49], dtype=torch.int32)\n",
      "tensor([1], dtype=torch.int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([12.0142], grad_fn=<_CTCBackward>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preds_size = torch.IntTensor([49])\n",
    "# length = torch.IntTensor([2])\n",
    "print(preds.size())\n",
    "print(text.size())\n",
    "print(text)\n",
    "print(preds_size)\n",
    "print(length)\n",
    "\n",
    "criterion(preds, text, preds_size, length)\n",
    "\n",
    "# prob size --> torch.Size([2, 1, 5])\n",
    "# labels size --> torch.Size([2])\n",
    "# prob sizes -->tensor([2], dtype=torch.int32)\n",
    "# label sizes -->tensor([2], dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(crnn.state_dict(), '/home/hecong/temp/data/ocr/simple_ocr.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.data.char as c\n",
    "import lib.utils as utils\n",
    "import os\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "\n",
    "\n",
    "ngpu = 0\n",
    "# size of the lstm hidden state\n",
    "nh = 256\n",
    "nclass = len(c.alphabet) + 1\n",
    "# input channel ， 因为训练图片是转成灰度图，所以该值为1\n",
    "nc = 1\n",
    "lr = 0.001\n",
    "beta1=0.5\n",
    "converter = utils.strLabelConverter(c.alphabet)\n",
    "\n",
    "crnn = CRNN(imgH, nc, nclass, nh, ngpu)\n",
    "crnn.apply(weights_init)\n",
    "if os.path.exists('/home/hecong/temp/data/ocr/simple_ocr.pkl'):\n",
    "    crnn.load_state_dict(torch.load('/home/hecong/temp/data/ocr/simple_ocr.pkl'))\n",
    "image = torch.FloatTensor(batchSize, 3, imgH, imgH)\n",
    "_,(v_image,v_text) = next(enumerate(train_loader))\n",
    "utils.loadData(image,v_image)\n",
    "preds_s = crnn(image)\n",
    "batch_size = v_image.size(0)\n",
    "preds_size = Variable(torch.IntTensor([preds_s.size(0)] * batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 49, 42])\n",
      "tensor([ 8,  8,  9,  9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16,\n",
      "        17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  2,  2,  3,\n",
      "         3,  4,  4,  4,  4,  5,  5,  6,  7,  7,  8,  8,  9,  9, 10, 10,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0, 30, 30, 30, 31, 31, 32, 32, 33, 33, 34,\n",
      "        34, 34, 35, 35, 35, 36, 36, 37, 37, 38, 38, 38, 39,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0, 20, 21, 21, 22, 22, 23, 23, 24, 24, 25, 25, 25, 26, 26, 27,\n",
      "        27, 28, 28, 29,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 23, 24,\n",
      "        24, 25, 25, 25, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30, 31, 31, 32,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "ghijklmn12'abcdefghiBCDEFGHIJK567890.[]A890.[]ABCD\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "preds = preds_s.clone()\n",
    "\n",
    "preds = preds.permute(1,0,2)\n",
    "print(preds.size())\n",
    "_,preds = preds.max(2)\n",
    "preds = preds.view(-1)\n",
    "print(preds)\n",
    "preds_size = Variable(torch.IntTensor([preds_s.size(0)])) * batchSize\n",
    "sim_preds = converter.decode(preds.data, preds_size.data, raw=False)\n",
    "\n",
    "print(sim_preds)\n",
    "image_0 = v_image[4][0]\n",
    "image_0 = image_0.numpy()\n",
    "plt.imshow(image_0,'gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.data.gen_data as gd\n",
    "import lib.data.dataset as ds\n",
    "\n",
    "# 生成文字图片\n",
    "gd.gen_data(100)\n",
    "\n",
    "# 根据生成文字图片，保存到lmdb\n",
    "ds.main_create_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.data.lmdb_dataset as lds\n",
    "import torch\n",
    "train_path = '/home/hecong/temp/data/ocr/lmdb'\n",
    "batchSize = 2\n",
    "sampler = None\n",
    "workers = 1\n",
    "imgH = 32\n",
    "imgW = 256\n",
    "\n",
    "train_dataset = lds.lmdbDataset(root=train_path)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batchSize,\n",
    "    shuffle=False,\n",
    "    sampler=sampler,\n",
    "    num_workers=int(workers),\n",
    "    collate_fn=lds.alignCollate(imgH=imgH, imgW=imgW, keep_ratio=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bcdefghijk', 'lmn1234567', ']ABCDEFGHI', '234567890.', 'klmn123456')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "_,(image,label) = next(enumerate(train_loader))\n",
    "image_0 = image[0][0]\n",
    "image_0 = image_0.numpy()\n",
    "print(label)\n",
    "plt.imshow(image_0,'gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "\n",
    "# custom weights initialization called on crnn\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def data_parallel(model, input, ngpu):\n",
    "    if ngpu > 1 and isinstance(input.data, torch.cuda.FloatTensor):\n",
    "        output = nn.parallel.data_parallel(model, input, range(ngpu))\n",
    "    else:\n",
    "        output = model(input)\n",
    "    return output\n",
    "    \n",
    "class BidirectionalLSTM(nn.Module):\n",
    "    def __init__(self, nIn, nHidden, nOut, ngpu):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True)\n",
    "        self.embedding = nn.Linear(nHidden * 2, nOut)\n",
    "\n",
    "    def forward(self, input):\n",
    "        recurrent, _ = data_parallel(self.rnn, input,\n",
    "                                           self.ngpu)  # [T, b, h * 2]\n",
    "        T, b, h = recurrent.size()\n",
    "        t_rec = recurrent.view(T * b, h)\n",
    "        output = data_parallel(self.embedding, \n",
    "                               t_rec,self.ngpu)  # [T * b, nOut]\n",
    "        output = output.view(T, b, -1)\n",
    "        return output\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, imgH, nc, nclass, nh, ngpu, n_rnn=2, leakyRelu=False):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        assert imgH % 16 == 0, 'imgH has to be a multiple of 16'\n",
    "\n",
    "        ks = [3, 3, 3, 3, 3, 3, 2]\n",
    "        ps = [1, 1, 1, 1, 1, 1, 0]\n",
    "        ss = [1, 1, 1, 1, 1, 1, 1]\n",
    "        nm = [64, 128, 256, 256, 512, 512, 512]\n",
    "\n",
    "        cnn = nn.Sequential()\n",
    "\n",
    "        def convRelu(i, batchNormalization=False):\n",
    "            nIn = nc if i == 0 else nm[i - 1]\n",
    "            nOut = nm[i]\n",
    "            cnn.add_module('conv{0}'.format(i),\n",
    "                           nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\n",
    "            if batchNormalization:\n",
    "                cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut))\n",
    "            if leakyRelu:\n",
    "                cnn.add_module('relu{0}'.format(i),\n",
    "                               nn.LeakyReLU(0.2, inplace=True))\n",
    "            else:\n",
    "                cnn.add_module('relu{0}'.format(i), nn.ReLU(True))\n",
    "                                                                    \n",
    "        convRelu(0)\n",
    "        cnn.add_module('pooling{0}'.format(0), nn.MaxPool2d(2, 2))  # 64x16x64\n",
    "        convRelu(1)\n",
    "        cnn.add_module('pooling{0}'.format(1), nn.MaxPool2d(2, 2))  # 128x8x32\n",
    "        convRelu(2, True)\n",
    "        convRelu(3)\n",
    "        # pool = nn.MaxPool2d(kernel_size=2, stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
    "        # 注意MaxPool2d 当stride = (2,1),表示只会根据H轴方向进行Pool，因为W方向是1。\n",
    "        cnn.add_module('pooling{0}'.format(2),\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 256x4x16\n",
    "        convRelu(4, True)\n",
    "        convRelu(5)\n",
    "        cnn.add_module('pooling{0}'.format(3),\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 512x2x16\n",
    "        convRelu(6, True)  # 512x1x16\n",
    "\n",
    "        self.cnn = cnn\n",
    "        self.rnn = nn.Sequential(\n",
    "            BidirectionalLSTM(512, nh, nh, ngpu),\n",
    "            BidirectionalLSTM(nh, nh, nclass, ngpu))\n",
    "\n",
    "    def forward(self, input):\n",
    "        # conv features\n",
    "#         print('input size --> {}'.format(input.size()))\n",
    "        conv = data_parallel(self.cnn, input, self.ngpu)\n",
    "        b, c, h, w = conv.size()\n",
    "#         print('conv out size --> {}'.format(conv.size()))\n",
    "        assert h == 1, \"the height of conv must be 1\"\n",
    "        conv = conv.squeeze(2)\n",
    "        conv = conv.permute(2, 0, 1)  # [w, b, c]\n",
    "        \n",
    "        # rnn features\n",
    "        output = data_parallel(self.rnn, conv, self.ngpu)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:0 loss --> tensor([178.9474], grad_fn=<DivBackward0>)\n",
      "0:10 loss --> tensor([4.3548], grad_fn=<DivBackward0>)\n",
      "0:20 loss --> tensor([4.4068], grad_fn=<DivBackward0>)\n",
      "1:0 loss --> tensor([4.6255], grad_fn=<DivBackward0>)\n",
      "1:10 loss --> tensor([4.3276], grad_fn=<DivBackward0>)\n",
      "1:20 loss --> tensor([4.2530], grad_fn=<DivBackward0>)\n",
      "2:0 loss --> tensor([4.5478], grad_fn=<DivBackward0>)\n",
      "2:10 loss --> tensor([4.3533], grad_fn=<DivBackward0>)\n",
      "2:20 loss --> tensor([4.1908], grad_fn=<DivBackward0>)\n",
      "3:0 loss --> tensor([4.5157], grad_fn=<DivBackward0>)\n",
      "3:10 loss --> tensor([4.3503], grad_fn=<DivBackward0>)\n",
      "3:20 loss --> tensor([4.1588], grad_fn=<DivBackward0>)\n",
      "4:0 loss --> tensor([4.4420], grad_fn=<DivBackward0>)\n",
      "4:10 loss --> tensor([4.3690], grad_fn=<DivBackward0>)\n",
      "4:20 loss --> tensor([4.1619], grad_fn=<DivBackward0>)\n",
      "5:0 loss --> tensor([4.3735], grad_fn=<DivBackward0>)\n",
      "5:10 loss --> tensor([4.2693], grad_fn=<DivBackward0>)\n",
      "5:20 loss --> tensor([4.1667], grad_fn=<DivBackward0>)\n",
      "6:0 loss --> tensor([4.0965], grad_fn=<DivBackward0>)\n",
      "6:10 loss --> tensor([4.1541], grad_fn=<DivBackward0>)\n",
      "6:20 loss --> tensor([3.9718], grad_fn=<DivBackward0>)\n",
      "7:0 loss --> tensor([4.1729], grad_fn=<DivBackward0>)\n",
      "7:10 loss --> tensor([4.0735], grad_fn=<DivBackward0>)\n",
      "7:20 loss --> tensor([4.2139], grad_fn=<DivBackward0>)\n",
      "8:0 loss --> tensor([4.1790], grad_fn=<DivBackward0>)\n",
      "8:10 loss --> tensor([4.1519], grad_fn=<DivBackward0>)\n",
      "8:20 loss --> tensor([4.4951], grad_fn=<DivBackward0>)\n",
      "9:0 loss --> tensor([4.1097], grad_fn=<DivBackward0>)\n",
      "9:10 loss --> tensor([4.2366], grad_fn=<DivBackward0>)\n",
      "9:20 loss --> tensor([4.7364], grad_fn=<DivBackward0>)\n",
      "10:0 loss --> tensor([3.9718], grad_fn=<DivBackward0>)\n",
      "10:10 loss --> tensor([4.2431], grad_fn=<DivBackward0>)\n",
      "10:20 loss --> tensor([3.8133], grad_fn=<DivBackward0>)\n",
      "11:0 loss --> tensor([3.9501], grad_fn=<DivBackward0>)\n",
      "11:10 loss --> tensor([4.1334], grad_fn=<DivBackward0>)\n",
      "11:20 loss --> tensor([3.5383], grad_fn=<DivBackward0>)\n",
      "12:0 loss --> tensor([3.8370], grad_fn=<DivBackward0>)\n",
      "12:10 loss --> tensor([5.3120], grad_fn=<DivBackward0>)\n",
      "12:20 loss --> tensor([3.5509], grad_fn=<DivBackward0>)\n",
      "13:0 loss --> tensor([3.8876], grad_fn=<DivBackward0>)\n",
      "13:10 loss --> tensor([4.6404], grad_fn=<DivBackward0>)\n",
      "13:20 loss --> tensor([3.5059], grad_fn=<DivBackward0>)\n",
      "14:0 loss --> tensor([3.8569], grad_fn=<DivBackward0>)\n",
      "14:10 loss --> tensor([4.6184], grad_fn=<DivBackward0>)\n",
      "14:20 loss --> tensor([3.4204], grad_fn=<DivBackward0>)\n",
      "15:0 loss --> tensor([3.8343], grad_fn=<DivBackward0>)\n",
      "15:10 loss --> tensor([3.6582], grad_fn=<DivBackward0>)\n",
      "15:20 loss --> tensor([3.3896], grad_fn=<DivBackward0>)\n",
      "16:0 loss --> tensor([3.7724], grad_fn=<DivBackward0>)\n",
      "16:10 loss --> tensor([3.6195], grad_fn=<DivBackward0>)\n",
      "16:20 loss --> tensor([3.3091], grad_fn=<DivBackward0>)\n",
      "17:0 loss --> tensor([3.7493], grad_fn=<DivBackward0>)\n",
      "17:10 loss --> tensor([3.8844], grad_fn=<DivBackward0>)\n",
      "17:20 loss --> tensor([3.3793], grad_fn=<DivBackward0>)\n",
      "18:0 loss --> tensor([3.9294], grad_fn=<DivBackward0>)\n",
      "18:10 loss --> tensor([3.8026], grad_fn=<DivBackward0>)\n",
      "18:20 loss --> tensor([3.2160], grad_fn=<DivBackward0>)\n",
      "19:0 loss --> tensor([3.7993], grad_fn=<DivBackward0>)\n",
      "19:10 loss --> tensor([3.1946], grad_fn=<DivBackward0>)\n",
      "19:20 loss --> tensor([3.0683], grad_fn=<DivBackward0>)\n",
      "20:0 loss --> tensor([3.6744], grad_fn=<DivBackward0>)\n",
      "20:10 loss --> tensor([3.1420], grad_fn=<DivBackward0>)\n",
      "20:20 loss --> tensor([3.4327], grad_fn=<DivBackward0>)\n",
      "21:0 loss --> tensor([3.9863], grad_fn=<DivBackward0>)\n",
      "21:10 loss --> tensor([5.1552], grad_fn=<DivBackward0>)\n",
      "21:20 loss --> tensor([4.1686], grad_fn=<DivBackward0>)\n",
      "22:0 loss --> tensor([4.0026], grad_fn=<DivBackward0>)\n",
      "22:10 loss --> tensor([4.7667], grad_fn=<DivBackward0>)\n",
      "22:20 loss --> tensor([4.2292], grad_fn=<DivBackward0>)\n",
      "23:0 loss --> tensor([4.0322], grad_fn=<DivBackward0>)\n",
      "23:10 loss --> tensor([4.1334], grad_fn=<DivBackward0>)\n",
      "23:20 loss --> tensor([4.3069], grad_fn=<DivBackward0>)\n",
      "24:0 loss --> tensor([4.0091], grad_fn=<DivBackward0>)\n",
      "24:10 loss --> tensor([4.1935], grad_fn=<DivBackward0>)\n",
      "24:20 loss --> tensor([4.2823], grad_fn=<DivBackward0>)\n",
      "25:0 loss --> tensor([3.9900], grad_fn=<DivBackward0>)\n",
      "25:10 loss --> tensor([4.1869], grad_fn=<DivBackward0>)\n",
      "25:20 loss --> tensor([4.0470], grad_fn=<DivBackward0>)\n",
      "26:0 loss --> tensor([3.9489], grad_fn=<DivBackward0>)\n",
      "26:10 loss --> tensor([4.1686], grad_fn=<DivBackward0>)\n",
      "26:20 loss --> tensor([4.2375], grad_fn=<DivBackward0>)\n",
      "27:0 loss --> tensor([3.9531], grad_fn=<DivBackward0>)\n",
      "27:10 loss --> tensor([4.0347], grad_fn=<DivBackward0>)\n",
      "27:20 loss --> tensor([3.6121], grad_fn=<DivBackward0>)\n",
      "28:0 loss --> tensor([3.7447], grad_fn=<DivBackward0>)\n",
      "28:10 loss --> tensor([3.4979], grad_fn=<DivBackward0>)\n",
      "28:20 loss --> tensor([2.9084], grad_fn=<DivBackward0>)\n",
      "29:0 loss --> tensor([3.6457], grad_fn=<DivBackward0>)\n",
      "29:10 loss --> tensor([2.7268], grad_fn=<DivBackward0>)\n",
      "29:20 loss --> tensor([2.6961], grad_fn=<DivBackward0>)\n",
      "30:0 loss --> tensor([3.6079], grad_fn=<DivBackward0>)\n",
      "30:10 loss --> tensor([2.7435], grad_fn=<DivBackward0>)\n",
      "30:20 loss --> tensor([2.7562], grad_fn=<DivBackward0>)\n",
      "31:0 loss --> tensor([3.5880], grad_fn=<DivBackward0>)\n",
      "31:10 loss --> tensor([2.5414], grad_fn=<DivBackward0>)\n",
      "31:20 loss --> tensor([2.7834], grad_fn=<DivBackward0>)\n",
      "32:0 loss --> tensor([3.6067], grad_fn=<DivBackward0>)\n",
      "32:10 loss --> tensor([2.1840], grad_fn=<DivBackward0>)\n",
      "32:20 loss --> tensor([2.2703], grad_fn=<DivBackward0>)\n",
      "33:0 loss --> tensor([3.6409], grad_fn=<DivBackward0>)\n",
      "33:10 loss --> tensor([1.8217], grad_fn=<DivBackward0>)\n",
      "33:20 loss --> tensor([2.5492], grad_fn=<DivBackward0>)\n",
      "34:0 loss --> tensor([3.5057], grad_fn=<DivBackward0>)\n",
      "34:10 loss --> tensor([3.0256], grad_fn=<DivBackward0>)\n",
      "34:20 loss --> tensor([2.3532], grad_fn=<DivBackward0>)\n",
      "35:0 loss --> tensor([3.4985], grad_fn=<DivBackward0>)\n",
      "35:10 loss --> tensor([2.0017], grad_fn=<DivBackward0>)\n",
      "35:20 loss --> tensor([2.1431], grad_fn=<DivBackward0>)\n",
      "36:0 loss --> tensor([3.8948], grad_fn=<DivBackward0>)\n",
      "36:10 loss --> tensor([1.7300], grad_fn=<DivBackward0>)\n",
      "36:20 loss --> tensor([2.5061], grad_fn=<DivBackward0>)\n",
      "37:0 loss --> tensor([3.4534], grad_fn=<DivBackward0>)\n",
      "37:10 loss --> tensor([1.7702], grad_fn=<DivBackward0>)\n",
      "37:20 loss --> tensor([1.9081], grad_fn=<DivBackward0>)\n",
      "38:0 loss --> tensor([3.4364], grad_fn=<DivBackward0>)\n",
      "38:10 loss --> tensor([1.7947], grad_fn=<DivBackward0>)\n",
      "38:20 loss --> tensor([1.3444], grad_fn=<DivBackward0>)\n",
      "39:0 loss --> tensor([3.3427], grad_fn=<DivBackward0>)\n",
      "39:10 loss --> tensor([1.6106], grad_fn=<DivBackward0>)\n",
      "39:20 loss --> tensor([3.6662], grad_fn=<DivBackward0>)\n",
      "40:0 loss --> tensor([3.5599], grad_fn=<DivBackward0>)\n",
      "40:10 loss --> tensor([4.5667], grad_fn=<DivBackward0>)\n",
      "40:20 loss --> tensor([1.7357], grad_fn=<DivBackward0>)\n",
      "41:0 loss --> tensor([3.6038], grad_fn=<DivBackward0>)\n",
      "41:10 loss --> tensor([2.1269], grad_fn=<DivBackward0>)\n",
      "41:20 loss --> tensor([2.1231], grad_fn=<DivBackward0>)\n",
      "42:0 loss --> tensor([4.5673], grad_fn=<DivBackward0>)\n",
      "42:10 loss --> tensor([1.6724], grad_fn=<DivBackward0>)\n",
      "42:20 loss --> tensor([1.5058], grad_fn=<DivBackward0>)\n",
      "43:0 loss --> tensor([4.6006], grad_fn=<DivBackward0>)\n",
      "43:10 loss --> tensor([1.4644], grad_fn=<DivBackward0>)\n",
      "43:20 loss --> tensor([1.2269], grad_fn=<DivBackward0>)\n",
      "44:0 loss --> tensor([3.4648], grad_fn=<DivBackward0>)\n",
      "44:10 loss --> tensor([1.4272], grad_fn=<DivBackward0>)\n",
      "44:20 loss --> tensor([1.2069], grad_fn=<DivBackward0>)\n",
      "45:0 loss --> tensor([3.4739], grad_fn=<DivBackward0>)\n",
      "45:10 loss --> tensor([1.2428], grad_fn=<DivBackward0>)\n",
      "45:20 loss --> tensor([1.9976], grad_fn=<DivBackward0>)\n",
      "46:0 loss --> tensor([3.2559], grad_fn=<DivBackward0>)\n",
      "46:10 loss --> tensor([1.2731], grad_fn=<DivBackward0>)\n",
      "46:20 loss --> tensor([2.0834], grad_fn=<DivBackward0>)\n",
      "47:0 loss --> tensor([3.5229], grad_fn=<DivBackward0>)\n",
      "47:10 loss --> tensor([1.1359], grad_fn=<DivBackward0>)\n",
      "47:20 loss --> tensor([1.2650], grad_fn=<DivBackward0>)\n",
      "48:0 loss --> tensor([4.1467], grad_fn=<DivBackward0>)\n",
      "48:10 loss --> tensor([1.0946], grad_fn=<DivBackward0>)\n",
      "48:20 loss --> tensor([1.0492], grad_fn=<DivBackward0>)\n",
      "49:0 loss --> tensor([2.7382], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49:10 loss --> tensor([1.1582], grad_fn=<DivBackward0>)\n",
      "49:20 loss --> tensor([0.7261], grad_fn=<DivBackward0>)\n",
      "50:0 loss --> tensor([2.2757], grad_fn=<DivBackward0>)\n",
      "50:10 loss --> tensor([0.9241], grad_fn=<DivBackward0>)\n",
      "50:20 loss --> tensor([0.5872], grad_fn=<DivBackward0>)\n",
      "51:0 loss --> tensor([2.2090], grad_fn=<DivBackward0>)\n",
      "51:10 loss --> tensor([0.8334], grad_fn=<DivBackward0>)\n",
      "51:20 loss --> tensor([0.5289], grad_fn=<DivBackward0>)\n",
      "52:0 loss --> tensor([2.0088], grad_fn=<DivBackward0>)\n",
      "52:10 loss --> tensor([0.9356], grad_fn=<DivBackward0>)\n",
      "52:20 loss --> tensor([0.7985], grad_fn=<DivBackward0>)\n",
      "53:0 loss --> tensor([1.6914], grad_fn=<DivBackward0>)\n",
      "53:10 loss --> tensor([1.4936], grad_fn=<DivBackward0>)\n",
      "53:20 loss --> tensor([0.5381], grad_fn=<DivBackward0>)\n",
      "54:0 loss --> tensor([1.7270], grad_fn=<DivBackward0>)\n",
      "54:10 loss --> tensor([0.7115], grad_fn=<DivBackward0>)\n",
      "54:20 loss --> tensor([0.9905], grad_fn=<DivBackward0>)\n",
      "55:0 loss --> tensor([1.4211], grad_fn=<DivBackward0>)\n",
      "55:10 loss --> tensor([1.0598], grad_fn=<DivBackward0>)\n",
      "55:20 loss --> tensor([0.7996], grad_fn=<DivBackward0>)\n",
      "56:0 loss --> tensor([1.4869], grad_fn=<DivBackward0>)\n",
      "56:10 loss --> tensor([0.8314], grad_fn=<DivBackward0>)\n",
      "56:20 loss --> tensor([0.4868], grad_fn=<DivBackward0>)\n",
      "57:0 loss --> tensor([1.5613], grad_fn=<DivBackward0>)\n",
      "57:10 loss --> tensor([0.8439], grad_fn=<DivBackward0>)\n",
      "57:20 loss --> tensor([0.3334], grad_fn=<DivBackward0>)\n",
      "58:0 loss --> tensor([1.5177], grad_fn=<DivBackward0>)\n",
      "58:10 loss --> tensor([1.3390], grad_fn=<DivBackward0>)\n",
      "58:20 loss --> tensor([0.3401], grad_fn=<DivBackward0>)\n",
      "59:0 loss --> tensor([2.8364], grad_fn=<DivBackward0>)\n",
      "59:10 loss --> tensor([0.4671], grad_fn=<DivBackward0>)\n",
      "59:20 loss --> tensor([0.4339], grad_fn=<DivBackward0>)\n",
      "60:0 loss --> tensor([1.4392], grad_fn=<DivBackward0>)\n",
      "60:10 loss --> tensor([0.4990], grad_fn=<DivBackward0>)\n",
      "60:20 loss --> tensor([0.5053], grad_fn=<DivBackward0>)\n",
      "61:0 loss --> tensor([1.1232], grad_fn=<DivBackward0>)\n",
      "61:10 loss --> tensor([0.7478], grad_fn=<DivBackward0>)\n",
      "61:20 loss --> tensor([0.7226], grad_fn=<DivBackward0>)\n",
      "62:0 loss --> tensor([0.9884], grad_fn=<DivBackward0>)\n",
      "62:10 loss --> tensor([0.5664], grad_fn=<DivBackward0>)\n",
      "62:20 loss --> tensor([0.4958], grad_fn=<DivBackward0>)\n",
      "63:0 loss --> tensor([0.6608], grad_fn=<DivBackward0>)\n",
      "63:10 loss --> tensor([0.4346], grad_fn=<DivBackward0>)\n",
      "63:20 loss --> tensor([0.4572], grad_fn=<DivBackward0>)\n",
      "64:0 loss --> tensor([0.5918], grad_fn=<DivBackward0>)\n",
      "64:10 loss --> tensor([0.4437], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import lib.data.char as c\n",
    "from warpctc_pytorch import CTCLoss\n",
    "import lib.utils as utils\n",
    "import torch.optim as optim\n",
    "\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "\n",
    "\n",
    "ngpu = 0\n",
    "# size of the lstm hidden state\n",
    "nh = 256\n",
    "nclass = len(c.alphabet) + 1\n",
    "# input channel ， 因为训练图片是转成灰度图，所以该值为1\n",
    "nc = 1\n",
    "lr = 0.001\n",
    "beta1=0.5\n",
    "EPOCH = 1000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 字符转换编码\n",
    "converter = utils.strLabelConverter(c.alphabet)\n",
    "# 损失函数\n",
    "criterion = CTCLoss()\n",
    "\n",
    "crnn = CRNN(imgH, nc, nclass, nh, ngpu)\n",
    "crnn.apply(weights_init)\n",
    "\n",
    "image = torch.FloatTensor(batchSize, 3, imgH, imgH)\n",
    "text = torch.IntTensor(batchSize * 5)\n",
    "length = torch.IntTensor(batchSize)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    crnn.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for step,(t_image,t_label) in enumerate(train_loader):\n",
    "        batch_size = t_image.size(0)\n",
    "        utils.loadData(image, t_image)\n",
    "        t, l = converter.encode(t_label)\n",
    "        utils.loadData(text, t)\n",
    "        utils.loadData(length, l)\n",
    "\n",
    "        preds = crnn(image)\n",
    "        preds_size = Variable(torch.IntTensor([preds.size(0)] * batch_size))\n",
    "        optimizer.zero_grad()\n",
    "        cost = criterion(preds, text, preds_size, length) / batch_size\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            print('{}:{} loss --> {}'.format(epoch, step, cost))\n",
    "            torch.save(net.state_dict(), '/home/hecong/temp/data/ocr/simple_ocr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49, 2, 42])\n",
      "torch.Size([20])\n",
      "tensor([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
      "        21, 22], dtype=torch.int32)\n",
      "tensor([49, 49], dtype=torch.int32)\n",
      "tensor([2], dtype=torch.int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([171.5280], grad_fn=<_CTCBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preds_size = torch.IntTensor([49])\n",
    "# length = torch.IntTensor([49])\n",
    "print(preds.size())\n",
    "print(text.size())\n",
    "print(text)\n",
    "print(preds_size)\n",
    "print(length)\n",
    "\n",
    "criterion(preds, text, preds_size, length)\n",
    "\n",
    "# prob size --> torch.Size([2, 1, 5])\n",
    "# labels size --> torch.Size([2])\n",
    "# prob sizes -->tensor([2], dtype=torch.int32)\n",
    "# label sizes -->tensor([2], dtype=torch.int32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

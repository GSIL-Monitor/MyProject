{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.data.gen_data as gd\n",
    "import lib.data.dataset as ds\n",
    "\n",
    "# 生成文字图片\n",
    "gd.gen_data(100)\n",
    "\n",
    "# 根据生成文字图片，保存到lmdb\n",
    "ds.main_create_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.data.lmdb_dataset as lds\n",
    "import torch\n",
    "train_path = '/home/hecong/temp/data/ocr/lmdb'\n",
    "batchSize = 2\n",
    "sampler = None\n",
    "workers = 1\n",
    "imgH = 32\n",
    "imgW = 256\n",
    "\n",
    "train_dataset = lds.lmdbDataset(root=train_path)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batchSize,\n",
    "    shuffle=False,\n",
    "    sampler=sampler,\n",
    "    num_workers=int(workers),\n",
    "    collate_fn=lds.alignCollate(imgH=imgH, imgW=imgW, keep_ratio=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bcdefghijk', 'lmn1234567', ']ABCDEFGHI', '234567890.', 'klmn123456')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "_,(image,label) = next(enumerate(train_loader))\n",
    "image_0 = image[0][0]\n",
    "image_0 = image_0.numpy()\n",
    "print(label)\n",
    "plt.imshow(image_0,'gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "\n",
    "# custom weights initialization called on crnn\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def data_parallel(model, input, ngpu):\n",
    "    if ngpu > 1 and isinstance(input.data, torch.cuda.FloatTensor):\n",
    "        output = nn.parallel.data_parallel(model, input, range(ngpu))\n",
    "    else:\n",
    "        output = model(input)\n",
    "    return output\n",
    "    \n",
    "class BidirectionalLSTM(nn.Module):\n",
    "    def __init__(self, nIn, nHidden, nOut, ngpu):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True)\n",
    "        self.embedding = nn.Linear(nHidden * 2, nOut)\n",
    "\n",
    "    def forward(self, input):\n",
    "        recurrent, _ = data_parallel(self.rnn, input,\n",
    "                                           self.ngpu)  # [T, b, h * 2]\n",
    "        T, b, h = recurrent.size()\n",
    "        t_rec = recurrent.view(T * b, h)\n",
    "        output = data_parallel(self.embedding, \n",
    "                               t_rec,self.ngpu)  # [T * b, nOut]\n",
    "        output = output.view(T, b, -1)\n",
    "        return output\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, imgH, nc, nclass, nh, ngpu, n_rnn=2, leakyRelu=False):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        assert imgH % 16 == 0, 'imgH has to be a multiple of 16'\n",
    "\n",
    "        ks = [3, 3, 3, 3, 3, 3, 2]\n",
    "        ps = [1, 1, 1, 1, 1, 1, 0]\n",
    "        ss = [1, 1, 1, 1, 1, 1, 1]\n",
    "        nm = [64, 128, 256, 256, 512, 512, 512]\n",
    "\n",
    "        cnn = nn.Sequential()\n",
    "\n",
    "        def convRelu(i, batchNormalization=False):\n",
    "            nIn = nc if i == 0 else nm[i - 1]\n",
    "            nOut = nm[i]\n",
    "            cnn.add_module('conv{0}'.format(i),\n",
    "                           nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\n",
    "            if batchNormalization:\n",
    "                cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut))\n",
    "            if leakyRelu:\n",
    "                cnn.add_module('relu{0}'.format(i),\n",
    "                               nn.LeakyReLU(0.2, inplace=True))\n",
    "            else:\n",
    "                cnn.add_module('relu{0}'.format(i), nn.ReLU(True))\n",
    "                                                                    \n",
    "        convRelu(0)\n",
    "        cnn.add_module('pooling{0}'.format(0), nn.MaxPool2d(2, 2))  # 64x16x64\n",
    "        convRelu(1)\n",
    "        cnn.add_module('pooling{0}'.format(1), nn.MaxPool2d(2, 2))  # 128x8x32\n",
    "        convRelu(2, True)\n",
    "        convRelu(3)\n",
    "        # pool = nn.MaxPool2d(kernel_size=2, stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
    "        # 注意MaxPool2d 当stride = (2,1),表示只会根据H轴方向进行Pool，因为W方向是1。\n",
    "        cnn.add_module('pooling{0}'.format(2),\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 256x4x16\n",
    "        convRelu(4, True)\n",
    "        convRelu(5)\n",
    "        cnn.add_module('pooling{0}'.format(3),\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 512x2x16\n",
    "        convRelu(6, True)  # 512x1x16\n",
    "\n",
    "        self.cnn = cnn\n",
    "        self.rnn = nn.Sequential(\n",
    "            BidirectionalLSTM(512, nh, nh, ngpu),\n",
    "            BidirectionalLSTM(nh, nh, nclass, ngpu))\n",
    "\n",
    "    def forward(self, input):\n",
    "        # conv features\n",
    "#         print('input size --> {}'.format(input.size()))\n",
    "        conv = data_parallel(self.cnn, input, self.ngpu)\n",
    "        b, c, h, w = conv.size()\n",
    "#         print('conv out size --> {}'.format(conv.size()))\n",
    "        assert h == 1, \"the height of conv must be 1\"\n",
    "        conv = conv.squeeze(2)\n",
    "        conv = conv.permute(2, 0, 1)  # [w, b, c]\n",
    "        \n",
    "        # rnn features\n",
    "        output = data_parallel(self.rnn, conv, self.ngpu)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:0 loss --> tensor([0.3532], grad_fn=<DivBackward0>)\n",
      "0:10 loss --> tensor([0.3041], grad_fn=<DivBackward0>)\n",
      "0:20 loss --> tensor([0.4410], grad_fn=<DivBackward0>)\n",
      "1:0 loss --> tensor([0.3675], grad_fn=<DivBackward0>)\n",
      "1:10 loss --> tensor([0.2539], grad_fn=<DivBackward0>)\n",
      "1:20 loss --> tensor([0.2896], grad_fn=<DivBackward0>)\n",
      "2:0 loss --> tensor([0.2045], grad_fn=<DivBackward0>)\n",
      "2:10 loss --> tensor([0.2958], grad_fn=<DivBackward0>)\n",
      "2:20 loss --> tensor([0.2850], grad_fn=<DivBackward0>)\n",
      "3:0 loss --> tensor([0.1428], grad_fn=<DivBackward0>)\n",
      "3:10 loss --> tensor([0.1936], grad_fn=<DivBackward0>)\n",
      "3:20 loss --> tensor([0.2244], grad_fn=<DivBackward0>)\n",
      "4:0 loss --> tensor([0.1102], grad_fn=<DivBackward0>)\n",
      "4:10 loss --> tensor([0.1454], grad_fn=<DivBackward0>)\n",
      "4:20 loss --> tensor([0.1879], grad_fn=<DivBackward0>)\n",
      "5:0 loss --> tensor([0.0654], grad_fn=<DivBackward0>)\n",
      "5:10 loss --> tensor([0.1203], grad_fn=<DivBackward0>)\n",
      "5:20 loss --> tensor([0.1348], grad_fn=<DivBackward0>)\n",
      "6:0 loss --> tensor([0.0528], grad_fn=<DivBackward0>)\n",
      "6:10 loss --> tensor([0.0752], grad_fn=<DivBackward0>)\n",
      "6:20 loss --> tensor([0.1153], grad_fn=<DivBackward0>)\n",
      "7:0 loss --> tensor([0.0391], grad_fn=<DivBackward0>)\n",
      "7:10 loss --> tensor([0.0822], grad_fn=<DivBackward0>)\n",
      "7:20 loss --> tensor([0.0794], grad_fn=<DivBackward0>)\n",
      "8:0 loss --> tensor([0.0317], grad_fn=<DivBackward0>)\n",
      "8:10 loss --> tensor([0.0352], grad_fn=<DivBackward0>)\n",
      "8:20 loss --> tensor([0.0403], grad_fn=<DivBackward0>)\n",
      "9:0 loss --> tensor([0.0263], grad_fn=<DivBackward0>)\n",
      "9:10 loss --> tensor([0.0249], grad_fn=<DivBackward0>)\n",
      "9:20 loss --> tensor([0.0302], grad_fn=<DivBackward0>)\n",
      "10:0 loss --> tensor([0.0206], grad_fn=<DivBackward0>)\n",
      "10:10 loss --> tensor([0.0192], grad_fn=<DivBackward0>)\n",
      "10:20 loss --> tensor([0.0235], grad_fn=<DivBackward0>)\n",
      "11:0 loss --> tensor([0.0163], grad_fn=<DivBackward0>)\n",
      "11:10 loss --> tensor([0.0151], grad_fn=<DivBackward0>)\n",
      "11:20 loss --> tensor([0.0187], grad_fn=<DivBackward0>)\n",
      "12:0 loss --> tensor([0.0130], grad_fn=<DivBackward0>)\n",
      "12:10 loss --> tensor([0.0118], grad_fn=<DivBackward0>)\n",
      "12:20 loss --> tensor([0.0153], grad_fn=<DivBackward0>)\n",
      "13:0 loss --> tensor([0.0110], grad_fn=<DivBackward0>)\n",
      "13:10 loss --> tensor([0.0095], grad_fn=<DivBackward0>)\n",
      "13:20 loss --> tensor([0.0129], grad_fn=<DivBackward0>)\n",
      "14:0 loss --> tensor([0.0091], grad_fn=<DivBackward0>)\n",
      "14:10 loss --> tensor([0.0076], grad_fn=<DivBackward0>)\n",
      "14:20 loss --> tensor([0.0104], grad_fn=<DivBackward0>)\n",
      "15:0 loss --> tensor([0.0078], grad_fn=<DivBackward0>)\n",
      "15:10 loss --> tensor([0.0063], grad_fn=<DivBackward0>)\n",
      "15:20 loss --> tensor([0.0087], grad_fn=<DivBackward0>)\n",
      "16:0 loss --> tensor([0.0067], grad_fn=<DivBackward0>)\n",
      "16:10 loss --> tensor([0.0051], grad_fn=<DivBackward0>)\n",
      "16:20 loss --> tensor([0.0073], grad_fn=<DivBackward0>)\n",
      "17:0 loss --> tensor([0.0059], grad_fn=<DivBackward0>)\n",
      "17:10 loss --> tensor([0.0042], grad_fn=<DivBackward0>)\n",
      "17:20 loss --> tensor([0.0066], grad_fn=<DivBackward0>)\n",
      "18:0 loss --> tensor([0.0052], grad_fn=<DivBackward0>)\n",
      "18:10 loss --> tensor([0.0037], grad_fn=<DivBackward0>)\n",
      "18:20 loss --> tensor([0.0052], grad_fn=<DivBackward0>)\n",
      "19:0 loss --> tensor([0.0044], grad_fn=<DivBackward0>)\n",
      "19:10 loss --> tensor([0.0033], grad_fn=<DivBackward0>)\n",
      "19:20 loss --> tensor([0.0044], grad_fn=<DivBackward0>)\n",
      "20:0 loss --> tensor([0.0040], grad_fn=<DivBackward0>)\n",
      "20:10 loss --> tensor([0.0026], grad_fn=<DivBackward0>)\n",
      "20:20 loss --> tensor([0.0039], grad_fn=<DivBackward0>)\n",
      "21:0 loss --> tensor([0.0036], grad_fn=<DivBackward0>)\n",
      "21:10 loss --> tensor([0.0022], grad_fn=<DivBackward0>)\n",
      "21:20 loss --> tensor([0.0034], grad_fn=<DivBackward0>)\n",
      "22:0 loss --> tensor([0.0032], grad_fn=<DivBackward0>)\n",
      "22:10 loss --> tensor([0.0020], grad_fn=<DivBackward0>)\n",
      "22:20 loss --> tensor([0.0030], grad_fn=<DivBackward0>)\n",
      "23:0 loss --> tensor([0.0029], grad_fn=<DivBackward0>)\n",
      "23:10 loss --> tensor([0.0018], grad_fn=<DivBackward0>)\n",
      "23:20 loss --> tensor([0.0027], grad_fn=<DivBackward0>)\n",
      "24:0 loss --> tensor([0.0026], grad_fn=<DivBackward0>)\n",
      "24:10 loss --> tensor([0.0016], grad_fn=<DivBackward0>)\n",
      "24:20 loss --> tensor([0.0024], grad_fn=<DivBackward0>)\n",
      "25:0 loss --> tensor([0.0024], grad_fn=<DivBackward0>)\n",
      "25:10 loss --> tensor([0.0015], grad_fn=<DivBackward0>)\n",
      "25:20 loss --> tensor([0.0022], grad_fn=<DivBackward0>)\n",
      "26:0 loss --> tensor([0.0022], grad_fn=<DivBackward0>)\n",
      "26:10 loss --> tensor([0.0013], grad_fn=<DivBackward0>)\n",
      "26:20 loss --> tensor([0.0020], grad_fn=<DivBackward0>)\n",
      "27:0 loss --> tensor([0.0020], grad_fn=<DivBackward0>)\n",
      "27:10 loss --> tensor([0.0012], grad_fn=<DivBackward0>)\n",
      "27:20 loss --> tensor([0.0019], grad_fn=<DivBackward0>)\n",
      "28:0 loss --> tensor([0.0019], grad_fn=<DivBackward0>)\n",
      "28:10 loss --> tensor([0.0011], grad_fn=<DivBackward0>)\n",
      "28:20 loss --> tensor([0.0017], grad_fn=<DivBackward0>)\n",
      "29:0 loss --> tensor([0.0017], grad_fn=<DivBackward0>)\n",
      "29:10 loss --> tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "29:20 loss --> tensor([0.0016], grad_fn=<DivBackward0>)\n",
      "30:0 loss --> tensor([0.0016], grad_fn=<DivBackward0>)\n",
      "30:10 loss --> tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "30:20 loss --> tensor([0.0015], grad_fn=<DivBackward0>)\n",
      "31:0 loss --> tensor([0.0015], grad_fn=<DivBackward0>)\n",
      "31:10 loss --> tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "31:20 loss --> tensor([0.0014], grad_fn=<DivBackward0>)\n",
      "32:0 loss --> tensor([0.0014], grad_fn=<DivBackward0>)\n",
      "32:10 loss --> tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "32:20 loss --> tensor([0.0013], grad_fn=<DivBackward0>)\n",
      "33:0 loss --> tensor([0.0013], grad_fn=<DivBackward0>)\n",
      "33:10 loss --> tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "33:20 loss --> tensor([0.0012], grad_fn=<DivBackward0>)\n",
      "34:0 loss --> tensor([0.0012], grad_fn=<DivBackward0>)\n",
      "34:10 loss --> tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "34:20 loss --> tensor([0.0011], grad_fn=<DivBackward0>)\n",
      "35:0 loss --> tensor([0.0011], grad_fn=<DivBackward0>)\n",
      "35:10 loss --> tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "35:20 loss --> tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "36:0 loss --> tensor([0.0011], grad_fn=<DivBackward0>)\n",
      "36:10 loss --> tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "36:20 loss --> tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "37:0 loss --> tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "37:10 loss --> tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "37:20 loss --> tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "38:0 loss --> tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "38:10 loss --> tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "38:20 loss --> tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "39:0 loss --> tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "39:10 loss --> tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "39:20 loss --> tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "40:0 loss --> tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "40:10 loss --> tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "40:20 loss --> tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "41:0 loss --> tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "41:10 loss --> tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "41:20 loss --> tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "42:0 loss --> tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "42:10 loss --> tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "42:20 loss --> tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "43:0 loss --> tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "43:10 loss --> tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "43:20 loss --> tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "44:0 loss --> tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "44:10 loss --> tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "44:20 loss --> tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "45:0 loss --> tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "45:10 loss --> tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "45:20 loss --> tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "46:0 loss --> tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "46:10 loss --> tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "46:20 loss --> tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "47:0 loss --> tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "47:10 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "47:20 loss --> tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "48:0 loss --> tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "48:10 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "48:20 loss --> tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "49:0 loss --> tensor([0.0005], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49:10 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "49:20 loss --> tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "50:0 loss --> tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "50:10 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "50:20 loss --> tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "51:0 loss --> tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "51:10 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "51:20 loss --> tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "52:0 loss --> tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "52:10 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "52:20 loss --> tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "53:0 loss --> tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "53:10 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "53:20 loss --> tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "54:0 loss --> tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "54:10 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "54:20 loss --> tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "55:0 loss --> tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "55:10 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "55:20 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "56:0 loss --> tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "56:10 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "56:20 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "57:0 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "57:10 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "57:20 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "58:0 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "58:10 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "58:20 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "59:0 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "59:10 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "59:20 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "60:0 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "60:10 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "60:20 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "61:0 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "61:10 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "61:20 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "62:0 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "62:10 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "62:20 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "63:0 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "63:10 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "63:20 loss --> tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "64:0 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "64:10 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "64:20 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "65:0 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "65:10 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "65:20 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "66:0 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "66:10 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "66:20 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "67:0 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "67:10 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "67:20 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "68:0 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "68:10 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "68:20 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "69:0 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "69:10 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "69:20 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "70:0 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "70:10 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "70:20 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "71:0 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "71:10 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "71:20 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "72:0 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "72:10 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "72:20 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "73:0 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "73:10 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "73:20 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "74:0 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "74:10 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "74:20 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "75:0 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "75:10 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "75:20 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "76:0 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "76:10 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "76:20 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "77:0 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "77:10 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "77:20 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "78:0 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "78:10 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "78:20 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "79:0 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "79:10 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "79:20 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "80:0 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "80:10 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "80:20 loss --> tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "81:0 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "81:10 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "81:20 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "82:0 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "82:10 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "82:20 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "83:0 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "83:10 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "83:20 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "84:0 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "84:10 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "84:20 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "85:0 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "85:10 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "85:20 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "86:0 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "86:10 loss --> tensor([0.0001], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-153:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hecong/tools/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/hecong/tools/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/hecong/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/hecong/tools/python3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/hecong/tools/python3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/hecong/tools/python3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/hecong/tools/python3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/hecong/tools/python3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9005875bd247>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mpreds_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3c4ea4b33415>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# rnn features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3c4ea4b33415>\u001b[0m in \u001b[0;36mdata_parallel\u001b[0;34m(model, input, ngpu)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3c4ea4b33415>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         recurrent, _ = data_parallel(self.rnn, input,\n\u001b[0;32m---> 29\u001b[0;31m                                            self.ngpu)  # [T, b, h * 2]\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mt_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3c4ea4b33415>\u001b[0m in \u001b[0;36mdata_parallel\u001b[0;34m(model, input, ngpu)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mLSTMCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mingate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mingate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mforgetgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforgetgate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mcellgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcellgate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0moutgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutgate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import lib.data.char as c\n",
    "from warpctc_pytorch import CTCLoss\n",
    "import lib.utils as utils\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "\n",
    "\n",
    "ngpu = 0\n",
    "# size of the lstm hidden state\n",
    "nh = 256\n",
    "nclass = len(c.alphabet) + 1\n",
    "# input channel ， 因为训练图片是转成灰度图，所以该值为1\n",
    "nc = 1\n",
    "lr = 0.001\n",
    "beta1=0.5\n",
    "EPOCH = 1000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 字符转换编码\n",
    "converter = utils.strLabelConverter(c.alphabet)\n",
    "# 损失函数\n",
    "criterion = CTCLoss()\n",
    "\n",
    "crnn = CRNN(imgH, nc, nclass, nh, ngpu)\n",
    "crnn.apply(weights_init)\n",
    "if os.path.exists('/home/hecong/temp/data/ocr/simple_ocr.pkl'):\n",
    "    crnn.load_state_dict(torch.load('/home/hecong/temp/data/ocr/simple_ocr.pkl'))\n",
    "\n",
    "image = torch.FloatTensor(batchSize, 3, imgH, imgH)\n",
    "text = torch.IntTensor(batchSize * 5)\n",
    "length = torch.IntTensor(batchSize)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    crnn.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for step,(t_image,t_label) in enumerate(train_loader):\n",
    "        batch_size = t_image.size(0)\n",
    "        utils.loadData(image, t_image)\n",
    "        t, l = converter.encode(t_label)\n",
    "        utils.loadData(text, t)\n",
    "        utils.loadData(length, l)\n",
    "\n",
    "        preds = crnn(image)\n",
    "        preds_size = Variable(torch.IntTensor([preds.size(0)] * batch_size))\n",
    "        optimizer.zero_grad()\n",
    "        cost = criterion(preds, text, preds_size, length) / batch_size\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            print('{}:{} loss --> {}'.format(epoch, step, cost))\n",
    "            torch.save(crnn.state_dict(), '/home/hecong/temp/data/ocr/simple_ocr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49, 2, 42])\n",
      "torch.Size([20])\n",
      "tensor([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
      "        21, 22], dtype=torch.int32)\n",
      "tensor([49, 49], dtype=torch.int32)\n",
      "tensor([2], dtype=torch.int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([171.5280], grad_fn=<_CTCBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preds_size = torch.IntTensor([49])\n",
    "# length = torch.IntTensor([49])\n",
    "print(preds.size())\n",
    "print(text.size())\n",
    "print(text)\n",
    "print(preds_size)\n",
    "print(length)\n",
    "\n",
    "criterion(preds, text, preds_size, length)\n",
    "\n",
    "# prob size --> torch.Size([2, 1, 5])\n",
    "# labels size --> torch.Size([2])\n",
    "# prob sizes -->tensor([2], dtype=torch.int32)\n",
    "# label sizes -->tensor([2], dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(crnn.state_dict(), '/home/hecong/temp/data/ocr/simple_ocr.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
